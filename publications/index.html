<!DOCTYPE html>
<html lang="en-US" class="no-js no-svg"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><script>(function(html){html.className=html.className.replace(/\bno-js\b/,'js')})(document.documentElement);</script><title>Publications – Theoretical Neuroscience@CIMH</title><link rel="dns-prefetch" href="//fonts.googleapis.com"><link rel="dns-prefetch" href="//s.w.org"><link href="https://fonts.gstatic.com" crossorigin rel="preconnect"><style id="papercite_css-css" media="all">.papercite_errors:before{content:"Papercite errors"}.papercite_errors{border:1px solid red;background:#eee;padding:5px}.papercite_errors>div{display:list-item}.papercite_bibtex{display:none}.papercite_bibtex pre{white-space:pre-wrap}.papercite_toggle:link,.papercite_toggle:visited{color:gray;text-decoration:none}.papercite_link,.papercite_link:link,.papercite_link:visited{color:#222;font-weight:bold;text-decoration:none;cursor:pointer}.papercite_info{color:#555}.papercite_highlight{font-weight:bold}span.papercite_checked_files{padding:5px;margin:5px;border:1px solid #000;font-size:150%;cursor:pointer;background:#eee;color:red;border-radius:3px}</style><link rel="stylesheet" id="wp-block-library-css" href="../wp-includes/css/dist/block-library/A.style.min.css,qver=5.5.5.pagespeed.cf.sbGIYr7uk6.css" type="text/css" media="all"><link rel="stylesheet" id="wp-block-library-theme-css" href="../wp-includes/css/dist/block-library/theme.min.css,qver=5.5.5.pagespeed.ce.m9MT-86WiO.css" type="text/css" media="all"><link rel="stylesheet" id="twentyseventeen-fonts-css" href="https://fonts.googleapis.com/css?family=Libre+Franklin%3A300%2C300i%2C400%2C400i%2C600%2C600i%2C800%2C800i&subset=latin%2Clatin-ext" type="text/css" media="all"><link rel="stylesheet" id="twentyseventeen-style-css" href="../wp-content/themes/twentyseventeen/A.style.css,qver=5.5.5.pagespeed.cf.Mj7IMGYjjb.css" type="text/css" media="all"><link rel="stylesheet" id="twentyseventeen-block-style-css" href="../wp-content/themes/twentyseventeen/assets/css/A.blocks.css,qver=1.1.pagespeed.cf.oofOXiv__M.css" type="text/css" media="all"><script type="text/javascript" src="../wp-includes/js/jquery/jquery.js,qver=1.12.4-wp.pagespeed.jm.gp20iU5FlU.js" id="jquery-core-js"></script><script type="text/javascript" id="papercite-js">//<![CDATA[
var $j=jQuery.noConflict();$j(document).ready(function(){$j('a.papercite_toggle').click(function(){$j("#"+$j(this).attr("id")+"_block").toggle();return false;});});
//]]></script><script type="text/javascript" id="wpgmza_data-js-extra">//<![CDATA[
var wpgmza_google_api_status={"message":"Engine is not google-maps","code":"ENGINE_NOT_GOOGLE_MAPS"};
//]]></script><script type="text/javascript" src="../wp-content/plugins/wp-google-maps/wpgmza_data.js" id="wpgmza_data-js"></script><script type="text/javascript" src="../wp-content/plugins/teachpress/js/frontend.js,qver=6.2.4.pagespeed.jm.0LxJCbnNI8.js"></script><link type="text/css" href="../wp-content/plugins/teachpress/styles/A.teachpress_front.css,qver=6.2.4.pagespeed.cf.AITGcPqCQj.css" rel="stylesheet"><style type="text/css" id="custom-theme-colors">.colors-custom a:hover,
.colors-custom a:active,
.colors-custom .entry-content a:focus,
.colors-custom .entry-content a:hover,
.colors-custom .entry-summary a:focus,
.colors-custom .entry-summary a:hover,
.colors-custom .comment-content a:focus,
.colors-custom .comment-content a:hover,
.colors-custom .widget a:focus,
.colors-custom .widget a:hover,
.colors-custom .site-footer .widget-area a:focus,
.colors-custom .site-footer .widget-area a:hover,
.colors-custom .posts-navigation a:focus,
.colors-custom .posts-navigation a:hover,
.colors-custom .comment-metadata a:focus,
.colors-custom .comment-metadata a:hover,
.colors-custom .comment-metadata a.comment-edit-link:focus,
.colors-custom .comment-metadata a.comment-edit-link:hover,
.colors-custom .comment-reply-link:focus,
.colors-custom .comment-reply-link:hover,
.colors-custom .widget_authors a:focus strong,
.colors-custom .widget_authors a:hover strong,
.colors-custom .entry-title a:focus,
.colors-custom .entry-title a:hover,
.colors-custom .entry-meta a:focus,
.colors-custom .entry-meta a:hover,
.colors-custom.blog .entry-meta a.post-edit-link:focus,
.colors-custom.blog .entry-meta a.post-edit-link:hover,
.colors-custom.archive .entry-meta a.post-edit-link:focus,
.colors-custom.archive .entry-meta a.post-edit-link:hover,
.colors-custom.search .entry-meta a.post-edit-link:focus,
.colors-custom.search .entry-meta a.post-edit-link:hover,
.colors-custom .page-links a:focus .page-number,
.colors-custom .page-links a:hover .page-number,
.colors-custom .entry-footer a:focus,
.colors-custom .entry-footer a:hover,
.colors-custom .entry-footer .cat-links a:focus,
.colors-custom .entry-footer .cat-links a:hover,
.colors-custom .entry-footer .tags-links a:focus,
.colors-custom .entry-footer .tags-links a:hover,
.colors-custom .post-navigation a:focus,
.colors-custom .post-navigation a:hover,
.colors-custom .pagination a:not(.prev):not(.next):focus,
.colors-custom .pagination a:not(.prev):not(.next):hover,
.colors-custom .comments-pagination a:not(.prev):not(.next):focus,
.colors-custom .comments-pagination a:not(.prev):not(.next):hover,
.colors-custom .logged-in-as a:focus,
.colors-custom .logged-in-as a:hover,
.colors-custom a:focus .nav-title,
.colors-custom a:hover .nav-title,
.colors-custom .edit-link a:focus,
.colors-custom .edit-link a:hover,
.colors-custom .site-info a:focus,
.colors-custom .site-info a:hover,
.colors-custom .widget .widget-title a:focus,
.colors-custom .widget .widget-title a:hover,
.colors-custom .widget ul li a:focus,
.colors-custom .widget ul li a:hover {color:hsl(31,50%,0%)}.colors-custom .entry-content a,.colors-custom .entry-summary a,.colors-custom .comment-content a,.colors-custom .widget a,.colors-custom .site-footer .widget-area a,.colors-custom .posts-navigation a,.colors-custom .widget_authors a strong{-webkit-box-shadow:inset 0 -1px 0 hsl(31,50%,6%);box-shadow:inset 0 -1px 0 hsl(31,50%,6%)}.colors-custom button,.colors-custom input[type="button"],.colors-custom input[type="submit"],.colors-custom .entry-footer .edit-link a.post-edit-link{background-color:hsl(31,50%,13%)}.colors-custom input[type="text"]:focus,
.colors-custom input[type="email"]:focus,
.colors-custom input[type="url"]:focus,
.colors-custom input[type="password"]:focus,
.colors-custom input[type="search"]:focus,
.colors-custom input[type="number"]:focus,
.colors-custom input[type="tel"]:focus,
.colors-custom input[type="range"]:focus,
.colors-custom input[type="date"]:focus,
.colors-custom input[type="month"]:focus,
.colors-custom input[type="week"]:focus,
.colors-custom input[type="time"]:focus,
.colors-custom input[type="datetime"]:focus,
.colors-custom .colors-custom input[type="datetime-local"]:focus,
.colors-custom input[type="color"]:focus,
.colors-custom textarea:focus,
.colors-custom button.secondary,
.colors-custom input[type="reset"],
.colors-custom input[type="button"].secondary,
.colors-custom input[type="reset"].secondary,
.colors-custom input[type="submit"].secondary,
.colors-custom a,
.colors-custom .site-title,
.colors-custom .site-title a,
.colors-custom .navigation-top a,
.colors-custom .dropdown-toggle,
.colors-custom .menu-toggle,
.colors-custom .page .panel-content .entry-title,
.colors-custom .page-title,
.colors-custom.page:not(.twentyseventeen-front-page) .entry-title,
.colors-custom .page-links a .page-number,
.colors-custom .comment-metadata a.comment-edit-link,
.colors-custom .comment-reply-link .icon,
.colors-custom h2.widget-title,
.colors-custom mark,
.colors-custom .post-navigation a:focus .icon,
.colors-custom .post-navigation a:hover .icon,
.colors-custom .site-content .site-content-light,
.colors-custom .twentyseventeen-panel .recent-posts .entry-header .edit-link {color:hsl(31,50%,13%)}.colors-custom .entry-content a:focus,
.colors-custom .entry-content a:hover,
.colors-custom .entry-summary a:focus,
.colors-custom .entry-summary a:hover,
.colors-custom .comment-content a:focus,
.colors-custom .comment-content a:hover,
.colors-custom .widget a:focus,
.colors-custom .widget a:hover,
.colors-custom .site-footer .widget-area a:focus,
.colors-custom .site-footer .widget-area a:hover,
.colors-custom .posts-navigation a:focus,
.colors-custom .posts-navigation a:hover,
.colors-custom .comment-metadata a:focus,
.colors-custom .comment-metadata a:hover,
.colors-custom .comment-metadata a.comment-edit-link:focus,
.colors-custom .comment-metadata a.comment-edit-link:hover,
.colors-custom .comment-reply-link:focus,
.colors-custom .comment-reply-link:hover,
.colors-custom .widget_authors a:focus strong,
.colors-custom .widget_authors a:hover strong,
.colors-custom .entry-title a:focus,
.colors-custom .entry-title a:hover,
.colors-custom .entry-meta a:focus,
.colors-custom .entry-meta a:hover,
.colors-custom.blog .entry-meta a.post-edit-link:focus,
.colors-custom.blog .entry-meta a.post-edit-link:hover,
.colors-custom.archive .entry-meta a.post-edit-link:focus,
.colors-custom.archive .entry-meta a.post-edit-link:hover,
.colors-custom.search .entry-meta a.post-edit-link:focus,
.colors-custom.search .entry-meta a.post-edit-link:hover,
.colors-custom .page-links a:focus .page-number,
.colors-custom .page-links a:hover .page-number,
.colors-custom .entry-footer .cat-links a:focus,
.colors-custom .entry-footer .cat-links a:hover,
.colors-custom .entry-footer .tags-links a:focus,
.colors-custom .entry-footer .tags-links a:hover,
.colors-custom .post-navigation a:focus,
.colors-custom .post-navigation a:hover,
.colors-custom .pagination a:not(.prev):not(.next):focus,
.colors-custom .pagination a:not(.prev):not(.next):hover,
.colors-custom .comments-pagination a:not(.prev):not(.next):focus,
.colors-custom .comments-pagination a:not(.prev):not(.next):hover,
.colors-custom .logged-in-as a:focus,
.colors-custom .logged-in-as a:hover,
.colors-custom a:focus .nav-title,
.colors-custom a:hover .nav-title,
.colors-custom .edit-link a:focus,
.colors-custom .edit-link a:hover,
.colors-custom .site-info a:focus,
.colors-custom .site-info a:hover,
.colors-custom .widget .widget-title a:focus,
.colors-custom .widget .widget-title a:hover,
.colors-custom .widget ul li a:focus,
.colors-custom .widget ul li a:hover {-webkit-box-shadow:inset 0 0 0 hsl(31,50%,13%) , 0 3px 0 hsl(31,50%,13%);box-shadow:inset 0 0 0 hsl(31,50%,13%) , 0 3px 0 hsl(31,50%,13%)}body.colors-custom,.colors-custom button,.colors-custom input,.colors-custom select,.colors-custom textarea,.colors-custom h3,.colors-custom h4,.colors-custom h6,.colors-custom label,.colors-custom .entry-title a,.colors-custom.twentyseventeen-front-page .panel-content .recent-posts article,.colors-custom .entry-footer .cat-links a,.colors-custom .entry-footer .tags-links a,.colors-custom .format-quote blockquote,.colors-custom .nav-title,.colors-custom .comment-body,.colors-custom .site-content .wp-playlist-light .wp-playlist-current-item .wp-playlist-item-album{color:hsl(31,40%,20%)}.colors-custom .social-navigation a:hover,.colors-custom .social-navigation a:focus{background:hsl(31,40%,20%)}.colors-custom input[type="text"]:focus,.colors-custom input[type="email"]:focus,.colors-custom input[type="url"]:focus,.colors-custom input[type="password"]:focus,.colors-custom input[type="search"]:focus,.colors-custom input[type="number"]:focus,.colors-custom input[type="tel"]:focus,.colors-custom input[type="range"]:focus,.colors-custom input[type="date"]:focus,.colors-custom input[type="month"]:focus,.colors-custom input[type="week"]:focus,.colors-custom input[type="time"]:focus,.colors-custom input[type="datetime"]:focus,.colors-custom input[type="datetime-local"]:focus,.colors-custom input[type="color"]:focus,.colors-custom textarea:focus,.bypostauthor>.comment-body>.comment-meta>.comment-author .avatar{border-color:hsl(31,40%,20%)}.colors-custom h2,.colors-custom blockquote,.colors-custom input[type="text"],.colors-custom input[type="email"],.colors-custom input[type="url"],.colors-custom input[type="password"],.colors-custom input[type="search"],.colors-custom input[type="number"],.colors-custom input[type="tel"],.colors-custom input[type="range"],.colors-custom input[type="date"],.colors-custom input[type="month"],.colors-custom input[type="week"],.colors-custom input[type="time"],.colors-custom input[type="datetime"],.colors-custom input[type="datetime-local"],.colors-custom input[type="color"],.colors-custom textarea,.colors-custom .site-description,.colors-custom .entry-content blockquote.alignleft,.colors-custom .entry-content blockquote.alignright,.colors-custom .colors-custom .taxonomy-description,.colors-custom .site-info a,.colors-custom .wp-caption,.colors-custom .gallery-caption{color:hsl(31,50%,40%)}.colors-custom abbr,.colors-custom acronym{border-bottom-color:hsl(31,50%,40%)}.colors-custom h5,.colors-custom .entry-meta,.colors-custom .entry-meta a,.colors-custom.blog .entry-meta a.post-edit-link,.colors-custom.archive .entry-meta a.post-edit-link,.colors-custom.search .entry-meta a.post-edit-link,.colors-custom .nav-subtitle,.colors-custom .comment-metadata,.colors-custom .comment-metadata a,.colors-custom .no-comments,.colors-custom .comment-awaiting-moderation,.colors-custom .page-numbers.current,.colors-custom .page-links .page-number,.colors-custom .navigation-top .current-menu-item>a,.colors-custom .navigation-top .current_page_item>a,.colors-custom .main-navigation a:hover,.colors-custom .site-content .wp-playlist-light .wp-playlist-current-item .wp-playlist-item-artist{color:hsl(31,50%,46%)}.colors-custom button:hover:not( .mejs-container > button ),
.colors-custom button:focus,
.colors-custom input[type="button"]:hover,
.colors-custom input[type="button"]:focus,
.colors-custom input[type="submit"]:hover,
.colors-custom input[type="submit"]:focus,
.colors-custom .entry-footer .edit-link a.post-edit-link:hover,
.colors-custom .entry-footer .edit-link a.post-edit-link:focus,
.colors-custom .social-navigation a,
.colors-custom .prev.page-numbers:focus,
.colors-custom .prev.page-numbers:hover,
.colors-custom .next.page-numbers:focus,
.colors-custom .next.page-numbers:hover,
.colors-custom .site-content .wp-playlist-light .wp-playlist-item:hover,
.colors-custom .site-content .wp-playlist-light .wp-playlist-item:focus {background:hsl(31,50%,46%)}.colors-custom button.secondary:hover,.colors-custom button.secondary:focus,.colors-custom input[type="reset"]:hover,.colors-custom input[type="reset"]:focus,.colors-custom input[type="button"].secondary:hover,.colors-custom input[type="button"].secondary:focus,.colors-custom input[type="reset"].secondary:hover,.colors-custom input[type="reset"].secondary:focus,.colors-custom input[type="submit"].secondary:hover,.colors-custom input[type="submit"].secondary:focus,.colors-custom hr{background:hsl(31,50%,73%)}.colors-custom input[type="text"],.colors-custom input[type="email"],.colors-custom input[type="url"],.colors-custom input[type="password"],.colors-custom input[type="search"],.colors-custom input[type="number"],.colors-custom input[type="tel"],.colors-custom input[type="range"],.colors-custom input[type="date"],.colors-custom input[type="month"],.colors-custom input[type="week"],.colors-custom input[type="time"],.colors-custom input[type="datetime"],.colors-custom input[type="datetime-local"],.colors-custom input[type="color"],.colors-custom textarea,.colors-custom select,.colors-custom fieldset,.colors-custom .widget .tagcloud a:hover,.colors-custom .widget .tagcloud a:focus,.colors-custom .widget.widget_tag_cloud a:hover,.colors-custom .widget.widget_tag_cloud a:focus,.colors-custom .wp_widget_tag_cloud a:hover,.colors-custom .wp_widget_tag_cloud a:focus{border-color:hsl(31,50%,73%)}.colors-custom thead th{border-bottom-color:hsl(31,50%,73%)}.colors-custom .entry-footer .cat-links .icon,.colors-custom .entry-footer .tags-links .icon{color:hsl(31,50%,73%)}.colors-custom button.secondary,.colors-custom input[type="reset"],.colors-custom input[type="button"].secondary,.colors-custom input[type="reset"].secondary,.colors-custom input[type="submit"].secondary,.colors-custom .prev.page-numbers,.colors-custom .next.page-numbers{background-color:hsl(31,50%,87%)}.colors-custom .widget .tagcloud a,.colors-custom .widget.widget_tag_cloud a,.colors-custom .wp_widget_tag_cloud a{border-color:hsl(31,50%,87%)}.colors-custom.twentyseventeen-front-page article:not(.has-post-thumbnail):not(:first-child),
.colors-custom .widget ul li {border-top-color:hsl(31,50%,87%)}.colors-custom .widget ul li{border-bottom-color:hsl(31,50%,87%)}.colors-custom pre,.colors-custom mark,.colors-custom ins{background:hsl(31,50%,93%)}.colors-custom .navigation-top,.colors-custom .main-navigation>div>ul,.colors-custom .pagination,.colors-custom .comments-pagination,.colors-custom .entry-footer,.colors-custom .site-footer{border-top-color:hsl(31,50%,93%)}.colors-custom .navigation-top,.colors-custom .main-navigation li,.colors-custom .entry-footer,.colors-custom .single-featured-image-header,.colors-custom .site-content .wp-playlist-light .wp-playlist-item,.colors-custom tr{border-bottom-color:hsl(31,50%,93%)}.colors-custom .site-content .wp-playlist-light{border-color:hsl(31,50%,93%)}.colors-custom .site-header,.colors-custom .single-featured-image-header{background-color:hsl(31,50%,98%)}.colors-custom button,.colors-custom input[type="button"],.colors-custom input[type="submit"],.colors-custom .entry-footer .edit-link a.post-edit-link,.colors-custom .social-navigation a,.colors-custom .site-content .wp-playlist-light a.wp-playlist-caption:hover,.colors-custom .site-content .wp-playlist-light .wp-playlist-item:hover a,.colors-custom .site-content .wp-playlist-light .wp-playlist-item:focus a,.colors-custom .site-content .wp-playlist-light .wp-playlist-item:hover,.colors-custom .site-content .wp-playlist-light .wp-playlist-item:focus,.colors-custom .prev.page-numbers:focus,.colors-custom .prev.page-numbers:hover,.colors-custom .next.page-numbers:focus,.colors-custom .next.page-numbers:hover,.colors-custom.has-header-image .site-title,.colors-custom.has-header-video .site-title,.colors-custom.has-header-image .site-title a,.colors-custom.has-header-video .site-title a,.colors-custom.has-header-image .site-description,.colors-custom.has-header-video .site-description{color:hsl(31,50%,100%)}body.colors-custom,.colors-custom .navigation-top,.colors-custom .main-navigation ul{background:hsl(31,50%,100%)}.colors-custom .widget ul li a,.colors-custom .site-footer .widget-area ul li a{-webkit-box-shadow:inset 0 -1px 0 hsl(31,50%,100%);box-shadow:inset 0 -1px 0 hsl(31,50%,100%)}.colors-custom .menu-toggle,.colors-custom .menu-toggle:hover,.colors-custom .menu-toggle:focus,.colors-custom .menu .dropdown-toggle,.colors-custom .menu-scroll-down,.colors-custom .menu-scroll-down:hover,.colors-custom .menu-scroll-down:focus{background-color:transparent}.colors-custom .widget .tagcloud a,.colors-custom .widget .tagcloud a:focus,.colors-custom .widget .tagcloud a:hover,.colors-custom .widget.widget_tag_cloud a,.colors-custom .widget.widget_tag_cloud a:focus,.colors-custom .widget.widget_tag_cloud a:hover,.colors-custom .wp_widget_tag_cloud a,.colors-custom .wp_widget_tag_cloud a:focus,.colors-custom .wp_widget_tag_cloud a:hover,.colors-custom .entry-footer .edit-link a.post-edit-link:focus,.colors-custom .entry-footer .edit-link a.post-edit-link:hover{-webkit-box-shadow:none!important;box-shadow:none!important}.colors-custom .entry-content a:hover,.colors-custom .entry-content a:focus,.colors-custom .entry-summary a:hover,.colors-custom .entry-summary a:focus,.colors-custom .comment-content a:focus,.colors-custom .comment-content a:hover,.colors-custom .widget a:hover,.colors-custom .widget a:focus,.colors-custom .site-footer .widget-area a:hover,.colors-custom .site-footer .widget-area a:focus,.colors-custom .posts-navigation a:hover,.colors-custom .posts-navigation a:focus,.colors-custom .widget_authors a:hover strong,.colors-custom .widget_authors a:focus strong{-webkit-box-shadow:inset 0 0 0 rgba(0,0,0,0) , 0 3px 0 rgba(0,0,0,1);box-shadow:inset 0 0 0 rgba(0,0,0,0) , 0 3px 0 rgba(0,0,0,1)}.colors-custom .gallery-item a,.colors-custom .gallery-item a:hover,.colors-custom .gallery-item a:focus{-webkit-box-shadow:none;box-shadow:none}@media screen and (min-width:48em){.colors-custom .nav-links .nav-previous .nav-title .icon,.colors-custom .nav-links .nav-next .nav-title .icon{color:hsl(31,50%,20%)}.colors-custom .main-navigation li li:hover,.colors-custom .main-navigation li li.focus{background:hsl(31,50%,46%)}.colors-custom .navigation-top .menu-scroll-down{color:hsl(31,50%,46%)}.colors-custom abbr[title]{border-bottom-color:hsl(31,50%,46%)}.colors-custom .main-navigation ul ul{border-color:hsl(31,50%,73%);background:hsl(31,50%,100%)}.colors-custom .main-navigation ul li.menu-item-has-children:before,.colors-custom .main-navigation ul li.page_item_has_children:before{border-bottom-color:hsl(31,50%,73%)}.colors-custom .main-navigation ul li.menu-item-has-children:after,.colors-custom .main-navigation ul li.page_item_has_children:after{border-bottom-color:hsl(31,50%,100%)}.colors-custom .main-navigation li li.focus>a,.colors-custom .main-navigation li li:focus>a,.colors-custom .main-navigation li li:hover>a,.colors-custom .main-navigation li li a:hover,.colors-custom .main-navigation li li a:focus,.colors-custom .main-navigation li li.current_page_item a:hover,.colors-custom .main-navigation li li.current-menu-item a:hover,.colors-custom .main-navigation li li.current_page_item a:focus,.colors-custom .main-navigation li li.current-menu-item a:focus{color:hsl(31,50%,100%)}}</style><style id="twentyseventeen-custom-header-styles" type="text/css">.site-title a,.colors-dark .site-title a,.colors-custom .site-title a,body.has-header-image .site-title a,body.has-header-video .site-title a,body.has-header-image.colors-dark .site-title a,body.has-header-video.colors-dark .site-title a,body.has-header-image.colors-custom .site-title a,body.has-header-video.colors-custom .site-title a,.site-description,.colors-dark .site-description,.colors-custom .site-description,body.has-header-image .site-description,body.has-header-video .site-description,body.has-header-image.colors-dark .site-description,body.has-header-video.colors-dark .site-description,body.has-header-image.colors-custom .site-description,body.has-header-video.colors-custom .site-description{color:#000200}</style><link rel="icon" href="../wp-content/uploads/2019/12/xcropped-website_colorful-5-32x32.jpg.pagespeed.ic.dllGM3WOfD.jpg" sizes="32x32"><link rel="icon" href="../wp-content/uploads/2019/12/xcropped-website_colorful-5-192x192.jpg.pagespeed.ic.jVzZ22cIgi.jpg" sizes="192x192"><link rel="apple-touch-icon" href="../wp-content/uploads/2019/12/xcropped-website_colorful-5-180x180.jpg.pagespeed.ic.rZrq9gujc2.jpg"><meta name="msapplication-TileImage" content="../wp-content/uploads/2019/12/cropped-website_colorful-5-270x270.jpg"></head><body class="page-template-default page page-id-51 wp-embed-responsive has-header-image page-one-column colors-custom">
<div id="page" class="site">
	<a class="skip-link screen-reader-text" href="#content">Skip to content</a>

	<header id="masthead" class="site-header" role="banner"><div class="custom-header">

		<div class="custom-header-media">
			<div id="wp-custom-header" class="wp-custom-header"><img src="http://10.0.12.159/wp-content/uploads/2019/12/cropped-website_colorful2-1-2.jpg" width="2000" height="1199" alt="Theoretical Neuroscience@CIMH" srcset="../wp-content/uploads/2019/12/xcropped-website_colorful2-1-2.jpg.pagespeed.ic.jcu1YEjkbu.jpg 2000w,../wp-content/uploads/2019/12/xcropped-website_colorful2-1-2-300x180.jpg.pagespeed.ic.Q640dwvAtK.jpg 300w,../wp-content/uploads/2019/12/xcropped-website_colorful2-1-2-768x460.jpg.pagespeed.ic.F1f2W0-HIX.jpg 768w,../wp-content/uploads/2019/12/xcropped-website_colorful2-1-2-1024x614.jpg.pagespeed.ic.0NTQFKUfY6.jpg 1024w" sizes="100vw"></div>		</div>

	<div class="site-branding">
	<div class="wrap">

		
		<div class="site-branding-text">
							<p class="site-title"><a href="../index.html" rel="home">Theoretical Neuroscience@CIMH</a></p>
			
							<p class="site-description">Durstewitz Lab</p>
					</div>

		
	</div>
</div>

</div>

					<div class="navigation-top">
				<div class="wrap">
					<nav id="site-navigation" class="main-navigation" role="navigation" aria-label="Top Menu"><button class="menu-toggle" aria-controls="top-menu" aria-expanded="false">
		<svg class="icon icon-bars" aria-hidden="true" role="img"><use href="#icon-bars" xlink:href="#icon-bars"></use></svg><svg class="icon icon-close" aria-hidden="true" role="img"><use href="#icon-close" xlink:href="#icon-close"></use></svg>Menu	</button>

	<div class="menu-main-menu-container"><ul id="top-menu" class="menu"><li id="menu-item-33" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-33"><a href="../index.html">Home</a></li>
<li id="menu-item-54" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-51 current_page_item menu-item-54"><a href="../publications/index.html" aria-current="page">Publications</a></li>
<li id="menu-item-37" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-37"><a href="../members/index.html">Members</a></li>
<li id="menu-item-36" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-36"><a href="../downloads/index.html">Downloads and Materials</a></li>
<li id="menu-item-35" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-35"><a href="../contact/index.html">Contact</a></li>
<li id="menu-item-181" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-181"><a href="../blog/index.html">Blog</a></li>
</ul></div>
	</nav></div>
			</div>
		
	</header><div class="site-content-contain">
		<div id="content" class="site-content">

<div class="wrap">
	<div id="primary" class="content-area">
		<main id="main" class="site-main" role="main"><article id="post-51" class="post-51 page type-page status-publish hentry"><header class="entry-header"><h1 class="entry-title">Publications</h1>			</header><div class="entry-content">
		
<h1><div class="tablenav"><div class="tablenav-pages"><span class="displaying-num">69 entries</span> <a class="first-page disabled">«</a> <a class="prev-page disabled">‹</a>  1 of 2 <a href="../publications/index.html" title="next page" class="page-numbers">›</a> <a href="../publications/index.html" title="last page" class="page-numbers">»</a> </div></div></h1><table class="teachpress_publication_list"><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2022">2022</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Manuel Brenner  Florian Hess, Jonas Mikhaeil Leonard Bereska Zahra Monfared Po-Chen Kuo Daniel Durstewitz M  F</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('77','tp_links')" style="cursor:pointer;">Tractable Dendritic RNNs for Reconstructing Nonlinear Dynamical Systems</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Proceedings of Machine Learning Research, </span><span class="tp_pub_additional_year">2022</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_77" class="tp_show" onclick="teachpress_pub_showhide('77','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_77" class="tp_show" onclick="teachpress_pub_showhide('77','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_77" class="tp_show" onclick="teachpress_pub_showhide('77','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_77" style="display:none;"><div class="tp_bibtex_entry">@article{Brenner2022,<br>
title = {Tractable Dendritic RNNs for Reconstructing Nonlinear Dynamical Systems},<br>
author = {Manuel Brenner, Florian Hess, Jonas M Mikhaeil, Leonard F Bereska, Zahra Monfared, Po-Chen Kuo, Daniel Durstewitz},<br>
url = {https://proceedings.mlr.press/v162/brenner22a.html},<br>
year  = {2022},<br>
date = {2022-07-01},<br>
journal = {Proceedings of Machine Learning Research},<br>
abstract = {In many scientific disciplines, we are interested in inferring the nonlinear dynamical system underlying a set of observed time series, a challenging task in the face of chaotic behavior and noise. Previous deep learning approaches toward this goal often suffered from a lack of interpretability and tractability. In particular, the high-dimensional latent spaces often required for a faithful embedding, even when the underlying dynamics lives on a lower-dimensional manifold, can hamper theoretical analysis. Motivated by the emerging principles of dendritic computation, we augment a dynamically interpretable and mathematically tractable piecewise-linear (PL) recurrent neural network (RNN) by a linear spline basis expansion. We show that this approach retains all the theoretically appealing properties of the simple PLRNN, yet boosts its capacity for approximating arbitrary nonlinear dynamical systems in comparatively low dimensions. We employ two frameworks for training the system, one combining BPTT with teacher forcing, and another based on fast and scalable variational inference. We show that the dendritically expanded PLRNN achieves better reconstructions with fewer parameters and dimensions on various dynamical systems benchmarks and compares favorably to other methods, while retaining a tractable and interpretable structure.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('77','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_77" style="display:none;"><div class="tp_abstract_entry">In many scientific disciplines, we are interested in inferring the nonlinear dynamical system underlying a set of observed time series, a challenging task in the face of chaotic behavior and noise. Previous deep learning approaches toward this goal often suffered from a lack of interpretability and tractability. In particular, the high-dimensional latent spaces often required for a faithful embedding, even when the underlying dynamics lives on a lower-dimensional manifold, can hamper theoretical analysis. Motivated by the emerging principles of dendritic computation, we augment a dynamically interpretable and mathematically tractable piecewise-linear (PL) recurrent neural network (RNN) by a linear spline basis expansion. We show that this approach retains all the theoretically appealing properties of the simple PLRNN, yet boosts its capacity for approximating arbitrary nonlinear dynamical systems in comparatively low dimensions. We employ two frameworks for training the system, one combining BPTT with teacher forcing, and another based on fast and scalable variational inference. We show that the dendritically expanded PLRNN achieves better reconstructions with fewer parameters and dimensions on various dynamical systems benchmarks and compares favorably to other methods, while retaining a tractable and interpretable structure.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('77','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_77" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://proceedings.mlr.press/v162/brenner22a.html" title="https://proceedings.mlr.press/v162/brenner22a.html" target="_blank">https://proceedings.mlr.press/v162/brenner22a.html</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('77','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Kramer, Daniel;  Bommer, Philine Lou;  Tombolini, Carlo;  Koppe, Georgia;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('74','tp_links')" style="cursor:pointer;">Identifying nonlinear dynamical systems from multi-modal time series data</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Proceedings of Machine Learning Research, </span><span class="tp_pub_additional_volume">162 </span>, <span class="tp_pub_additional_year">2022</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_74" class="tp_show" onclick="teachpress_pub_showhide('74','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_74" class="tp_show" onclick="teachpress_pub_showhide('74','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_74" class="tp_show" onclick="teachpress_pub_showhide('74','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_74" style="display:none;"><div class="tp_bibtex_entry">@article{Kramer2022,<br>
title = {Identifying nonlinear dynamical systems from multi-modal time series data},<br>
author = {Daniel Kramer and Philine Lou Bommer and Carlo Tombolini and Georgia Koppe and Daniel Durstewitz},<br>
url = {https://proceedings.mlr.press/v162/kramer22a.html},<br>
year  = {2022},<br>
date = {2022-06-21},<br>
journal = {Proceedings of Machine Learning Research},<br>
volume = {162},<br>
abstract = {Empirically observed time series in physics, biology, or medicine, are commonly generated by some underlying dynamical system (DS) which is the target of scientific interest. There is an increasing interest to harvest machine learning methods to reconstruct this latent DS in a completely data-driven, unsupervised way. In many areas of science it is common to sample time series observations from many data modalities simultaneously, e.g. electrophysiological and behavioral time series in a typical neuroscience experiment. However, current machine learning tools for reconstructing DSs usually focus on just one data modality. Here we propose a general framework for multi-modal data integration for the purpose of nonlinear DS identification and cross-modal prediction. This framework is based on dynamically interpretable recurrent neural networks as general approximators of nonlinear DSs, coupled to sets of modality-specific decoder models from the class of generalized linear models. Both an expectation-maximization and a variational inference algorithm for model training are advanced and compared. We show on nonlinear DS benchmarks that our algorithms can efficiently compensate for too noisy or missing information in one data channel by exploiting other channels, and demonstrate on experimental neuroscience data how the algorithm learns to link different data domains to the underlying dynamics },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('74','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_74" style="display:none;"><div class="tp_abstract_entry">Empirically observed time series in physics, biology, or medicine, are commonly generated by some underlying dynamical system (DS) which is the target of scientific interest. There is an increasing interest to harvest machine learning methods to reconstruct this latent DS in a completely data-driven, unsupervised way. In many areas of science it is common to sample time series observations from many data modalities simultaneously, e.g. electrophysiological and behavioral time series in a typical neuroscience experiment. However, current machine learning tools for reconstructing DSs usually focus on just one data modality. Here we propose a general framework for multi-modal data integration for the purpose of nonlinear DS identification and cross-modal prediction. This framework is based on dynamically interpretable recurrent neural networks as general approximators of nonlinear DSs, coupled to sets of modality-specific decoder models from the class of generalized linear models. Both an expectation-maximization and a variational inference algorithm for model training are advanced and compared. We show on nonlinear DS benchmarks that our algorithms can efficiently compensate for too noisy or missing information in one data channel by exploiting other channels, and demonstrate on experimental neuroscience data how the algorithm learns to link different data domains to the underlying dynamics </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('74','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_74" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://proceedings.mlr.press/v162/kramer22a.html" title="https://proceedings.mlr.press/v162/kramer22a.html" target="_blank">https://proceedings.mlr.press/v162/kramer22a.html</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('74','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2021">2021</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Thome, Janine;  Steinbach, Robert;  Grosskreutz, Julian;  Durstewitz, Daniel;  Koppe, Georgia</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('75','tp_links')" style="cursor:pointer;">Classification of amyotrophic lateral sclerosis by brain volume, connectivity, and network dynamics</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Human Brain Mapping, </span><span class="tp_pub_additional_year">2021</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_75" class="tp_show" onclick="teachpress_pub_showhide('75','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_75" class="tp_show" onclick="teachpress_pub_showhide('75','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_75" class="tp_show" onclick="teachpress_pub_showhide('75','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_75" style="display:none;"><div class="tp_bibtex_entry">@article{Thome2021,<br>
title = {Classification of amyotrophic lateral sclerosis by brain volume, connectivity, and network dynamics},<br>
author = {Janine Thome and Robert Steinbach and Julian Grosskreutz and Daniel Durstewitz and Georgia Koppe},<br>
url = {https://doi.org/10.1002/hbm.25679},<br>
year  = {2021},<br>
date = {2021-10-16},<br>
journal = {Human Brain Mapping},<br>
abstract = {Emerging studies corroborate the importance of neuroimaging biomarkers and machine learning to improve diagnostic classification of amyotrophic lateral sclerosis (ALS). While most studies focus on structural data, recent studies assessing functional connectivity between brain regions by linear methods highlight the role of brain function. These studies have yet to be combined with brain structure and nonlinear functional features. We investigate the role of linear and nonlinear functional brain features, and the benefit of combining brain structure and function for ALS classification. ALS patients (N = 97) and healthy controls (N = 59) underwent structural and functional resting state magnetic resonance imaging. Based on key hubs of resting state networks, we defined three feature sets comprising brain volume, resting state functional connectivity (rsFC), as well as (nonlinear) resting state dynamics assessed via recurrent neural networks. Unimodal and multimodal random forest classifiers were built to classify ALS. Out-of-sample prediction errors were assessed via five-fold cross-validation. Unimodal classifiers achieved a classification accuracy of 56.35–61.66%. Multimodal classifiers outperformed unimodal classifiers achieving accuracies of 62.85–66.82%. Evaluating the ranking of individual features' importance scores across all classifiers revealed that rsFC features were most dominant in classification. While univariate analyses revealed reduced rsFC in ALS patients, functional features more generally indicated deficits in information integration across resting state brain networks in ALS. The present work undermines that combining brain structure and function provides an additional benefit to diagnostic classification, as indicated by multimodal classifiers, while emphasizing the importance of capturing both linear and nonlinear functional brain properties to identify discriminative biomarkers of ALS.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('75','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_75" style="display:none;"><div class="tp_abstract_entry">Emerging studies corroborate the importance of neuroimaging biomarkers and machine learning to improve diagnostic classification of amyotrophic lateral sclerosis (ALS). While most studies focus on structural data, recent studies assessing functional connectivity between brain regions by linear methods highlight the role of brain function. These studies have yet to be combined with brain structure and nonlinear functional features. We investigate the role of linear and nonlinear functional brain features, and the benefit of combining brain structure and function for ALS classification. ALS patients (N = 97) and healthy controls (N = 59) underwent structural and functional resting state magnetic resonance imaging. Based on key hubs of resting state networks, we defined three feature sets comprising brain volume, resting state functional connectivity (rsFC), as well as (nonlinear) resting state dynamics assessed via recurrent neural networks. Unimodal and multimodal random forest classifiers were built to classify ALS. Out-of-sample prediction errors were assessed via five-fold cross-validation. Unimodal classifiers achieved a classification accuracy of 56.35–61.66%. Multimodal classifiers outperformed unimodal classifiers achieving accuracies of 62.85–66.82%. Evaluating the ranking of individual features' importance scores across all classifiers revealed that rsFC features were most dominant in classification. While univariate analyses revealed reduced rsFC in ALS patients, functional features more generally indicated deficits in information integration across resting state brain networks in ALS. The present work undermines that combining brain structure and function provides an additional benefit to diagnostic classification, as indicated by multimodal classifiers, while emphasizing the importance of capturing both linear and nonlinear functional brain properties to identify discriminative biomarkers of ALS.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('75','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_75" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1002/hbm.25679" title="https://doi.org/10.1002/hbm.25679" target="_blank">https://doi.org/10.1002/hbm.25679</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('75','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Monfared, Zahra;  Mikhaeil, Jonas M;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('73','tp_links')" style="cursor:pointer;">How to train RNNs on chaotic data?</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">arxiv, </span><span class="tp_pub_additional_year">2021</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_73" class="tp_show" onclick="teachpress_pub_showhide('73','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_73" class="tp_show" onclick="teachpress_pub_showhide('73','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_73" class="tp_show" onclick="teachpress_pub_showhide('73','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_73" style="display:none;"><div class="tp_bibtex_entry">@article{Monfared2021,<br>
title = {How to train RNNs on chaotic data?},<br>
author = {Zahra Monfared and Jonas M. Mikhaeil and Daniel Durstewitz},<br>
url = {https://arxiv.org/abs/2110.07238},<br>
year  = {2021},<br>
date = {2021-10-14},<br>
journal = {arxiv},<br>
abstract = {Recurrent neural networks (RNNs) are wide-spread machine learning tools for modeling sequential and time series data. They are notoriously hard to train because their loss gradients backpropagated in time tend to saturate or diverge during training. This is known as the exploding and vanishing gradient problem. Previous solutions to this issue either built on rather complicated, purpose-engineered architectures with gated memory buffers, or - more recently - imposed constraints that ensure convergence to a fixed point or restrict (the eigenspectrum of) the recurrence matrix. Such constraints, however, convey severe limitations on the expressivity of the RNN. Essential intrinsic dynamics such as multistability or chaos are disabled. This is inherently at disaccord with the chaotic nature of many, if not most, time series encountered in nature and society. Here we offer a comprehensive theoretical treatment of this problem by relating the loss gradients during RNN training to the Lyapunov spectrum of RNN-generated orbits. We mathematically prove that RNNs producing stable equilibrium or cyclic behavior have bounded gradients, whereas the gradients of RNNs with chaotic dynamics always diverge. Based on these analyses and insights, we offer an effective yet simple training technique for chaotic data and guidance on how to choose relevant hyperparameters according to the Lyapunov spectrum. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('73','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_73" style="display:none;"><div class="tp_abstract_entry">Recurrent neural networks (RNNs) are wide-spread machine learning tools for modeling sequential and time series data. They are notoriously hard to train because their loss gradients backpropagated in time tend to saturate or diverge during training. This is known as the exploding and vanishing gradient problem. Previous solutions to this issue either built on rather complicated, purpose-engineered architectures with gated memory buffers, or - more recently - imposed constraints that ensure convergence to a fixed point or restrict (the eigenspectrum of) the recurrence matrix. Such constraints, however, convey severe limitations on the expressivity of the RNN. Essential intrinsic dynamics such as multistability or chaos are disabled. This is inherently at disaccord with the chaotic nature of many, if not most, time series encountered in nature and society. Here we offer a comprehensive theoretical treatment of this problem by relating the loss gradients during RNN training to the Lyapunov spectrum of RNN-generated orbits. We mathematically prove that RNNs producing stable equilibrium or cyclic behavior have bounded gradients, whereas the gradients of RNNs with chaotic dynamics always diverge. Based on these analyses and insights, we offer an effective yet simple training technique for chaotic data and guidance on how to choose relevant hyperparameters according to the Lyapunov spectrum. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('73','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_73" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://arxiv.org/abs/2110.07238" title="https://arxiv.org/abs/2110.07238" target="_blank">https://arxiv.org/abs/2110.07238</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('73','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Russo, Eleonora;  Ma, Tianyang;  Spanagel, Rainer;  Durstewitz, Daniel;  Toutounji, Hazem;  Köhr, Georg</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('76','tp_links')" style="cursor:pointer;">Coordinated prefrontal state transition leads extinction of reward-seeking behaviors</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Journal of Neuroscience, </span><span class="tp_pub_additional_volume">41 </span><span class="tp_pub_additional_number">(11), </span><span class="tp_pub_additional_year">2021</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_76" class="tp_show" onclick="teachpress_pub_showhide('76','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_76" class="tp_show" onclick="teachpress_pub_showhide('76','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_76" class="tp_show" onclick="teachpress_pub_showhide('76','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_76" style="display:none;"><div class="tp_bibtex_entry">@article{Russo2021,<br>
title = {Coordinated prefrontal state transition leads extinction of reward-seeking behaviors},<br>
author = {Eleonora Russo and Tianyang Ma and Rainer Spanagel and Daniel Durstewitz and Hazem Toutounji and Georg Köhr},<br>
url = {https://www.jneurosci.org/content/jneuro/41/11/2406.full.pdf},<br>
year  = {2021},<br>
date = {2021-02-02},<br>
journal = {Journal of Neuroscience},<br>
volume = {41},<br>
number = {11},<br>
abstract = {Extinction learning suppresses conditioned reward responses and is thus fundamental to adapt to changing environmental<br>
demands and to control excessive reward seeking. The medial prefrontal cortex (mPFC) monitors and controls conditioned<br><br>
reward responses. Abrupt transitions in mPFC activity anticipate changes in conditioned responses to altered contingencies.<br>
It remains, however, unknown whether such transitions are driven by the extinction of old behavioral strategies or by the ac-<br>
quisition of new competing ones. Using in vivo multiple single-unit recordings of mPFC in male rats, we studied the relation-<br>
ship between single-unit and population dynamics during extinction learning, using alcohol as a positive reinforcer in an<br>
operant conditioning paradigm. To examine the fine temporal relation between neural activity and behavior, we developed a<br>
novel behavioral model that allowed us to identify the number, onset, and duration of extinction-learning episodes in the<br><br>
behavior of each animal. We found that single-unit responses to conditioned stimuli changed even under stable experimental<br>
conditions and behavior. However, when behavioral responses to task contingencies had to be updated, unit-specific modula-<br>
tions became coordinated across the whole population, pushing the network into a new stable attractor state. Thus, extinction<br><br>
learning is not associated with suppressed mPFC responses to conditioned stimuli, but is anticipated by single-unit coordina-<br>
tion into population-wide transitions of the internal state of the animal.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('76','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_76" style="display:none;"><div class="tp_abstract_entry">Extinction learning suppresses conditioned reward responses and is thus fundamental to adapt to changing environmental<br>
demands and to control excessive reward seeking. The medial prefrontal cortex (mPFC) monitors and controls conditioned<br><br>
reward responses. Abrupt transitions in mPFC activity anticipate changes in conditioned responses to altered contingencies.<br>
It remains, however, unknown whether such transitions are driven by the extinction of old behavioral strategies or by the ac-<br>
quisition of new competing ones. Using in vivo multiple single-unit recordings of mPFC in male rats, we studied the relation-<br>
ship between single-unit and population dynamics during extinction learning, using alcohol as a positive reinforcer in an<br>
operant conditioning paradigm. To examine the fine temporal relation between neural activity and behavior, we developed a<br>
novel behavioral model that allowed us to identify the number, onset, and duration of extinction-learning episodes in the<br><br>
behavior of each animal. We found that single-unit responses to conditioned stimuli changed even under stable experimental<br>
conditions and behavior. However, when behavioral responses to task contingencies had to be updated, unit-specific modula-<br>
tions became coordinated across the whole population, pushing the network into a new stable attractor state. Thus, extinction<br><br>
learning is not associated with suppressed mPFC responses to conditioned stimuli, but is anticipated by single-unit coordina-<br>
tion into population-wide transitions of the internal state of the animal.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('76','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_76" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="https://www.jneurosci.org/content/jneuro/41/11/2406.full.pdf" title="https://www.jneurosci.org/content/jneuro/41/11/2406.full.pdf" target="_blank">https://www.jneurosci.org/content/jneuro/41/11/2406.full.pdf</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('76','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2020">2020</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Georgia Koppe  Andreas Meyer-Lindenberg, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('69','tp_links')" style="cursor:pointer;">Deep learning for small and big data in psychiatry</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Neuropsychopharmacology, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_69" class="tp_show" onclick="teachpress_pub_showhide('69','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_69" class="tp_show" onclick="teachpress_pub_showhide('69','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_69" class="tp_show" onclick="teachpress_pub_showhide('69','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_69" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2020b,<br>
title = {Deep learning for small and big data in psychiatry},<br>
author = {Georgia Koppe, Andreas Meyer-Lindenberg, Daniel Durstewitz},<br>
url = {https://www.nature.com/articles/s41386-020-0767-z},<br>
doi = {10.1038/s41386-020-0767-z},<br>
year  = {2020},<br>
date = {2020-07-15},<br>
journal = {Neuropsychopharmacology},<br>
abstract = {Psychiatry today must gain a better understanding of the common and distinct pathophysiological mechanisms underlying psychiatric disorders in order to deliver more effective, person-tailored treatments. To this end, it appears that the analysis of ‘small’ experimental samples using conventional statistical approaches has largely failed to capture the heterogeneity underlying psychiatric phenotypes. Modern algorithms and approaches from machine learning, particularly deep learning, provide new hope to address these issues given their outstanding prediction performance in other disciplines. The strength of deep learning algorithms is that they can implement very complicated, and in principle arbitrary predictor-response mappings efficiently. This power comes at a cost, the need for large training (and test) samples to infer the (sometimes over millions of) model parameters. This appears to be at odds with the as yet rather ‘small’ samples available in psychiatric human research to date (n 
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('69','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_69" style="display:none;"><div class="tp_abstract_entry">Psychiatry today must gain a better understanding of the common and distinct pathophysiological mechanisms underlying psychiatric disorders in order to deliver more effective, person-tailored treatments. To this end, it appears that the analysis of ‘small’ experimental samples using conventional statistical approaches has largely failed to capture the heterogeneity underlying psychiatric phenotypes. Modern algorithms and approaches from machine learning, particularly deep learning, provide new hope to address these issues given their outstanding prediction performance in other disciplines. The strength of deep learning algorithms is that they can implement very complicated, and in principle arbitrary predictor-response mappings efficiently. This power comes at a cost, the need for large training (and test) samples to infer the (sometimes over millions of) model parameters. This appears to be at odds with the as yet rather ‘small’ samples available in psychiatric human research to date (n < 10,000), and the ambition of predicting treatment at the single subject level (n = 1). Here, we aim at giving a comprehensive overview on how we can yet use such models for prediction in psychiatry. We review how machine learning approaches compare to more traditional statistical hypothesis-driven approaches, how their complexity relates to the need of large sample sizes, and what we can do to optimally use these powerful techniques in psychiatric neuroscience.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('69','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_69" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.nature.com/articles/s41386-020-0767-z" title="https://www.nature.com/articles/s41386-020-0767-z" target="_blank">https://www.nature.com/articles/s41386-020-0767-z</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1038/s41386-020-0767-z" title="Follow DOI:10.1038/s41386-020-0767-z" target="_blank">doi:10.1038/s41386-020-0767-z</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('69','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Lars-Lennart Oettl  Max Scheller, Carla Filosa Sebastian Wieland Franziska Haag Cathrin Loeb Daniel Durstewitz Roman Shusterman Eleonora Russo & Wolfgang Kelsch </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('67','tp_links')" style="cursor:pointer;">Phasic dopamine reinforces distinct striatal stimulus encoding in the olfactory tubercle driving dopaminergic reward prediction</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Nature Communications, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_67" class="tp_show" onclick="teachpress_pub_showhide('67','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_67" class="tp_show" onclick="teachpress_pub_showhide('67','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_67" class="tp_show" onclick="teachpress_pub_showhide('67','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_67" style="display:none;"><div class="tp_bibtex_entry">@article{Oettl2020,<br>
title = {Phasic dopamine reinforces distinct striatal stimulus encoding in the olfactory tubercle driving dopaminergic reward prediction},<br>
author = {Lars-Lennart Oettl, Max Scheller, Carla Filosa, Sebastian Wieland, Franziska Haag, Cathrin Loeb, Daniel Durstewitz, Roman Shusterman, Eleonora Russo & Wolfgang Kelsch},<br>
url = {https://www.nature.com/articles/s41467-020-17257-7#disqus_thread},<br>
doi = {https://doi.org/10.1038/s41467-020-17257-7},<br>
year  = {2020},<br>
date = {2020-07-10},<br>
journal = {Nature Communications},<br>
abstract = {The learning of stimulus-outcome associations allows for predictions about the environment. Ventral striatum and dopaminergic midbrain neurons form a larger network for generating reward prediction signals from sensory cues. Yet, the network plasticity mechanisms to generate predictive signals in these distributed circuits have not been entirely clarified. Also, direct evidence of the underlying interregional assembly formation and information transfer is still missing. Here we show that phasic dopamine is sufficient to reinforce the distinctness of stimulus representations in the ventral striatum even in the absence of reward. Upon such reinforcement, striatal stimulus encoding gives rise to interregional assemblies that drive dopaminergic neurons during stimulus-outcome learning. These assemblies dynamically encode the predicted reward value of conditioned stimuli. Together, our data reveal that ventral striatal and midbrain reward networks form a reinforcing loop to generate reward prediction coding.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('67','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_67" style="display:none;"><div class="tp_abstract_entry">The learning of stimulus-outcome associations allows for predictions about the environment. Ventral striatum and dopaminergic midbrain neurons form a larger network for generating reward prediction signals from sensory cues. Yet, the network plasticity mechanisms to generate predictive signals in these distributed circuits have not been entirely clarified. Also, direct evidence of the underlying interregional assembly formation and information transfer is still missing. Here we show that phasic dopamine is sufficient to reinforce the distinctness of stimulus representations in the ventral striatum even in the absence of reward. Upon such reinforcement, striatal stimulus encoding gives rise to interregional assemblies that drive dopaminergic neurons during stimulus-outcome learning. These assemblies dynamically encode the predicted reward value of conditioned stimuli. Together, our data reveal that ventral striatal and midbrain reward networks form a reinforcing loop to generate reward prediction coding.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('67','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_67" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.nature.com/articles/s41467-020-17257-7#disqus_thread" title="https://www.nature.com/articles/s41467-020-17257-7#disqus_thread" target="_blank">https://www.nature.com/articles/s41467-020-17257-7#disqus_thread</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1038/s41467-020-17257-7" title="Follow DOI:https://doi.org/10.1038/s41467-020-17257-7" target="_blank">doi:https://doi.org/10.1038/s41467-020-17257-7</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('67','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Lars-Lennart Oettl  Max Scheller, Carla Filosa Sebastian Wieland Franziska Haag Cathrin Loeb Daniel Durstewitz Roman Shusterman Eleonora Russo Wolfgang Kelsch </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('70','tp_links')" style="cursor:pointer;">Phasic dopamine reinforces distinct striatal stimulus encoding in the olfactory tubercle driving dopaminergic reward prediction</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Nature Communications, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_70" class="tp_show" onclick="teachpress_pub_showhide('70','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_70" class="tp_show" onclick="teachpress_pub_showhide('70','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_70" class="tp_show" onclick="teachpress_pub_showhide('70','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_70" style="display:none;"><div class="tp_bibtex_entry">@article{Oettl2020b,<br>
title = {Phasic dopamine reinforces distinct striatal stimulus encoding in the olfactory tubercle driving dopaminergic reward prediction},<br>
author = {Lars-Lennart Oettl, Max Scheller, Carla Filosa, Sebastian Wieland, Franziska Haag, Cathrin Loeb, Daniel Durstewitz, Roman Shusterman, Eleonora Russo, Wolfgang Kelsch},<br>
url = {https://www.nature.com/articles/s41467-020-17257-7#citeas},<br>
doi = {https://doi.org/10.1038/s41467-020-17257-7},<br>
year  = {2020},<br>
date = {2020-07-10},<br>
journal = {Nature Communications},<br>
abstract = {The learning of stimulus-outcome associations allows for predictions about the environment. Ventral striatum and dopaminergic midbrain neurons form a larger network for generating reward prediction signals from sensory cues. Yet, the network plasticity mechanisms to generate predictive signals in these distributed circuits have not been entirely clarified. Also, direct evidence of the underlying interregional assembly formation and information transfer is still missing. Here we show that phasic dopamine is sufficient to reinforce the distinctness of stimulus representations in the ventral striatum even in the absence of reward. Upon such reinforcement, striatal stimulus encoding gives rise to interregional assemblies that drive dopaminergic neurons during stimulus-outcome learning. These assemblies dynamically encode the predicted reward value of conditioned stimuli. Together, our data reveal that ventral striatal and midbrain reward networks form a reinforcing loop to generate reward prediction coding.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('70','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_70" style="display:none;"><div class="tp_abstract_entry">The learning of stimulus-outcome associations allows for predictions about the environment. Ventral striatum and dopaminergic midbrain neurons form a larger network for generating reward prediction signals from sensory cues. Yet, the network plasticity mechanisms to generate predictive signals in these distributed circuits have not been entirely clarified. Also, direct evidence of the underlying interregional assembly formation and information transfer is still missing. Here we show that phasic dopamine is sufficient to reinforce the distinctness of stimulus representations in the ventral striatum even in the absence of reward. Upon such reinforcement, striatal stimulus encoding gives rise to interregional assemblies that drive dopaminergic neurons during stimulus-outcome learning. These assemblies dynamically encode the predicted reward value of conditioned stimuli. Together, our data reveal that ventral striatal and midbrain reward networks form a reinforcing loop to generate reward prediction coding.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('70','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_70" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.nature.com/articles/s41467-020-17257-7#citeas" title="https://www.nature.com/articles/s41467-020-17257-7#citeas" target="_blank">https://www.nature.com/articles/s41467-020-17257-7#citeas</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1038/s41467-020-17257-7" title="Follow DOI:https://doi.org/10.1038/s41467-020-17257-7" target="_blank">doi:https://doi.org/10.1038/s41467-020-17257-7</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('70','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Zahra Monfared, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('66','tp_links')" style="cursor:pointer;">Existence of n-cycles and border-collision bifurcations in piecewise-linear continuous maps with applications to recurrent neural networks</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Nonlinear Dynamics, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_66" class="tp_show" onclick="teachpress_pub_showhide('66','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_66" class="tp_show" onclick="teachpress_pub_showhide('66','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_66" class="tp_show" onclick="teachpress_pub_showhide('66','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_66" style="display:none;"><div class="tp_bibtex_entry">@article{Monfared2020,<br>
title = {Existence of n-cycles and border-collision bifurcations in piecewise-linear continuous maps with applications to recurrent neural networks},<br>
author = {Zahra Monfared, Daniel Durstewitz},<br>
url = {https://arxiv.org/abs/1911.04304},<br>
doi = {10.1007/s11071-020-05777-2},<br>
year  = {2020},<br>
date = {2020-07-01},<br>
journal = {Nonlinear Dynamics},<br>
abstract = {Piecewise linear recurrent neural networks (PLRNNs) form the basis of many successful machine learning applications for time series prediction and dynamical systems identification, but rigorous mathematical analysis of their dynamics and properties is lagging behind. Here we contribute to this topic by investigating the existence of n-cycles (n≥3) and border-collision bifurcations in a class of n-dimensional piecewise linear continuous maps which have the general form of a PLRNN. This is particularly important as for one-dimensional maps the existence of 3-cycles implies chaos. It is shown that these n-cycles collide with the switching boundary in a border-collision bifurcation, and parametric regions for the existence of both stable and unstable n-cycles and border-collision bifurcations will be derived theoretically. We then discuss how our results can be extended and applied to PLRNNs. Finally, numerical simulations demonstrate the implementation of our results and are found to be in good agreement with the theoretical derivations. Our findings thus provide a basis for understanding periodic behavior in PLRNNs, how it emerges in bifurcations, and how it may lead into chaos. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('66','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_66" style="display:none;"><div class="tp_abstract_entry">Piecewise linear recurrent neural networks (PLRNNs) form the basis of many successful machine learning applications for time series prediction and dynamical systems identification, but rigorous mathematical analysis of their dynamics and properties is lagging behind. Here we contribute to this topic by investigating the existence of n-cycles (n≥3) and border-collision bifurcations in a class of n-dimensional piecewise linear continuous maps which have the general form of a PLRNN. This is particularly important as for one-dimensional maps the existence of 3-cycles implies chaos. It is shown that these n-cycles collide with the switching boundary in a border-collision bifurcation, and parametric regions for the existence of both stable and unstable n-cycles and border-collision bifurcations will be derived theoretically. We then discuss how our results can be extended and applied to PLRNNs. Finally, numerical simulations demonstrate the implementation of our results and are found to be in good agreement with the theoretical derivations. Our findings thus provide a basis for understanding periodic behavior in PLRNNs, how it emerges in bifurcations, and how it may lead into chaos. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('66','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_66" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://arxiv.org/abs/1911.04304" title="https://arxiv.org/abs/1911.04304" target="_blank">https://arxiv.org/abs/1911.04304</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1007/s11071-020-05777-2" title="Follow DOI:10.1007/s11071-020-05777-2" target="_blank">doi:10.1007/s11071-020-05777-2</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('66','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Zahra Monfared, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('68','tp_links')" style="cursor:pointer;">Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Proceedings of the International Conference on Machine Learning, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_68" class="tp_show" onclick="teachpress_pub_showhide('68','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_68" class="tp_show" onclick="teachpress_pub_showhide('68','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_68" class="tp_show" onclick="teachpress_pub_showhide('68','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_68" style="display:none;"><div class="tp_bibtex_entry">@article{Monfared2020b,<br>
title = {Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time},<br>
author = {Zahra Monfared, Daniel Durstewitz},<br>
url = {https://arxiv.org/abs/2007.00321},<br>
year  = {2020},<br>
date = {2020-07-01},<br>
journal = {Proceedings of the International Conference on Machine Learning},<br>
abstract = {Recurrent neural networks (RNN) as used in machine learning are commonly formulated in discrete time, i.e. as recursive maps. This brings a lot of advantages for training models on data, e.g. for the purpose of time series prediction or dynamical systems identification, as powerful and efficient inference algorithms exist for discrete time systems and numerical integration of differential equations is not necessary. On the other hand, mathematical analysis of dynamical systems inferred from data is often more convenient and enables additional insights if these are formulated in continuous time, i.e. as systems of ordinary (or partial) differential equations (ODE). Here we show how to perform such a translation from discrete to continuous time for a particular class of ReLU-based RNN. We prove three theorems on the mathematical equivalence between the discrete and continuous time formulations under a variety of conditions, and illustrate how to use our mathematical results on different machine learning and nonlinear dynamical systems examples. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('68','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_68" style="display:none;"><div class="tp_abstract_entry">Recurrent neural networks (RNN) as used in machine learning are commonly formulated in discrete time, i.e. as recursive maps. This brings a lot of advantages for training models on data, e.g. for the purpose of time series prediction or dynamical systems identification, as powerful and efficient inference algorithms exist for discrete time systems and numerical integration of differential equations is not necessary. On the other hand, mathematical analysis of dynamical systems inferred from data is often more convenient and enables additional insights if these are formulated in continuous time, i.e. as systems of ordinary (or partial) differential equations (ODE). Here we show how to perform such a translation from discrete to continuous time for a particular class of ReLU-based RNN. We prove three theorems on the mathematical equivalence between the discrete and continuous time formulations under a variety of conditions, and illustrate how to use our mathematical results on different machine learning and nonlinear dynamical systems examples. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('68','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_68" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://arxiv.org/abs/2007.00321" title="https://arxiv.org/abs/2007.00321" target="_blank">https://arxiv.org/abs/2007.00321</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('68','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Linke, Julia;  Koppe, Georgia;  Scholz, Vanessa;  Kanske, Philipp;  Durstewitz, Daniel;  Wessa, Michèle</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('71','tp_links')" style="cursor:pointer;">Aberrant probabilistic reinforcement learning in first-degree relatives of individuals with bipolar disorder</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Journal of Affective Disorders, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_71" class="tp_show" onclick="teachpress_pub_showhide('71','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_71" class="tp_show" onclick="teachpress_pub_showhide('71','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_71" class="tp_show" onclick="teachpress_pub_showhide('71','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_71" style="display:none;"><div class="tp_bibtex_entry">@article{Linke2020,<br>
title = {Aberrant probabilistic reinforcement learning in first-degree relatives of individuals with bipolar disorder},<br>
author = {Julia Linke and Georgia Koppe and Vanessa Scholz and Philipp Kanske and Daniel Durstewitz and Michèle Wessa},<br>
url = {https://doi.org/10.1016/j.jad.2019.11.063},<br>
doi = {10.1016/j.jad.2019.11.063},<br>
year  = {2020},<br>
date = {2020-03-01},<br>
journal = {Journal of Affective Disorders},<br>
abstract = {Motivational dysregulation represents a core vulnerability factor for bipolar disorder. Whether this also comprises aberrant learning of stimulus-reinforcer contingencies is less clear.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('71','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_71" style="display:none;"><div class="tp_abstract_entry">Motivational dysregulation represents a core vulnerability factor for bipolar disorder. Whether this also comprises aberrant learning of stimulus-reinforcer contingencies is less clear.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('71','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_71" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1016/j.jad.2019.11.063" title="https://doi.org/10.1016/j.jad.2019.11.063" target="_blank">https://doi.org/10.1016/j.jad.2019.11.063</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1016/j.jad.2019.11.063" title="Follow DOI:10.1016/j.jad.2019.11.063" target="_blank">doi:10.1016/j.jad.2019.11.063</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('71','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Eleonora Russo  Tianyang Ma, Rainer Spanagel Daniel Durstewitz Hazem Toutounji Georg Köhr </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('29','tp_links')" style="cursor:pointer;">Coordinated prefrontal state transition leads extinction of reward-seeking behaviors</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">biorxiv, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_29" class="tp_show" onclick="teachpress_pub_showhide('29','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_29" class="tp_show" onclick="teachpress_pub_showhide('29','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_29" class="tp_show" onclick="teachpress_pub_showhide('29','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_29" style="display:none;"><div class="tp_bibtex_entry">@article{Russo2020,<br>
title = {Coordinated prefrontal state transition leads extinction of reward-seeking behaviors},<br>
author = {Eleonora Russo, Tianyang Ma, Rainer Spanagel, Daniel Durstewitz, Hazem Toutounji, Georg Köhr},<br>
url = {https://www.biorxiv.org/content/10.1101/2020.02.26.964510v1.full},<br>
doi = {https://doi.org/10.1101/2020.02.26.964510},<br>
year  = {2020},<br>
date = {2020-02-27},<br>
journal = {biorxiv},<br>
abstract = {Extinction learning suppresses conditioned reward responses and is thus fundamental to adapt to changing environmental demands and to control excessive reward seeking. The medial prefrontal cortex (mPFC) monitors and controls conditioned reward responses. Using in vivo multiple single-unit recordings of mPFC we studied the relationship between single-unit and population dynamics during different phases of an operant conditioning task. To examine the fine temporal relation between neural activity and behavior, we developed a model-based statistical analysis that captured behavioral idiosyncrasies. We found that single-unit responses to conditioned stimuli changed throughout the course of a session even under stable experimental conditions and consistent behavior. However, when behavioral responses to task contingencies had to be updated during the extinction phase, unit-specific modulations became coordinated across the whole population, pushing the network into a new stable attractor state. These results show that extinction learning is not associated with suppressed mPFC responses to conditioned stimuli, but is driven by single-unit coordination into population-wide transitions of the animal’s internal state.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('29','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_29" style="display:none;"><div class="tp_abstract_entry">Extinction learning suppresses conditioned reward responses and is thus fundamental to adapt to changing environmental demands and to control excessive reward seeking. The medial prefrontal cortex (mPFC) monitors and controls conditioned reward responses. Using in vivo multiple single-unit recordings of mPFC we studied the relationship between single-unit and population dynamics during different phases of an operant conditioning task. To examine the fine temporal relation between neural activity and behavior, we developed a model-based statistical analysis that captured behavioral idiosyncrasies. We found that single-unit responses to conditioned stimuli changed throughout the course of a session even under stable experimental conditions and consistent behavior. However, when behavioral responses to task contingencies had to be updated during the extinction phase, unit-specific modulations became coordinated across the whole population, pushing the network into a new stable attractor state. These results show that extinction learning is not associated with suppressed mPFC responses to conditioned stimuli, but is driven by single-unit coordination into population-wide transitions of the animal’s internal state.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('29','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_29" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.biorxiv.org/content/10.1101/2020.02.26.964510v1.full" title="https://www.biorxiv.org/content/10.1101/2020.02.26.964510v1.full" target="_blank">https://www.biorxiv.org/content/10.1101/2020.02.26.964510v1.full</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1101/2020.02.26.964510" title="Follow DOI:https://doi.org/10.1101/2020.02.26.964510" target="_blank">doi:https://doi.org/10.1101/2020.02.26.964510</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('29','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Georgia Koppe  Quentin Huys, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('38','tp_links')" style="cursor:pointer;">Psychiatric Illnesses as Disorders of Network Dynamics</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Biological Psychiatry, </span><span class="tp_pub_additional_year">2020</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_38" class="tp_show" onclick="teachpress_pub_showhide('38','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_38" class="tp_show" onclick="teachpress_pub_showhide('38','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_38" class="tp_show" onclick="teachpress_pub_showhide('38','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_38" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2020,<br>
title = {Psychiatric Illnesses as Disorders of Network Dynamics},<br>
author = {Georgia Koppe, Quentin Huys, Daniel Durstewitz},<br>
url = {https://www.biologicalpsychiatrycnni.org/article/S2451902220300197/abstract},<br>
year  = {2020},<br>
date = {2020-01-16},<br>
journal = {Biological Psychiatry},<br>
abstract = {This review provides a dynamical systems perspective on mental illness. After a brief introduction to the theory of dynamical systems, we focus on the common assumption in theoretical and computational neuroscience that phenomena at subcellular, cellular, network, cognitive, and even societal levels could be described and explained in terms of dynamical systems theory. As such, dynamical systems theory may also provide a framework for understanding mental illnesses. The review examines a number of core dynamical systems phenomena and relates each of these to aspects of mental illnesses. This provides an outline of how a broad set of phenomena in serious and common mental illnesses and neurological conditions can be understood in dynamical systems terms. It suggests that the dynamical systems level may provide a central, hublike level of convergence that unifies and links multiple biophysical and behavioral phenomena in the sense that diverse biophysical changes can give rise to the same dynamical phenomena and, vice versa, similar changes in dynamics may yield different behavioral symptoms depending on the brain area where these changes manifest. We also briefly outline current methodological approaches for inferring dynamical systems from data such as electroencephalography, functional magnetic resonance imaging, or self-reports, and we discuss the implications of a dynamical view for the diagnosis, prognosis, and treatment of psychiatric conditions. We argue that a consideration of dynamics could play a potentially transformative role in the choice and target of interventions. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('38','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_38" style="display:none;"><div class="tp_abstract_entry">This review provides a dynamical systems perspective on mental illness. After a brief introduction to the theory of dynamical systems, we focus on the common assumption in theoretical and computational neuroscience that phenomena at subcellular, cellular, network, cognitive, and even societal levels could be described and explained in terms of dynamical systems theory. As such, dynamical systems theory may also provide a framework for understanding mental illnesses. The review examines a number of core dynamical systems phenomena and relates each of these to aspects of mental illnesses. This provides an outline of how a broad set of phenomena in serious and common mental illnesses and neurological conditions can be understood in dynamical systems terms. It suggests that the dynamical systems level may provide a central, hublike level of convergence that unifies and links multiple biophysical and behavioral phenomena in the sense that diverse biophysical changes can give rise to the same dynamical phenomena and, vice versa, similar changes in dynamics may yield different behavioral symptoms depending on the brain area where these changes manifest. We also briefly outline current methodological approaches for inferring dynamical systems from data such as electroencephalography, functional magnetic resonance imaging, or self-reports, and we discuss the implications of a dynamical view for the diagnosis, prognosis, and treatment of psychiatric conditions. We argue that a consideration of dynamics could play a potentially transformative role in the choice and target of interventions. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('38','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_38" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.biologicalpsychiatrycnni.org/article/S2451902220300197/abstract" title="https://www.biologicalpsychiatrycnni.org/article/S2451902220300197/abstract" target="_blank">https://www.biologicalpsychiatrycnni.org/article/S2451902220300197/abstract</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('38','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2019">2019</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Schmidt, Dominik;  Koppe, Georgia;  Beutelspacher, Max;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('26','tp_links')" style="cursor:pointer;">Inferring Dynamical Systems with Long-Range Dependencies through Line Attractor Regularization</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_year">2019</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_26" class="tp_show" onclick="teachpress_pub_showhide('26','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_26" class="tp_show" onclick="teachpress_pub_showhide('26','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_26" class="tp_show" onclick="teachpress_pub_showhide('26','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_26" style="display:none;"><div class="tp_bibtex_entry">@article{Schmidt2019,<br>
title = {Inferring Dynamical Systems with Long-Range Dependencies through Line Attractor Regularization},<br>
author = {Dominik Schmidt and Georgia Koppe and Max Beutelspacher and Daniel Durstewitz},<br>
url = {http://arxiv.org/abs/1910.03471},<br>
year  = {2019},<br>
date = {2019-10-01},<br>
abstract = {Vanilla RNN with ReLU activation have a simple structure that is amenable to systematic dynamical systems analysis and interpretation, but they suffer from the exploding vs. vanishing gradients problem. Recent attempts to retain this simplicity while alleviating the gradient problem are based on proper initialization schemes or orthogonality/unitary constraints on the RNN's recurrence matrix, which, however, comes with limitations to its expressive power with regards to dynamical systems phenomena like chaos or multi-stability. Here, we instead suggest a regularization scheme that pushes part of the RNN's latent subspace toward a line attractor configuration that enables long short-term memory and arbitrarily slow time scales. We show that our approach excels on a number of benchmarks like the sequential MNIST or multiplication problems, and enables reconstruction of dynamical systems which harbor widely different time scales.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('26','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_26" style="display:none;"><div class="tp_abstract_entry">Vanilla RNN with ReLU activation have a simple structure that is amenable to systematic dynamical systems analysis and interpretation, but they suffer from the exploding vs. vanishing gradients problem. Recent attempts to retain this simplicity while alleviating the gradient problem are based on proper initialization schemes or orthogonality/unitary constraints on the RNN's recurrence matrix, which, however, comes with limitations to its expressive power with regards to dynamical systems phenomena like chaos or multi-stability. Here, we instead suggest a regularization scheme that pushes part of the RNN's latent subspace toward a line attractor configuration that enables long short-term memory and arbitrarily slow time scales. We show that our approach excels on a number of benchmarks like the sequential MNIST or multiplication problems, and enables reconstruction of dynamical systems which harbor widely different time scales.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('26','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_26" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://arxiv.org/abs/1910.03471" title="http://arxiv.org/abs/1910.03471" target="_blank">http://arxiv.org/abs/1910.03471</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('26','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Lars-Lennart Oettl  Max Scheller, Sebastian Wieland Franziska Haag David Wolf Cathrin Loeb Namasivayam Ravi Daniel Durstewitz Roman Shusterman Eleonora Russo Wolfgang Kelsch </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('30','tp_links')" style="cursor:pointer;">Phasic dopamine enhances the distinct decoding and perceived salience of stimuli</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">bioRxiv, </span><span class="tp_pub_additional_year">2019</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_30" class="tp_show" onclick="teachpress_pub_showhide('30','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_30" class="tp_show" onclick="teachpress_pub_showhide('30','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_30" class="tp_show" onclick="teachpress_pub_showhide('30','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_30" style="display:none;"><div class="tp_bibtex_entry">@article{Oettl2019,<br>
title = {Phasic dopamine enhances the distinct decoding and perceived salience of stimuli},<br>
author = {Lars-Lennart Oettl, Max Scheller, Sebastian Wieland, Franziska Haag, David Wolf, Cathrin Loeb, Namasivayam Ravi, Daniel Durstewitz, Roman Shusterman, Eleonora Russo, Wolfgang Kelsch},<br>
url = {https://www.biorxiv.org/content/10.1101/771162v1},<br>
doi = {https://doi.org/10.1101/771162 },<br>
year  = {2019},<br>
date = {2019-09-18},<br>
journal = {bioRxiv},<br>
abstract = {Subjects learn to assign value to stimuli that predict outcomes. Novelty, rewards or punishment evoke reinforcing phasic dopamine release from midbrain neurons to ventral striatum that mediates expected value and salience of stimuli in humans and animals. It is however not clear whether phasic dopamine release is sufficient to form distinct engrams that encode salient stimuli within these circuits. We addressed this question in awake mice. Evoked phasic dopamine induced plasticity selectively to the population encoding of coincidently presented stimuli and increased their distinctness from other stimuli. Phasic dopamine thereby enhanced the decoding of previously paired stimuli and increased their perceived salience. This dopamine-induced plasticity mimicked population coding dynamics of conditioned stimuli during reinforcement learning. These findings provide a network coding mechanism of how dopaminergic learning signals promote value assignment to stimulus representations.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('30','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_30" style="display:none;"><div class="tp_abstract_entry">Subjects learn to assign value to stimuli that predict outcomes. Novelty, rewards or punishment evoke reinforcing phasic dopamine release from midbrain neurons to ventral striatum that mediates expected value and salience of stimuli in humans and animals. It is however not clear whether phasic dopamine release is sufficient to form distinct engrams that encode salient stimuli within these circuits. We addressed this question in awake mice. Evoked phasic dopamine induced plasticity selectively to the population encoding of coincidently presented stimuli and increased their distinctness from other stimuli. Phasic dopamine thereby enhanced the decoding of previously paired stimuli and increased their perceived salience. This dopamine-induced plasticity mimicked population coding dynamics of conditioned stimuli during reinforcement learning. These findings provide a network coding mechanism of how dopaminergic learning signals promote value assignment to stimulus representations.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('30','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_30" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.biorxiv.org/content/10.1101/771162v1" title="https://www.biorxiv.org/content/10.1101/771162v1" target="_blank">https://www.biorxiv.org/content/10.1101/771162v1</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1101/771162%20" title="Follow DOI:https://doi.org/10.1101/771162 " target="_blank">doi:https://doi.org/10.1101/771162 </a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('30','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Koppe, Georgia;  Toutounji, Hazem;  Kirsch, Peter;  Lis, Stefanie;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('11','tp_links')" style="cursor:pointer;">Identifying nonlinear dynamical systems via generative recurrent neural networks with applications to fMRI</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLOS Computational Biology, </span><span class="tp_pub_additional_volume">15 </span><span class="tp_pub_additional_number">(8), </span><span class="tp_pub_additional_pages">pp. e1007263, </span><span class="tp_pub_additional_year">2019</span>, <span class="tp_pub_additional_issn">ISSN: 1553-7358</span>.</p><p class="tp_pub_tags"><span class="tp_resource_link"><a id="tp_links_sh_11" class="tp_show" onclick="teachpress_pub_showhide('11','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_11" class="tp_show" onclick="teachpress_pub_showhide('11','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_11" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2019,<br>
title = {Identifying nonlinear dynamical systems via generative recurrent neural networks with applications to fMRI},<br>
author = {Georgia Koppe and Hazem Toutounji and Peter Kirsch and Stefanie Lis and Daniel Durstewitz},<br>
editor = {Leyla Isik},<br>
url = {http://dx.plos.org/10.1371/journal.pcbi.1007263},<br>
doi = {10.1371/journal.pcbi.1007263},<br>
issn = {1553-7358},<br>
year  = {2019},<br>
date = {2019-08-01},<br>
journal = {PLOS Computational Biology},<br>
volume = {15},<br>
number = {8},<br>
pages = {e1007263},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('11','tp_bibtex')">Close</a></p></div><div class="tp_links" id="tp_links_11" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://dx.plos.org/10.1371/journal.pcbi.1007263" title="http://dx.plos.org/10.1371/journal.pcbi.1007263" target="_blank">http://dx.plos.org/10.1371/journal.pcbi.1007263</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pcbi.1007263" title="Follow DOI:10.1371/journal.pcbi.1007263" target="_blank">doi:10.1371/journal.pcbi.1007263</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('11','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Urs Braun  Anais Harneit, Giulio Pergola Tommaso Menara Axel Schaefer Richard Betzel Zhenxiang Zang Janina Schweiger Kristina Schwarz Junfang Chen Giuseppe Blasi Alessandro Bertolino Daniel Durstewitz Fabio Pasqualetti Emanuel Schwarz Andreas Meyer-Lindenberg Danielle Bassett Heike Tost F   I          S</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('72','tp_links')" style="cursor:pointer;">Brain state stability during working memory is explained by network control theory, modulated by dopamine D1/D2 receptor function, and diminished in schizophrenia</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Arxiv Preprint, </span><span class="tp_pub_additional_year">2019</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_72" class="tp_show" onclick="teachpress_pub_showhide('72','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_72" class="tp_show" onclick="teachpress_pub_showhide('72','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_72" class="tp_show" onclick="teachpress_pub_showhide('72','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_72" style="display:none;"><div class="tp_bibtex_entry">@article{Braun2019,<br>
title = {Brain state stability during working memory is explained by network control theory, modulated by dopamine D1/D2 receptor function, and diminished in schizophrenia},<br>
author = {Urs Braun, Anais Harneit, Giulio Pergola, Tommaso Menara, Axel Schaefer, Richard F Betzel, Zhenxiang Zang, Janina I Schweiger, Kristina Schwarz, Junfang Chen, Giuseppe Blasi, Alessandro Bertolino, Daniel Durstewitz, Fabio Pasqualetti, Emanuel Schwarz, Andreas Meyer-Lindenberg, Danielle S Bassett, Heike Tost},<br>
url = {https://arxiv.org/ftp/arxiv/papers/1906/1906.09290.pdf},<br>
doi = {arXiv:1906.09290},<br>
year  = {2019},<br>
date = {2019-06-21},<br>
journal = {Arxiv Preprint},<br>
abstract = {Dynamical brain state transitions are critical for flexible working memory but the network mechanisms are incompletely understood. Here, we show that working memory entails brainwide switching between activity states. The stability of states relates to dopamine D1 receptor gene expression while state transitions are influenced by D2 receptor expression and pharmacological modulation. Schizophrenia patients show altered network control properties, including a more diverse energy landscape and decreased stability of working memory representations.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('72','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_72" style="display:none;"><div class="tp_abstract_entry">Dynamical brain state transitions are critical for flexible working memory but the network mechanisms are incompletely understood. Here, we show that working memory entails brainwide switching between activity states. The stability of states relates to dopamine D1 receptor gene expression while state transitions are influenced by D2 receptor expression and pharmacological modulation. Schizophrenia patients show altered network control properties, including a more diverse energy landscape and decreased stability of working memory representations.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('72','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_72" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="https://arxiv.org/ftp/arxiv/papers/1906/1906.09290.pdf" title="https://arxiv.org/ftp/arxiv/papers/1906/1906.09290.pdf" target="_blank">https://arxiv.org/ftp/arxiv/papers/1906/1906.09290.pdf</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/arXiv:1906.09290" title="Follow DOI:arXiv:1906.09290" target="_blank">doi:arXiv:1906.09290</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('72','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Elke Kirschbaum  Manuel Haußmann, Steffen Wolf Hannah Sonntag Justus Schneider Shehabeldin Elzoheiry Oliver Kann Daniel Durstewitz Fred Hamprecht A</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('39','tp_links')" style="cursor:pointer;">LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos</a> <span class="tp_pub_type conference">Conference</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_publisher">ICLR. Proceedings, </span><span class="tp_pub_additional_year">2019</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_39" class="tp_show" onclick="teachpress_pub_showhide('39','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_39" class="tp_show" onclick="teachpress_pub_showhide('39','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_39" class="tp_show" onclick="teachpress_pub_showhide('39','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_39" style="display:none;"><div class="tp_bibtex_entry">@conference{Kirschbaum2019,<br>
title = {LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},<br>
author = {Elke Kirschbaum, Manuel Haußmann, Steffen Wolf, Hannah Sonntag, Justus Schneider, Shehabeldin Elzoheiry, Oliver Kann, Daniel Durstewitz, Fred A. Hamprecht},<br>
url = {https://arxiv.org/abs/1806.09963},<br>
year  = {2019},<br>
date = {2019-02-22},<br>
publisher = {ICLR. Proceedings},<br>
abstract = {Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or "motifs", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {conference}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('39','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_39" style="display:none;"><div class="tp_abstract_entry">Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or "motifs", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('39','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_39" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://arxiv.org/abs/1806.09963" title="https://arxiv.org/abs/1806.09963" target="_blank">https://arxiv.org/abs/1806.09963</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('39','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Koppe, Georgia;  Guloksuz, Sinan;  Reininghaus, Ulrich;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('15','tp_links')" style="cursor:pointer;">Recurrent Neural Networks in Mobile Sampling and Intervention</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Schizophrenia Bulletin, </span><span class="tp_pub_additional_volume">45 </span><span class="tp_pub_additional_number">(2), </span><span class="tp_pub_additional_pages">pp. 272–276, </span><span class="tp_pub_additional_year">2019</span>, <span class="tp_pub_additional_issn">ISSN: 17451701</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_15" class="tp_show" onclick="teachpress_pub_showhide('15','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_15" class="tp_show" onclick="teachpress_pub_showhide('15','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_15" class="tp_show" onclick="teachpress_pub_showhide('15','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_15" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2019b,<br>
title = {Recurrent Neural Networks in Mobile Sampling and Intervention},<br>
author = {Georgia Koppe and Sinan Guloksuz and Ulrich Reininghaus and Daniel Durstewitz},<br>
doi = {10.1093/schbul/sby171},<br>
issn = {17451701},<br>
year  = {2019},<br>
date = {2019-01-01},<br>
journal = {Schizophrenia Bulletin},<br>
volume = {45},<br>
number = {2},<br>
pages = {272--276},<br>
abstract = {The rapid rise and now widespread distribution of handheld and wearable devices, such as smartphones, fitness trackers, or smartwatches, has opened a new universe of possibilities for monitoring emotion and cognition in everyday-life context, and for applying experience- and context-specific interventions in psychosis. These devices are equipped with multiple sensors, recording channels, and app-based opportunities for assessment using experience sampling methodology (ESM), which enables to collect vast amounts of temporally highly resolved and ecologically valid personal data from various domains in daily life. In psychosis, this allows to elucidate intermediate and clinical phenotypes, psychological processes and mechanisms, and their interplay with socioenvironmental factors, as well as to evaluate the effects of treatments for psychosis on important clinical and social outcomes. Although these data offer immense opportunities, they also pose tremendous challenges for data analysis. These challenges include the sheer amount of time series data generated and the many different data modalities and their specific properties and sampling rates. After a brief review of studies and approaches to ESM and ecological momentary interventions in psychosis, we will discuss recurrent neural networks (RNNs) as a powerful statistical machine learning approach for time series analysis and prediction in this context. RNNs can be trained on multiple data modalities simultaneously to learn a dynamical model that could be used to forecast individual trajectories and schedule online feedback and intervention accordingly. Future research using this approach is likely going to offer new avenues to further our understanding and treatments of psychosis.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('15','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_15" style="display:none;"><div class="tp_abstract_entry">The rapid rise and now widespread distribution of handheld and wearable devices, such as smartphones, fitness trackers, or smartwatches, has opened a new universe of possibilities for monitoring emotion and cognition in everyday-life context, and for applying experience- and context-specific interventions in psychosis. These devices are equipped with multiple sensors, recording channels, and app-based opportunities for assessment using experience sampling methodology (ESM), which enables to collect vast amounts of temporally highly resolved and ecologically valid personal data from various domains in daily life. In psychosis, this allows to elucidate intermediate and clinical phenotypes, psychological processes and mechanisms, and their interplay with socioenvironmental factors, as well as to evaluate the effects of treatments for psychosis on important clinical and social outcomes. Although these data offer immense opportunities, they also pose tremendous challenges for data analysis. These challenges include the sheer amount of time series data generated and the many different data modalities and their specific properties and sampling rates. After a brief review of studies and approaches to ESM and ecological momentary interventions in psychosis, we will discuss recurrent neural networks (RNNs) as a powerful statistical machine learning approach for time series analysis and prediction in this context. RNNs can be trained on multiple data modalities simultaneously to learn a dynamical model that could be used to forecast individual trajectories and schedule online feedback and intervention accordingly. Future research using this approach is likely going to offer new avenues to further our understanding and treatments of psychosis.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('15','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_15" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1093/schbul/sby171" title="Follow DOI:10.1093/schbul/sby171" target="_blank">doi:10.1093/schbul/sby171</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('15','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel;  Koppe, Georgia;  Meyer-Lindenberg, Andreas</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('16','tp_links')" style="cursor:pointer;">Deep neural networks in psychiatry</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Molecular Psychiatry, </span><span class="tp_pub_additional_year">2019</span>, <span class="tp_pub_additional_issn">ISSN: 14765578</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_16" class="tp_show" onclick="teachpress_pub_showhide('16','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_16" class="tp_show" onclick="teachpress_pub_showhide('16','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_16" class="tp_show" onclick="teachpress_pub_showhide('16','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_16" style="display:none;"><div class="tp_bibtex_entry">@article{Durstewitz2019,<br>
title = {Deep neural networks in psychiatry},<br>
author = {Daniel Durstewitz and Georgia Koppe and Andreas Meyer-Lindenberg},<br>
url = {http://dx.doi.org/10.1038/s41380-019-0365-9},<br>
doi = {10.1038/s41380-019-0365-9},<br>
issn = {14765578},<br>
year  = {2019},<br>
date = {2019-01-01},<br>
journal = {Molecular Psychiatry},<br>
publisher = {Springer US},<br>
abstract = {Machine and deep learning methods, today's core of artificial intelligence, have been applied with increasing success and impact in many commercial and research settings. They are powerful tools for large scale data analysis, prediction and classification, especially in very data-rich environments (“big data”), and have started to find their way into medical applications. Here we will first give an overview of machine learning methods, with a focus on deep and recurrent neural networks, their relation to statistics, and the core principles behind them. We will then discuss and review directions along which (deep) neural networks can be, or already have been, applied in the context of psychiatry, and will try to delineate their future potential in this area. We will also comment on an emerging area that so far has been much less well explored: by embedding semantically interpretable computational models of brain dynamics or behavior into a statistical machine learning context, insights into dysfunction beyond mere prediction and classification may be gained. Especially this marriage of computational models with statistical inference may offer insights into neural and behavioral mechanisms that could open completely novel avenues for psychiatric treatment.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('16','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_16" style="display:none;"><div class="tp_abstract_entry">Machine and deep learning methods, today's core of artificial intelligence, have been applied with increasing success and impact in many commercial and research settings. They are powerful tools for large scale data analysis, prediction and classification, especially in very data-rich environments (“big data”), and have started to find their way into medical applications. Here we will first give an overview of machine learning methods, with a focus on deep and recurrent neural networks, their relation to statistics, and the core principles behind them. We will then discuss and review directions along which (deep) neural networks can be, or already have been, applied in the context of psychiatry, and will try to delineate their future potential in this area. We will also comment on an emerging area that so far has been much less well explored: by embedding semantically interpretable computational models of brain dynamics or behavior into a statistical machine learning context, insights into dysfunction beyond mere prediction and classification may be gained. Especially this marriage of computational models with statistical inference may offer insights into neural and behavioral mechanisms that could open completely novel avenues for psychiatric treatment.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('16','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_16" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://dx.doi.org/10.1038/s41380-019-0365-9" title="http://dx.doi.org/10.1038/s41380-019-0365-9" target="_blank">http://dx.doi.org/10.1038/s41380-019-0365-9</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1038/s41380-019-0365-9" title="Follow DOI:10.1038/s41380-019-0365-9" target="_blank">doi:10.1038/s41380-019-0365-9</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('16','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2018">2018</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Toutounji, Hazem;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('41','tp_links')" style="cursor:pointer;">Detecting Multiple Change Points Using Adaptive Regression Splines With Application to Neural Recordings</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Frontiers in Neuroinformatics, </span><span class="tp_pub_additional_volume">12 </span><span class="tp_pub_additional_number">(67), </span><span class="tp_pub_additional_year">2018</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_41" class="tp_show" onclick="teachpress_pub_showhide('41','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_41" class="tp_show" onclick="teachpress_pub_showhide('41','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_41" class="tp_show" onclick="teachpress_pub_showhide('41','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_41" style="display:none;"><div class="tp_bibtex_entry">@article{Toutounji2018,<br>
title = {Detecting Multiple Change Points Using Adaptive Regression Splines With Application to Neural Recordings},<br>
author = {Hazem Toutounji and Daniel Durstewitz},<br>
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6187984/},<br>
doi = {10.3389/fninf.2018.00067},<br>
year  = {2018},<br>
date = {2018-10-04},<br>
journal = {Frontiers in Neuroinformatics},<br>
volume = {12},<br>
number = {67},<br>
abstract = {Time series, as frequently the case in neuroscience, are rarely stationary, but often exhibit abrupt changes due to attractor transitions or bifurcations in the dynamical systems producing them. A plethora of methods for detecting such change points in time series statistics have been developed over the years, in addition to test criteria to evaluate their significance. Issues to consider when developing change point analysis methods include computational demands, difficulties arising from either limited amount of data or a large number of covariates, and arriving at statistical tests with sufficient power to detect as many changes as contained in potentially high-dimensional time series. Here, a general method called Paired Adaptive Regressors for Cumulative Sum is developed for detecting multiple change points in the mean of multivariate time series. The method's advantages over alternative approaches are demonstrated through a series of simulation experiments. This is followed by a real data application to neural recordings from rat medial prefrontal cortex during learning. Finally, the method's flexibility to incorporate useful features from state-of-the-art change point detection techniques is discussed, along with potential drawbacks and suggestions to remedy them.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('41','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_41" style="display:none;"><div class="tp_abstract_entry">Time series, as frequently the case in neuroscience, are rarely stationary, but often exhibit abrupt changes due to attractor transitions or bifurcations in the dynamical systems producing them. A plethora of methods for detecting such change points in time series statistics have been developed over the years, in addition to test criteria to evaluate their significance. Issues to consider when developing change point analysis methods include computational demands, difficulties arising from either limited amount of data or a large number of covariates, and arriving at statistical tests with sufficient power to detect as many changes as contained in potentially high-dimensional time series. Here, a general method called Paired Adaptive Regressors for Cumulative Sum is developed for detecting multiple change points in the mean of multivariate time series. The method's advantages over alternative approaches are demonstrated through a series of simulation experiments. This is followed by a real data application to neural recordings from rat medial prefrontal cortex during learning. Finally, the method's flexibility to incorporate useful features from state-of-the-art change point detection techniques is discussed, along with potential drawbacks and suggestions to remedy them.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('41','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_41" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6187984/" title="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6187984/" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6187984/</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.3389/fninf.2018.00067" title="Follow DOI:10.3389/fninf.2018.00067" target="_blank">doi:10.3389/fninf.2018.00067</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('41','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel;  Huys, Quentin J M;  Koppe, Georgia</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('21','tp_links')" style="cursor:pointer;">Psychiatric Illnesses as Disorders of Network Dynamics</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_pages">pp. 1–24, </span><span class="tp_pub_additional_year">2018</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_21" class="tp_show" onclick="teachpress_pub_showhide('21','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_21" class="tp_show" onclick="teachpress_pub_showhide('21','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_21" class="tp_show" onclick="teachpress_pub_showhide('21','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_21" style="display:none;"><div class="tp_bibtex_entry">@article{Durstewitza,<br>
title = {Psychiatric Illnesses as Disorders of Network Dynamics},<br>
author = {Daniel Durstewitz and Quentin J M Huys and Georgia Koppe},<br>
url = {https://arxiv.org/pdf/1809.06303.pdf},<br>
year  = {2018},<br>
date = {2018-09-18},<br>
pages = {1--24},<br>
abstract = {This review provides a dynamical systems perspective on psychiatric symptoms and disease, and discusses its potential implications for diagnosis, prognosis, and treatment. After a brief introduction into the theory of dynamical systems, we will focus on the idea that cognitive and emotional functions are implemented in terms of dynamical systems phenomena in the brain, a common assumption in theoretical and computational neuroscience. Specific computational models, anchored in biophysics, for generating different types of network dynamics, and with a relation to psychiatric symptoms, will be briefly reviewed, as well as methodological approaches for reconstructing the system dynamics from observed time series (like fMRI or EEG recordings). We then attempt to outline how psychiatric phenomena, associated with schizophrenia, depression, PTSD, ADHD, phantom pain, and others, could be understood in dynamical systems terms. Most importantly, we will try to convey that the dynamical systems level may provide a central, hub-like level of convergence which unifies and links multiple biophysical and behavioral phenomena, in the sense that diverse biophysical changes can give rise to the same dynamical phenomena and, vice versa, similar changes in dynamics may yield different behavioral symptoms depending on the brain area where these changes manifest. If this assessment is correct, it may have profound implications for the diagnosis, prognosis, and treatment of psychiatric conditions, as it puts the focus on dynamics. We therefore argue that consideration of dynamics should play an important role in the choice and target of interventions.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('21','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_21" style="display:none;"><div class="tp_abstract_entry">This review provides a dynamical systems perspective on psychiatric symptoms and disease, and discusses its potential implications for diagnosis, prognosis, and treatment. After a brief introduction into the theory of dynamical systems, we will focus on the idea that cognitive and emotional functions are implemented in terms of dynamical systems phenomena in the brain, a common assumption in theoretical and computational neuroscience. Specific computational models, anchored in biophysics, for generating different types of network dynamics, and with a relation to psychiatric symptoms, will be briefly reviewed, as well as methodological approaches for reconstructing the system dynamics from observed time series (like fMRI or EEG recordings). We then attempt to outline how psychiatric phenomena, associated with schizophrenia, depression, PTSD, ADHD, phantom pain, and others, could be understood in dynamical systems terms. Most importantly, we will try to convey that the dynamical systems level may provide a central, hub-like level of convergence which unifies and links multiple biophysical and behavioral phenomena, in the sense that diverse biophysical changes can give rise to the same dynamical phenomena and, vice versa, similar changes in dynamics may yield different behavioral symptoms depending on the brain area where these changes manifest. If this assessment is correct, it may have profound implications for the diagnosis, prognosis, and treatment of psychiatric conditions, as it puts the focus on dynamics. We therefore argue that consideration of dynamics should play an important role in the choice and target of interventions.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('21','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_21" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="https://arxiv.org/pdf/1809.06303.pdf" title="https://arxiv.org/pdf/1809.06303.pdf" target="_blank">https://arxiv.org/pdf/1809.06303.pdf</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('21','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Livio Oboti  Eleonora Russo, Tuyen Tran Daniel Durstewitz ;  Corbin, Joshua G</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('27','tp_links')" style="cursor:pointer;">Amygdala Corticofugal Input Shapes Mitral Cell Responses in the Accessory Olfactory Bulb</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">eNeuro, </span><span class="tp_pub_additional_year">2018</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_27" class="tp_show" onclick="teachpress_pub_showhide('27','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_27" class="tp_show" onclick="teachpress_pub_showhide('27','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_27" class="tp_show" onclick="teachpress_pub_showhide('27','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_27" style="display:none;"><div class="tp_bibtex_entry">@article{Oboti2018,<br>
title = {Amygdala Corticofugal Input Shapes Mitral Cell Responses in the Accessory Olfactory Bulb},<br>
author = {Livio Oboti, Eleonora Russo, Tuyen Tran, Daniel Durstewitz and Joshua G. Corbin},<br>
doi = {https://doi.org/10.1523/ENEURO.0175-18.2018},<br>
year  = {2018},<br>
date = {2018-05-18},<br>
journal = {eNeuro},<br>
abstract = {Interconnections between the olfactory bulb and the amygdala are a major pathway for triggering strong behavioralresponses to a variety of odorants. However, while this broad mapping has been established, the patterns of amygdalafeedback connectivity and the influence on olfactory circuitry remain unknown. Here, using a combination of neuronaltracing approaches, we dissect the connectivity of a cortical amygdala [posteromedial cortical nucleus (PmCo)]feedback circuit innervating the mouse accessory olfactory bulb. Optogenetic activation of PmCo feedback mainlyresults in feedforward mitral cell (MC) inhibition through direct excitation of GABAergic granule cells. In addition,LED-driven activity of corticofugal afferents increases the gain of MC responses to olfactory nerve stimulation. Thus,through corticofugal pathways, the PmCo likely regulates primary olfactory and social odor processing.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('27','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_27" style="display:none;"><div class="tp_abstract_entry">Interconnections between the olfactory bulb and the amygdala are a major pathway for triggering strong behavioralresponses to a variety of odorants. However, while this broad mapping has been established, the patterns of amygdalafeedback connectivity and the influence on olfactory circuitry remain unknown. Here, using a combination of neuronaltracing approaches, we dissect the connectivity of a cortical amygdala [posteromedial cortical nucleus (PmCo)]feedback circuit innervating the mouse accessory olfactory bulb. Optogenetic activation of PmCo feedback mainlyresults in feedforward mitral cell (MC) inhibition through direct excitation of GABAergic granule cells. In addition,LED-driven activity of corticofugal afferents increases the gain of MC responses to olfactory nerve stimulation. Thus,through corticofugal pathways, the PmCo likely regulates primary olfactory and social odor processing.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('27','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_27" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1523/ENEURO.0175-18.2018" title="Follow DOI:https://doi.org/10.1523/ENEURO.0175-18.2018" target="_blank">doi:https://doi.org/10.1523/ENEURO.0175-18.2018</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('27','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Koppe, Georgia;  Toutounji, Hazem;  Kirsch, Peter;  Lis, Stefanie;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('1','tp_links')" style="cursor:pointer;">Identifying nonlinear dynamical systems via generative recurrent neural networks with applications to fMRI</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">arxiv, </span><span class="tp_pub_additional_volume">6 </span><span class="tp_pub_additional_number">(2), </span><span class="tp_pub_additional_pages">pp. 103, </span><span class="tp_pub_additional_year">2018</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_1" class="tp_show" onclick="teachpress_pub_showhide('1','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_1" class="tp_show" onclick="teachpress_pub_showhide('1','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_1" class="tp_show" onclick="teachpress_pub_showhide('1','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_1" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2018,<br>
title = {Identifying nonlinear dynamical systems via generative recurrent neural networks with applications to fMRI},<br>
author = {Georgia Koppe and Hazem Toutounji and Peter Kirsch and Stefanie Lis and Daniel Durstewitz},<br>
url = {https://arxiv.org/ftp/arxiv/papers/1902/1902.07186.pdf},<br>
year  = {2018},<br>
date = {2018-01-01},<br>
journal = {arxiv},<br>
volume = {6},<br>
number = {2},<br>
pages = {103},<br>
abstract = {A major tenet in theoretical neuroscience is that cognitive and behavioral processes are ultimately implemented in terms of the neural system dynamics. Accordingly, a major aim for the analysis of neurophysiological measurements should lie in the identification of the computational dynamics underlying task processing. Here we advance a state space model (SSM) based on generative piecewise-linear recurrent neural networks (PLRNN) to assess dynamics from neuroimaging data. In contrast to many other nonlinear time series models which have been proposed for reconstructing latent dynamics, our model is easily interpretable in neural terms, amenable to systematic dynamical systems analysis of the resulting set of equations, and can straightforwardly be transformed into an equivalent continuous-time dynamical system. The major contributions of this paper are the introduction of a new observation model suitable for functional magnetic resonance imaging (fMRI)},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('1','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_1" style="display:none;"><div class="tp_abstract_entry">A major tenet in theoretical neuroscience is that cognitive and behavioral processes are ultimately implemented in terms of the neural system dynamics. Accordingly, a major aim for the analysis of neurophysiological measurements should lie in the identification of the computational dynamics underlying task processing. Here we advance a state space model (SSM) based on generative piecewise-linear recurrent neural networks (PLRNN) to assess dynamics from neuroimaging data. In contrast to many other nonlinear time series models which have been proposed for reconstructing latent dynamics, our model is easily interpretable in neural terms, amenable to systematic dynamical systems analysis of the resulting set of equations, and can straightforwardly be transformed into an equivalent continuous-time dynamical system. The major contributions of this paper are the introduction of a new observation model suitable for functional magnetic resonance imaging (fMRI)</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('1','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_1" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="https://arxiv.org/ftp/arxiv/papers/1902/1902.07186.pdf" title="https://arxiv.org/ftp/arxiv/papers/1902/1902.07186.pdf" target="_blank">https://arxiv.org/ftp/arxiv/papers/1902/1902.07186.pdf</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('1','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2017">2017</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('3','tp_links')" style="cursor:pointer;">Advanced Data Analysis in Neuroscience</a> <span class="tp_pub_type book">Book</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_year">2017</span>, <span class="tp_pub_additional_isbn">ISBN: 9783319599748</span>.</p><p class="tp_pub_tags"><span class="tp_resource_link"><a id="tp_links_sh_3" class="tp_show" onclick="teachpress_pub_showhide('3','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_3" class="tp_show" onclick="teachpress_pub_showhide('3','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_3" style="display:none;"><div class="tp_bibtex_entry">@book{Durstewitzb,<br>
title = {Advanced Data Analysis in Neuroscience},<br>
author = {Daniel Durstewitz},<br>
url = {https://link.springer.com/content/pdf/10.1007%2F978-3-319-59976-2.pdf},<br>
isbn = {9783319599748},<br>
year  = {2017},<br>
date = {2017-11-01},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {book}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('3','tp_bibtex')">Close</a></p></div><div class="tp_links" id="tp_links_3" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-59976-2.pdf" title="https://link.springer.com/content/pdf/10.1007%2F978-3-319-59976-2.pdf" target="_blank">https://link.springer.com/content/pdf/10.1007%2F978-3-319-59976-2.pdf</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('3','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Koppe, Georgia;  Mallien, Anne Stephanie;  Berger, Stefan;  Bartsch, Dusan;  Gass, Peter;  Vollmayr, Barbara;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('42','tp_links')" style="cursor:pointer;">CACNA1C gene regulates behavioral strategies in operant rule learning</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLOS Biology, </span><span class="tp_pub_additional_volume">15 </span><span class="tp_pub_additional_number">(6), </span><span class="tp_pub_additional_year">2017</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_42" class="tp_show" onclick="teachpress_pub_showhide('42','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_42" class="tp_show" onclick="teachpress_pub_showhide('42','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_42" class="tp_show" onclick="teachpress_pub_showhide('42','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_42" style="display:none;"><div class="tp_bibtex_entry">@article{Koppe2017,<br>
title = {CACNA1C gene regulates behavioral strategies in operant rule learning},<br>
author = {Georgia Koppe and Anne Stephanie Mallien and Stefan Berger and Dusan Bartsch and Peter Gass and Barbara Vollmayr and Daniel Durstewitz<br>
},<br>
url = { https://doi.org/10.1371/journal.pbio.2000936},<br>
doi = {10.1371/journal.pbio.2000936},<br>
year  = {2017},<br>
date = {2017-06-12},<br>
journal = {PLOS Biology},<br>
volume = {15},<br>
number = {6},<br>
abstract = {Behavioral experiments are usually designed to tap into a specific cognitive function, but animals may solve a given task through a variety of different and individual behavioral strategies, some of them not foreseen by the experimenter. Animal learning may therefore be seen more as the process of selecting among, and adapting, potential behavioral policies, rather than mere strengthening of associative links. Calcium influx through high-voltage-gated Ca2+ channels is central to synaptic plasticity, and altered expression of Cav1.2 channels and the CACNA1C gene have been associated with severe learning deficits and psychiatric disorders. Given this, we were interested in how specifically a selective functional ablation of the Cacna1c gene would modulate the learning process. Using a detailed, individual-level analysis of learning on an operant cue discrimination task in terms of behavioral strategies, combined with Bayesian selection among computational models estimated from the empirical data, we show that a Cacna1c knockout does not impair learning in general but has a much more specific effect: the majority of Cacna1c knockout mice still managed to increase reward feedback across trials but did so by adapting an outcome-based strategy, while the majority of matched controls adopted the experimentally intended cue-association rule. Our results thus point to a quite specific role of a single gene in learning and highlight that much more mechanistic insight could be gained by examining response patterns in terms of a larger repertoire of potential behavioral strategies. The results may also have clinical implications for treating psychiatric disorders.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('42','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_42" style="display:none;"><div class="tp_abstract_entry">Behavioral experiments are usually designed to tap into a specific cognitive function, but animals may solve a given task through a variety of different and individual behavioral strategies, some of them not foreseen by the experimenter. Animal learning may therefore be seen more as the process of selecting among, and adapting, potential behavioral policies, rather than mere strengthening of associative links. Calcium influx through high-voltage-gated Ca2+ channels is central to synaptic plasticity, and altered expression of Cav1.2 channels and the CACNA1C gene have been associated with severe learning deficits and psychiatric disorders. Given this, we were interested in how specifically a selective functional ablation of the Cacna1c gene would modulate the learning process. Using a detailed, individual-level analysis of learning on an operant cue discrimination task in terms of behavioral strategies, combined with Bayesian selection among computational models estimated from the empirical data, we show that a Cacna1c knockout does not impair learning in general but has a much more specific effect: the majority of Cacna1c knockout mice still managed to increase reward feedback across trials but did so by adapting an outcome-based strategy, while the majority of matched controls adopted the experimentally intended cue-association rule. Our results thus point to a quite specific role of a single gene in learning and highlight that much more mechanistic insight could be gained by examining response patterns in terms of a larger repertoire of potential behavioral strategies. The results may also have clinical implications for treating psychiatric disorders.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('42','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_42" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1371/journal.pbio.2000936" title="https://doi.org/10.1371/journal.pbio.2000936" target="_blank">https://doi.org/10.1371/journal.pbio.2000936</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pbio.2000936" title="Follow DOI:10.1371/journal.pbio.2000936" target="_blank">doi:10.1371/journal.pbio.2000936</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('42','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Eleonora Russo, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('28','tp_links')" style="cursor:pointer;">Cell assemblies at multiple time scales with arbitrary lag constellations</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">eLife, </span><span class="tp_pub_additional_year">2017</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_28" class="tp_show" onclick="teachpress_pub_showhide('28','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_28" class="tp_show" onclick="teachpress_pub_showhide('28','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_28" class="tp_show" onclick="teachpress_pub_showhide('28','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_28" style="display:none;"><div class="tp_bibtex_entry">@article{Russo2017,<br>
title = {Cell assemblies at multiple time scales with arbitrary lag constellations},<br>
author = {Eleonora Russo, Daniel Durstewitz},<br>
url = {https://elifesciences.org/articles/19428},<br>
doi = {10.7554/eLife.19428},<br>
year  = {2017},<br>
date = {2017-01-11},<br>
journal = {eLife},<br>
abstract = {Hebb's idea of a cell assembly as the fundamental unit of neural information processing has dominated neuroscience like no other theoretical concept within the past 60 years. A range of different physiological phenomena, from precisely synchronized spiking to broadly simultaneous rate increases, has been subsumed under this term. Yet progress in this area is hampered by the lack of statistical tools that would enable to extract assemblies with arbitrary constellations of time lags, and at multiple temporal scales, partly due to the severe computational burden. Here we present such a unifying methodological and conceptual framework which detects assembly structure at many different time scales, levels of precision, and with arbitrary internal organization. Applying this methodology to multiple single unit recordings from various cortical areas, we find that there is no universal cortical coding scheme, but that assembly structure and precision significantly depends on the brain area recorded and ongoing task demands.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('28','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_28" style="display:none;"><div class="tp_abstract_entry">Hebb's idea of a cell assembly as the fundamental unit of neural information processing has dominated neuroscience like no other theoretical concept within the past 60 years. A range of different physiological phenomena, from precisely synchronized spiking to broadly simultaneous rate increases, has been subsumed under this term. Yet progress in this area is hampered by the lack of statistical tools that would enable to extract assemblies with arbitrary constellations of time lags, and at multiple temporal scales, partly due to the severe computational burden. Here we present such a unifying methodological and conceptual framework which detects assembly structure at many different time scales, levels of precision, and with arbitrary internal organization. Applying this methodology to multiple single unit recordings from various cortical areas, we find that there is no universal cortical coding scheme, but that assembly structure and precision significantly depends on the brain area recorded and ongoing task demands.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('28','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_28" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://elifesciences.org/articles/19428" title="https://elifesciences.org/articles/19428" target="_blank">https://elifesciences.org/articles/19428</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.7554/eLife.19428" title="Follow DOI:10.7554/eLife.19428" target="_blank">doi:10.7554/eLife.19428</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('28','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('2','tp_links')" style="cursor:pointer;">A State Space Approach for Piecewise‐Linear Recurrent Neural Networks for Reconstructing Nonlinear Dynamics from Neural Measurements</a> <span class="tp_pub_type book">Book</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_year">2017</span>, <span class="tp_pub_additional_issn">ISSN: 1553-7358</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_2" class="tp_show" onclick="teachpress_pub_showhide('2','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_2" class="tp_show" onclick="teachpress_pub_showhide('2','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_2" class="tp_show" onclick="teachpress_pub_showhide('2','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_2" style="display:none;"><div class="tp_bibtex_entry">@book{Durstewitz2017,<br>
title = {A State Space Approach for Piecewise‐Linear Recurrent Neural Networks for Reconstructing Nonlinear Dynamics from Neural Measurements},<br>
author = {Daniel Durstewitz},<br>
doi = {10.1371/journal.pcbi.1005542},<br>
issn = {1553-7358},<br>
year  = {2017},<br>
date = {2017-01-01},<br>
booktitle = {PLoS Computational Biology},<br>
volume = {13},<br>
number = {6},<br>
pages = {e1005542},<br>
abstract = {The computational and cognitive properties of neural systems are often thought to be imple-mented in terms of their (stochastic) network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit recordings or neuroimaging data, is an important step toward understanding its computa-tions. Ideally, one would not only seek a (lower-dimensional) state space representation of the dynamics, but would wish to have access to its statistical properties and their generative equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maxi-mization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, and using inference through particle filters for comparison, the approach is applied to multiple single-unit recordings from the rodent anterior cingulate cortex (ACC) obtained during performance of a classical working memory task, delayed alternation. Mod-els estimated from kernel-smoothed spike time data were able to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, however, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation frame-work for PLRNNs that may enable to recover relevant aspects of the nonlinear dynamics underlying observed neuronal time series, and directly link these to computational properties. Citation: Durstewitz D (2017) A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural measurements. PLoS Comput Biol 13 (6): Neuronal dynamics mediate between the physiological and anatomical properties of a neural system and the computations it performs, in fact may be seen as the 'computational language' of the brain. It is therefore of great interest to recover from experimentally recorded time series, like multiple single-unit or neuroimaging data, the underlying sto-chastic network dynamics and, ideally, even equations governing their statistical evolu-tion. This is not at all a trivial enterprise, however, since neural systems are very high-dimensional, come with considerable levels of intrinsic (process) noise, are usually only partially observable, and these observations may be further corrupted by noise from mea-surement and preprocessing steps. The present article embeds piecewise-linear recurrent neural networks (PLRNNs) within a state space approach, a statistical estimation frame-work that deals with both process and observation noise. PLRNNs are computationally and dynamically powerful nonlinear systems. Their statistically principled estimation from multivariate neuronal time series thus may provide access to some essential features of the neuronal dynamics, like attractor states, generative equations, and their computa-tional implications. The approach is exemplified on multiple single-unit recordings from the rat prefrontal cortex during working memory.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {book}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('2','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_2" style="display:none;"><div class="tp_abstract_entry">The computational and cognitive properties of neural systems are often thought to be imple-mented in terms of their (stochastic) network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit recordings or neuroimaging data, is an important step toward understanding its computa-tions. Ideally, one would not only seek a (lower-dimensional) state space representation of the dynamics, but would wish to have access to its statistical properties and their generative equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maxi-mization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, and using inference through particle filters for comparison, the approach is applied to multiple single-unit recordings from the rodent anterior cingulate cortex (ACC) obtained during performance of a classical working memory task, delayed alternation. Mod-els estimated from kernel-smoothed spike time data were able to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, however, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation frame-work for PLRNNs that may enable to recover relevant aspects of the nonlinear dynamics underlying observed neuronal time series, and directly link these to computational properties. Citation: Durstewitz D (2017) A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural measurements. PLoS Comput Biol 13 (6): Neuronal dynamics mediate between the physiological and anatomical properties of a neural system and the computations it performs, in fact may be seen as the 'computational language' of the brain. It is therefore of great interest to recover from experimentally recorded time series, like multiple single-unit or neuroimaging data, the underlying sto-chastic network dynamics and, ideally, even equations governing their statistical evolu-tion. This is not at all a trivial enterprise, however, since neural systems are very high-dimensional, come with considerable levels of intrinsic (process) noise, are usually only partially observable, and these observations may be further corrupted by noise from mea-surement and preprocessing steps. The present article embeds piecewise-linear recurrent neural networks (PLRNNs) within a state space approach, a statistical estimation frame-work that deals with both process and observation noise. PLRNNs are computationally and dynamically powerful nonlinear systems. Their statistically principled estimation from multivariate neuronal time series thus may provide access to some essential features of the neuronal dynamics, like attractor states, generative equations, and their computa-tional implications. The approach is exemplified on multiple single-unit recordings from the rat prefrontal cortex during working memory.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('2','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_2" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pcbi.1005542" title="Follow DOI:10.1371/journal.pcbi.1005542" target="_blank">doi:10.1371/journal.pcbi.1005542</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('2','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('6','tp_links')" style="cursor:pointer;">A State Space Approach for Piecewise‐Linear Recurrent Neural Networks for Reconstructing Nonlinear Dynamics from Neural Measurements</a> <span class="tp_pub_type book">Book</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_year">2017</span>, <span class="tp_pub_additional_issn">ISSN: 1553-7358</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_6" class="tp_show" onclick="teachpress_pub_showhide('6','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_6" class="tp_show" onclick="teachpress_pub_showhide('6','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_6" class="tp_show" onclick="teachpress_pub_showhide('6','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_6" style="display:none;"><div class="tp_bibtex_entry">@book{Durstewitz2017b,<br>
title = {A State Space Approach for Piecewise‐Linear Recurrent Neural Networks for Reconstructing Nonlinear Dynamics from Neural Measurements},<br>
author = {Daniel Durstewitz},<br>
doi = {10.1371/journal.pcbi.1005542},<br>
issn = {1553-7358},<br>
year  = {2017},<br>
date = {2017-01-01},<br>
booktitle = {PLoS Computational Biology},<br>
volume = {13},<br>
number = {6},<br>
pages = {e1005542},<br>
abstract = {The computational and cognitive properties of neural systems are often thought to be imple-mented in terms of their (stochastic) network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit recordings or neuroimaging data, is an important step toward understanding its computa-tions. Ideally, one would not only seek a (lower-dimensional) state space representation of the dynamics, but would wish to have access to its statistical properties and their generative equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maxi-mization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, and using inference through particle filters for comparison, the approach is applied to multiple single-unit recordings from the rodent anterior cingulate cortex (ACC) obtained during performance of a classical working memory task, delayed alternation. Mod-els estimated from kernel-smoothed spike time data were able to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, however, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation frame-work for PLRNNs that may enable to recover relevant aspects of the nonlinear dynamics underlying observed neuronal time series, and directly link these to computational properties. Citation: Durstewitz D (2017) A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural measurements. PLoS Comput Biol 13 (6): Neuronal dynamics mediate between the physiological and anatomical properties of a neural system and the computations it performs, in fact may be seen as the 'computational language' of the brain. It is therefore of great interest to recover from experimentally recorded time series, like multiple single-unit or neuroimaging data, the underlying sto-chastic network dynamics and, ideally, even equations governing their statistical evolu-tion. This is not at all a trivial enterprise, however, since neural systems are very high-dimensional, come with considerable levels of intrinsic (process) noise, are usually only partially observable, and these observations may be further corrupted by noise from mea-surement and preprocessing steps. The present article embeds piecewise-linear recurrent neural networks (PLRNNs) within a state space approach, a statistical estimation frame-work that deals with both process and observation noise. PLRNNs are computationally and dynamically powerful nonlinear systems. Their statistically principled estimation from multivariate neuronal time series thus may provide access to some essential features of the neuronal dynamics, like attractor states, generative equations, and their computa-tional implications. The approach is exemplified on multiple single-unit recordings from the rat prefrontal cortex during working memory.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {book}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('6','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_6" style="display:none;"><div class="tp_abstract_entry">The computational and cognitive properties of neural systems are often thought to be imple-mented in terms of their (stochastic) network dynamics. Hence, recovering the system dynamics from experimentally observed neuronal time series, like multiple single-unit recordings or neuroimaging data, is an important step toward understanding its computa-tions. Ideally, one would not only seek a (lower-dimensional) state space representation of the dynamics, but would wish to have access to its statistical properties and their generative equations for in-depth analysis. Recurrent neural networks (RNNs) are a computationally powerful and dynamically universal formal framework which has been extensively studied from both the computational and the dynamical systems perspective. Here we develop a semi-analytical maximum-likelihood estimation scheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of state space models, which accounts for noise in both the underlying latent dynamics and the observation process. The Expectation-Maxi-mization algorithm is used to infer the latent state distribution, through a global Laplace approximation, and the PLRNN parameters iteratively. After validating the procedure on toy examples, and using inference through particle filters for comparison, the approach is applied to multiple single-unit recordings from the rodent anterior cingulate cortex (ACC) obtained during performance of a classical working memory task, delayed alternation. Mod-els estimated from kernel-smoothed spike time data were able to capture the essential computational dynamics underlying task performance, including stimulus-selective delay activity. The estimated models were rarely multi-stable, however, but rather were tuned to exhibit slow dynamics in the vicinity of a bifurcation point. In summary, the present work advances a semi-analytical (thus reasonably fast) maximum-likelihood estimation frame-work for PLRNNs that may enable to recover relevant aspects of the nonlinear dynamics underlying observed neuronal time series, and directly link these to computational properties. Citation: Durstewitz D (2017) A state space approach for piecewise-linear recurrent neural networks for identifying computational dynamics from neural measurements. PLoS Comput Biol 13 (6): Neuronal dynamics mediate between the physiological and anatomical properties of a neural system and the computations it performs, in fact may be seen as the 'computational language' of the brain. It is therefore of great interest to recover from experimentally recorded time series, like multiple single-unit or neuroimaging data, the underlying sto-chastic network dynamics and, ideally, even equations governing their statistical evolu-tion. This is not at all a trivial enterprise, however, since neural systems are very high-dimensional, come with considerable levels of intrinsic (process) noise, are usually only partially observable, and these observations may be further corrupted by noise from mea-surement and preprocessing steps. The present article embeds piecewise-linear recurrent neural networks (PLRNNs) within a state space approach, a statistical estimation frame-work that deals with both process and observation noise. PLRNNs are computationally and dynamically powerful nonlinear systems. Their statistically principled estimation from multivariate neuronal time series thus may provide access to some essential features of the neuronal dynamics, like attractor states, generative equations, and their computa-tional implications. The approach is exemplified on multiple single-unit recordings from the rat prefrontal cortex during working memory.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('6','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_6" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pcbi.1005542" title="Follow DOI:10.1371/journal.pcbi.1005542" target="_blank">doi:10.1371/journal.pcbi.1005542</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('6','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Peter, Sven ;  Kirschbaum, Elke ;  Both, Martin ;  Campbell, Lee ;  Harvey, Brandon ;  Heins, Conor ;  Durstewitz, Daniel ;  Diego, Ferran ;  Hamprecht, Fred A</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('40','tp_links')" style="cursor:pointer;">Sparse convolutional coding for neuronal assembly detection</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Advances in Neural Information Processing Systems , </span><span class="tp_pub_additional_volume">30 </span>, <span class="tp_pub_additional_pages">pp. 3675–3685, </span><span class="tp_pub_additional_year">2017</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_40" class="tp_show" onclick="teachpress_pub_showhide('40','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_40" class="tp_show" onclick="teachpress_pub_showhide('40','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_40" class="tp_show" onclick="teachpress_pub_showhide('40','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_40" style="display:none;"><div class="tp_bibtex_entry">@article{Peter2017,<br>
title = {Sparse convolutional coding for neuronal assembly detection},<br>
author = {Peter, Sven and Kirschbaum, Elke and Both, Martin and Campbell, Lee and Harvey, Brandon and Heins, Conor and Durstewitz, Daniel and Diego, Ferran and Hamprecht, Fred A},<br>
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},<br>
url = {http://papers.nips.cc/paper/6958-sparse-convolutional-coding-for-neuronal-assembly-detection.pdf},<br>
year  = {2017},<br>
date = {2017-01-01},<br>
journal = {Advances in Neural Information Processing Systems },<br>
volume = {30},<br>
pages = {3675--3685},<br>
abstract = {Cell assemblies, originally proposed by Donald Hebb (1949), are subsets of neurons firing in a temporally coordinated way that gives rise to repeated motifs supposed to underly neural representations and information processing. Although Hebb's original proposal dates back many decades, the detection of assemblies and their role in coding is still an open and current research topic, partly because simultaneous recordings from large populations of neurons became feasible only relatively recently. Most current and easy-to-apply computational techniques focus on the identification of strictly synchronously spiking neurons. In this paper we propose a new algorithm, based on sparse convolutional coding, for detecting recurrent motifs of arbitrary structure up to a given length. Testing of our algorithm on synthetically generated datasets shows that it outperforms established methods and accurately identifies the temporal structure of embedded assemblies, even when these contain overlapping neurons or when strong background noise is present. Moreover, exploratory analysis of experimental datasets from hippocampal slices and cortical neuron cultures have provided promising results.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('40','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_40" style="display:none;"><div class="tp_abstract_entry">Cell assemblies, originally proposed by Donald Hebb (1949), are subsets of neurons firing in a temporally coordinated way that gives rise to repeated motifs supposed to underly neural representations and information processing. Although Hebb's original proposal dates back many decades, the detection of assemblies and their role in coding is still an open and current research topic, partly because simultaneous recordings from large populations of neurons became feasible only relatively recently. Most current and easy-to-apply computational techniques focus on the identification of strictly synchronously spiking neurons. In this paper we propose a new algorithm, based on sparse convolutional coding, for detecting recurrent motifs of arbitrary structure up to a given length. Testing of our algorithm on synthetically generated datasets shows that it outperforms established methods and accurately identifies the temporal structure of embedded assemblies, even when these contain overlapping neurons or when strong background noise is present. Moreover, exploratory analysis of experimental datasets from hippocampal slices and cortical neuron cultures have provided promising results.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('40','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_40" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xapplication-pdf.png.pagespeed.ic.0ml3CRc81n.png)" href="http://papers.nips.cc/paper/6958-sparse-convolutional-coding-for-neuronal-assembly-detection.pdf" title="http://papers.nips.cc/paper/6958-sparse-convolutional-coding-for-neuronal-assemb[...]" target="_blank">http://papers.nips.cc/paper/6958-sparse-convolutional-coding-for-neuronal-assemb[...]</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('40','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2016">2016</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Ma, Liya;  Hyman, James M;  Durstewitz, Daniel;  Phillips, Anthony G;  Seamans, Jeremy K</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('43','tp_links')" style="cursor:pointer;">A Quantitative Analysis of Context-Dependent Remapping of Medial Frontal Cortex Neurons and Ensembles</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">J Neurosci. 2016 Aug 3; 36(31), </span><span class="tp_pub_additional_volume">3 </span><span class="tp_pub_additional_number">(36), </span><span class="tp_pub_additional_pages">pp. 31, </span><span class="tp_pub_additional_year">2016</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_43" class="tp_show" onclick="teachpress_pub_showhide('43','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_43" class="tp_show" onclick="teachpress_pub_showhide('43','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_43" class="tp_show" onclick="teachpress_pub_showhide('43','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_43" style="display:none;"><div class="tp_bibtex_entry">@article{Ma2016,<br>
title = {A Quantitative Analysis of Context-Dependent Remapping of Medial Frontal Cortex Neurons and Ensembles},<br>
author = {Liya Ma and James M. Hyman and Daniel Durstewitz and Anthony G. Phillips and Jeremy K. Seamans},<br>
doi = {10.1523/JNEUROSCI.3176-15.2016},<br>
year  = {2016},<br>
date = {2016-08-03},<br>
journal = {J Neurosci. 2016 Aug 3; 36(31)},<br>
volume = {3},<br>
number = {36},<br>
pages = {31},<br>
abstract = {The frontal cortex has been implicated in a number of cognitive and motivational processes, but understanding how individual neurons contribute to these processes is particularly challenging as they respond to a broad array of events (multiplexing) in a manner that can be dynamically modulated by the task context, i.e., adaptive coding (Duncan, 2001). Fundamental questions remain, such as how the flexibility gained through these mechanisms is balanced by the need for consistency and how the ensembles of neurons are coherently shaped by task demands. In the present study, ensembles of medial frontal cortex neurons were recorded from rats trained to perform three different operant actions either in two different sequences or two different physical environments. Single neurons exhibited diverse mixtures of responsivity to each of the three actions and these mixtures were abruptly altered by context/sequence switches. Remarkably, the overall responsivity of the population remained highly consistent both within and between context/sequences because the gains versus losses were tightly balanced across neurons and across the three actions. These data are consistent with a reallocation mixture model in which individual neurons express unique mixtures of selectivity for different actions that become reallocated as task conditions change. However, because the allocations and reallocations are so well balanced across neurons, the population maintains a low but highly consistent response to all actions. The frontal cortex may therefore balance consistency with flexibility by having ensembles respond in a fixed way to task-relevant actions while abruptly reconfiguring single neurons to encode “actions in context.”},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('43','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_43" style="display:none;"><div class="tp_abstract_entry">The frontal cortex has been implicated in a number of cognitive and motivational processes, but understanding how individual neurons contribute to these processes is particularly challenging as they respond to a broad array of events (multiplexing) in a manner that can be dynamically modulated by the task context, i.e., adaptive coding (Duncan, 2001). Fundamental questions remain, such as how the flexibility gained through these mechanisms is balanced by the need for consistency and how the ensembles of neurons are coherently shaped by task demands. In the present study, ensembles of medial frontal cortex neurons were recorded from rats trained to perform three different operant actions either in two different sequences or two different physical environments. Single neurons exhibited diverse mixtures of responsivity to each of the three actions and these mixtures were abruptly altered by context/sequence switches. Remarkably, the overall responsivity of the population remained highly consistent both within and between context/sequences because the gains versus losses were tightly balanced across neurons and across the three actions. These data are consistent with a reallocation mixture model in which individual neurons express unique mixtures of selectivity for different actions that become reallocated as task conditions change. However, because the allocations and reallocations are so well balanced across neurons, the population maintains a low but highly consistent response to all actions. The frontal cortex may therefore balance consistency with flexibility by having ensembles respond in a fixed way to task-relevant actions while abruptly reconfiguring single neurons to encode “actions in context.”</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('43','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_43" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1523/JNEUROSCI.3176-15.2016" title="Follow DOI:10.1523/JNEUROSCI.3176-15.2016" target="_blank">doi:10.1523/JNEUROSCI.3176-15.2016</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('43','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Hass, Joachim;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('44','tp_links')" style="cursor:pointer;">Time at the center, or time at the side? Assessing current models of time perception.</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Current Opinion in Behavioral Sciences, </span><span class="tp_pub_additional_volume">8 </span>, <span class="tp_pub_additional_pages">pp. Pages 238-244, </span><span class="tp_pub_additional_year">2016</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_44" class="tp_show" onclick="teachpress_pub_showhide('44','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_44" class="tp_show" onclick="teachpress_pub_showhide('44','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_44" class="tp_show" onclick="teachpress_pub_showhide('44','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_44" style="display:none;"><div class="tp_bibtex_entry">@article{Hass2016b,<br>
title = {Time at the center, or time at the side? Assessing current models of time perception.},<br>
author = {Joachim Hass and Daniel Durstewitz},<br>
url = {https://www.sciencedirect.com/science/article/pii/S2352154616300535},<br>
doi = {https://doi.org/10.1016/j.cobeha.2016.02.030},<br>
year  = {2016},<br>
date = {2016-04-01},<br>
journal = {Current Opinion in Behavioral Sciences},<br>
volume = {8},<br>
pages = {Pages 238-244},<br>
abstract = {The ability to tell time is a crucial requirement for almost everything we do, but the neural mechanisms of time perception are still largely unknown. One way to approach these mechanisms is through computational modeling. This review provides an overview of the most prominent timing models, experimental evidence in their support, and formal ways for understanding the relationship between mechanisms of time perception and the scaling behavior of time estimation errors. Theories that interpret timing as a byproduct of other computational processes are also discussed. We suggest that there may be in fact a multitude of timing mechanisms in operation, anchored within area-specific computations, and tailored to different sensory-behavioral requirements. These ultimately have to be integrated into a common frame (a ‘temporal hub’) for the purpose of decision making. This common frame may support Bayesian integration and generalization across sensory modalities.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('44','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_44" style="display:none;"><div class="tp_abstract_entry">The ability to tell time is a crucial requirement for almost everything we do, but the neural mechanisms of time perception are still largely unknown. One way to approach these mechanisms is through computational modeling. This review provides an overview of the most prominent timing models, experimental evidence in their support, and formal ways for understanding the relationship between mechanisms of time perception and the scaling behavior of time estimation errors. Theories that interpret timing as a byproduct of other computational processes are also discussed. We suggest that there may be in fact a multitude of timing mechanisms in operation, anchored within area-specific computations, and tailored to different sensory-behavioral requirements. These ultimately have to be integrated into a common frame (a ‘temporal hub’) for the purpose of decision making. This common frame may support Bayesian integration and generalization across sensory modalities.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('44','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_44" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.sciencedirect.com/science/article/pii/S2352154616300535" title="https://www.sciencedirect.com/science/article/pii/S2352154616300535" target="_blank">https://www.sciencedirect.com/science/article/pii/S2352154616300535</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/https://doi.org/10.1016/j.cobeha.2016.02.030" title="Follow DOI:https://doi.org/10.1016/j.cobeha.2016.02.030" target="_blank">doi:https://doi.org/10.1016/j.cobeha.2016.02.030</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('44','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel;  Koppe, Georgia;  Toutounji, Hazem</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('4','tp_links')" style="cursor:pointer;">Computational models as statistical tools</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Current Opinion in Behavioral Sciences, </span><span class="tp_pub_additional_volume">11 </span>, <span class="tp_pub_additional_pages">pp. 93–99, </span><span class="tp_pub_additional_year">2016</span>, <span class="tp_pub_additional_issn">ISSN: 23521546</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_4" class="tp_show" onclick="teachpress_pub_showhide('4','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_4" class="tp_show" onclick="teachpress_pub_showhide('4','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_4" class="tp_show" onclick="teachpress_pub_showhide('4','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_4" style="display:none;"><div class="tp_bibtex_entry">@article{Durstewitz2016,<br>
title = {Computational models as statistical tools},<br>
author = {Daniel Durstewitz and Georgia Koppe and Hazem Toutounji},<br>
url = {http://dx.doi.org/10.1016/j.cobeha.2016.07.004},<br>
doi = {10.1016/j.cobeha.2016.07.004},<br>
issn = {23521546},<br>
year  = {2016},<br>
date = {2016-01-01},<br>
journal = {Current Opinion in Behavioral Sciences},<br>
volume = {11},<br>
pages = {93--99},<br>
publisher = {Elsevier Ltd},<br>
abstract = {Traditionally, models in statistics are relatively simple ???general purpose??? quantitative inference tools, while models in computational neuroscience aim more at mechanistically explaining specific observations. Research on methods for inferring behavioral and neural models from data, however, has shown that a lot could be gained by merging these approaches, augmenting computational models with distributional assumptions. This enables estimation of parameters of such models in a principled way, comes with confidence regions that quantify uncertainty in estimates, and allows for quantitative assessment of prediction quality of computational models and tests of specific hypotheses about underlying mechanisms. Thus, unlike in conventional statistics, inferences about the latent dynamical mechanisms that generated the observed data can be drawn. Future directions and challenges of this approach are discussed.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('4','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_4" style="display:none;"><div class="tp_abstract_entry">Traditionally, models in statistics are relatively simple ???general purpose??? quantitative inference tools, while models in computational neuroscience aim more at mechanistically explaining specific observations. Research on methods for inferring behavioral and neural models from data, however, has shown that a lot could be gained by merging these approaches, augmenting computational models with distributional assumptions. This enables estimation of parameters of such models in a principled way, comes with confidence regions that quantify uncertainty in estimates, and allows for quantitative assessment of prediction quality of computational models and tests of specific hypotheses about underlying mechanisms. Thus, unlike in conventional statistics, inferences about the latent dynamical mechanisms that generated the observed data can be drawn. Future directions and challenges of this approach are discussed.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('4','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_4" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://dx.doi.org/10.1016/j.cobeha.2016.07.004" title="http://dx.doi.org/10.1016/j.cobeha.2016.07.004" target="_blank">http://dx.doi.org/10.1016/j.cobeha.2016.07.004</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1016/j.cobeha.2016.07.004" title="Follow DOI:10.1016/j.cobeha.2016.07.004" target="_blank">doi:10.1016/j.cobeha.2016.07.004</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('4','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Hass, Joachim;  Hertäg, Loreen;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('13','tp_links')" style="cursor:pointer;">A Detailed Data-Driven Network Model of Prefrontal Cortex Reproduces Key Features of In Vivo Activity</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLoS Computational Biology, </span><span class="tp_pub_additional_volume">12 </span><span class="tp_pub_additional_number">(5), </span><span class="tp_pub_additional_pages">pp. 1–29, </span><span class="tp_pub_additional_year">2016</span>, <span class="tp_pub_additional_issn">ISSN: 15537358</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_13" class="tp_show" onclick="teachpress_pub_showhide('13','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_13" class="tp_show" onclick="teachpress_pub_showhide('13','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_13" class="tp_show" onclick="teachpress_pub_showhide('13','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_13" style="display:none;"><div class="tp_bibtex_entry">@article{Hass2016,<br>
title = {A Detailed Data-Driven Network Model of Prefrontal Cortex Reproduces Key Features of In Vivo Activity},<br>
author = {Joachim Hass and Loreen Hertäg and Daniel Durstewitz},<br>
doi = {10.1371/journal.pcbi.1004930},<br>
issn = {15537358},<br>
year  = {2016},<br>
date = {2016-01-01},<br>
journal = {PLoS Computational Biology},<br>
volume = {12},<br>
number = {5},<br>
pages = {1--29},<br>
abstract = {textcopyright 2016 Hass et al. The prefrontal cortex is centrally involved in a wide range of cognitive functions and their impairment in psychiatric disorders. Yet, the computational principles that govern the dynamics of prefrontal neural networks, and link their physiological, biochemical and anatomical properties to cognitive functions, are not well understood. Computational models can help to bridge the gap between these different levels of description, provided they are sufficiently constrained by experimental data and capable of predicting key properties of the intact cortex. Here, we present a detailed network model of the prefrontal cortex, based on a simple computationally efficient single neuron model (simpAdEx), with all parameters derived from in vitro electrophysiological and anatomical data. Without additional tuning, this model could be shown to quantitatively reproduce a wide range of measures from in vivo electrophysiological recordings, to a degree where simulated and experimentally observed activities were statistically indistinguishable. These measures include spike train statistics, membrane potential fluctuations, local field potentials, and the transmission of transient stimulus information across layers. We further demonstrate that model predictions are robust against moderate changes in key parameters, and that synaptic heterogeneity is a crucial ingredient to the quantitative reproduction of in vivo-like electrophysiological behavior. Thus, we have produced a physiologically highly valid, in a quantitative sense, yet computationally efficient PFC network model, which helped to identify key properties underlying spike time dynamics as observed in vivo, and can be harvested for in-depth investigation of the links between physiology and cognition.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('13','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_13" style="display:none;"><div class="tp_abstract_entry">textcopyright 2016 Hass et al. The prefrontal cortex is centrally involved in a wide range of cognitive functions and their impairment in psychiatric disorders. Yet, the computational principles that govern the dynamics of prefrontal neural networks, and link their physiological, biochemical and anatomical properties to cognitive functions, are not well understood. Computational models can help to bridge the gap between these different levels of description, provided they are sufficiently constrained by experimental data and capable of predicting key properties of the intact cortex. Here, we present a detailed network model of the prefrontal cortex, based on a simple computationally efficient single neuron model (simpAdEx), with all parameters derived from in vitro electrophysiological and anatomical data. Without additional tuning, this model could be shown to quantitatively reproduce a wide range of measures from in vivo electrophysiological recordings, to a degree where simulated and experimentally observed activities were statistically indistinguishable. These measures include spike train statistics, membrane potential fluctuations, local field potentials, and the transmission of transient stimulus information across layers. We further demonstrate that model predictions are robust against moderate changes in key parameters, and that synaptic heterogeneity is a crucial ingredient to the quantitative reproduction of in vivo-like electrophysiological behavior. Thus, we have produced a physiologically highly valid, in a quantitative sense, yet computationally efficient PFC network model, which helped to identify key properties underlying spike time dynamics as observed in vivo, and can be harvested for in-depth investigation of the links between physiology and cognition.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('13','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_13" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pcbi.1004930" title="Follow DOI:10.1371/journal.pcbi.1004930" target="_blank">doi:10.1371/journal.pcbi.1004930</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('13','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2015">2015</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Demanuele, Charmaine ;  Bähner, Florian ;  Plichta, Michael ;  Kirsch, Peter ;  Tost, Heike ;  Meyer-Lindenberg, Andreas ;  Durstewitz, Daniel </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('45','tp_links')" style="cursor:pointer;">A statistical approach for segregating cognitive task stages from multivariate fMRI BOLD time series</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Frontiers in Human Neuroscience, </span><span class="tp_pub_additional_volume">9 </span>, <span class="tp_pub_additional_year">2015</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_45" class="tp_show" onclick="teachpress_pub_showhide('45','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_45" class="tp_show" onclick="teachpress_pub_showhide('45','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_45" class="tp_show" onclick="teachpress_pub_showhide('45','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_45" style="display:none;"><div class="tp_bibtex_entry">@article{Demanuele2015,<br>
title = {A statistical approach for segregating cognitive task stages from multivariate fMRI BOLD time series},<br>
author = {Demanuele, Charmaine and Bähner, Florian and Plichta, Michael and Kirsch, Peter and Tost, Heike and Meyer-Lindenberg, Andreas and Durstewitz, Daniel},<br>
url = {https://www.researchgate.net/publication/282647853_A_statistical_approach_for_segregating_cognitive_task_stages_from_multivariate_fMRI_BOLD_time_series},<br>
doi = {DOI: 10.3389/fnhum.2015.00537 },<br>
year  = {2015},<br>
date = {2015-09-01},<br>
journal = {Frontiers in Human Neuroscience},<br>
volume = {9},<br>
abstract = {Multivariate pattern analysis can reveal new information from neuroimaging data to illuminate human cognition and its disturbances. Here, we develop a methodological approach, based on multivariate statistical/machine learning and time series analysis, to discern cognitive processing stages from fMRI blood oxygenation level dependent (BOLD) time series. We apply this method to data recorded from a group of healthy adults whilst performing a virtual reality version of the delayed win-shift radial arm maze task. This task has been frequently used to study working memory and decision making in rodents. Using linear classifiers and multivariate test statistics in conjunction with time series bootstraps, we show that different cognitive stages of the task, as defined by the experimenter, namely, the encoding/retrieval, choice, reward and delay stages, can be statistically discriminated from the BOLD time series in brain areas relevant for decision making and working memory. Discrimination of these task stages was significantly reduced during poor behavioral performance in dorsolateral prefrontal cortex (DLPFC), but not in the primary visual cortex (V1). Experimenter-defined dissection of time series into class labels based on task structure was confirmed by an unsupervised, bottom-up approach based on Hidden Markov Models. Furthermore, we show that different groupings of recorded time points into cognitive event classes can be used to test hypotheses about the specific cognitive role of a given brain region during task execution. We found that whilst the DLPFC strongly differentiated between task stages associated with different memory loads, but not between different visual-spatial aspects, the reverse was true for V1. Our methodology illustrates how different aspects of cognitive information processing during one and the same task can be separated and attributed to specific brain regions based on information contained in multivariate patterns of voxel activity.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('45','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_45" style="display:none;"><div class="tp_abstract_entry">Multivariate pattern analysis can reveal new information from neuroimaging data to illuminate human cognition and its disturbances. Here, we develop a methodological approach, based on multivariate statistical/machine learning and time series analysis, to discern cognitive processing stages from fMRI blood oxygenation level dependent (BOLD) time series. We apply this method to data recorded from a group of healthy adults whilst performing a virtual reality version of the delayed win-shift radial arm maze task. This task has been frequently used to study working memory and decision making in rodents. Using linear classifiers and multivariate test statistics in conjunction with time series bootstraps, we show that different cognitive stages of the task, as defined by the experimenter, namely, the encoding/retrieval, choice, reward and delay stages, can be statistically discriminated from the BOLD time series in brain areas relevant for decision making and working memory. Discrimination of these task stages was significantly reduced during poor behavioral performance in dorsolateral prefrontal cortex (DLPFC), but not in the primary visual cortex (V1). Experimenter-defined dissection of time series into class labels based on task structure was confirmed by an unsupervised, bottom-up approach based on Hidden Markov Models. Furthermore, we show that different groupings of recorded time points into cognitive event classes can be used to test hypotheses about the specific cognitive role of a given brain region during task execution. We found that whilst the DLPFC strongly differentiated between task stages associated with different memory loads, but not between different visual-spatial aspects, the reverse was true for V1. Our methodology illustrates how different aspects of cognitive information processing during one and the same task can be separated and attributed to specific brain regions based on information contained in multivariate patterns of voxel activity.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('45','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_45" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.researchgate.net/publication/282647853_A_statistical_approach_for_segregating_cognitive_task_stages_from_multivariate_fMRI_BOLD_time_series" title="https://www.researchgate.net/publication/282647853_A_statistical_approach_for_se[...]" target="_blank">https://www.researchgate.net/publication/282647853_A_statistical_approach_for_se[...]</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/DOI:%2010.3389/fnhum.2015.00537%20" title="Follow DOI:DOI: 10.3389/fnhum.2015.00537 " target="_blank">doi:DOI: 10.3389/fnhum.2015.00537 </a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('45','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Demanuele, Charmaine;  Kirsch, Peter;  Esslinger, Christine;  Zink, Mathias;  Meyer-Lindenberg, Andreas;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('46','tp_links')" style="cursor:pointer;">Area-Specific Information Processing in Prefrontal Cortex during a Probabilistic Inference Task: A Multivariate fMRI BOLD Time Series Analysis</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLOS ONE, </span><span class="tp_pub_additional_year">2015</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_46" class="tp_show" onclick="teachpress_pub_showhide('46','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_46" class="tp_show" onclick="teachpress_pub_showhide('46','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_46" class="tp_show" onclick="teachpress_pub_showhide('46','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_46" style="display:none;"><div class="tp_bibtex_entry">@article{Demanuele2015b,<br>
title = {Area-Specific Information Processing in Prefrontal Cortex during a Probabilistic Inference Task: A Multivariate fMRI BOLD Time Series Analysis},<br>
author = {Charmaine Demanuele and Peter Kirsch and Christine Esslinger and Mathias Zink and Andreas Meyer-Lindenberg and Daniel Durstewitz},<br>
url = { https://doi.org/10.1371/journal.pone.0135424<br>
},<br>
doi = {10.1371/journal.pone.0135424},<br>
year  = {2015},<br>
date = {2015-08-10},<br>
journal = {PLOS ONE},<br>
abstract = {Discriminating spatiotemporal stages of information processing involved in complex cognitive processes remains a challenge for neuroscience. This is especially so in prefrontal cortex whose subregions, such as the dorsolateral prefrontal (DLPFC), anterior cingulate (ACC) and orbitofrontal (OFC) cortices are known to have differentiable roles in cognition. Yet it is much less clear how these subregions contribute to different cognitive processes required by a given task. To investigate this, we use functional MRI data recorded from a group of healthy adults during a “Jumping to Conclusions” probabilistic reasoning task.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('46','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_46" style="display:none;"><div class="tp_abstract_entry">Discriminating spatiotemporal stages of information processing involved in complex cognitive processes remains a challenge for neuroscience. This is especially so in prefrontal cortex whose subregions, such as the dorsolateral prefrontal (DLPFC), anterior cingulate (ACC) and orbitofrontal (OFC) cortices are known to have differentiable roles in cognition. Yet it is much less clear how these subregions contribute to different cognitive processes required by a given task. To investigate this, we use functional MRI data recorded from a group of healthy adults during a “Jumping to Conclusions” probabilistic reasoning task.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('46','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_46" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1371/journal.pone.0135424" title="https://doi.org/10.1371/journal.pone.0135424" target="_blank">https://doi.org/10.1371/journal.pone.0135424</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pone.0135424" title="Follow DOI:10.1371/journal.pone.0135424" target="_blank">doi:10.1371/journal.pone.0135424</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('46','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Florian Bähner  Charmaine Demanuele, Janina Schweiger Martin Gerchen Vera Zamoscik Kai Ueltzhöffer Tim Hahn Patric Meyer Herta Flor Daniel Durstewitz Heike Tost Peter Kirsch Michael Plichta & Andreas Meyer-Lindenberg F          M</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('47','tp_links')" style="cursor:pointer;">Hippocampal-dorsolateral prefrontal coupling as a species-conserved cognitive mechanism: a human translational imaging study</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Neuropsychopharmacology, </span><span class="tp_pub_additional_volume">40 </span><span class="tp_pub_additional_number">(7), </span><span class="tp_pub_additional_pages">pp. 1674-81, </span><span class="tp_pub_additional_year">2015</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_47" class="tp_show" onclick="teachpress_pub_showhide('47','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_47" class="tp_show" onclick="teachpress_pub_showhide('47','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_47" class="tp_show" onclick="teachpress_pub_showhide('47','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_47" style="display:none;"><div class="tp_bibtex_entry">@article{Bähner2015,<br>
title = {Hippocampal-dorsolateral prefrontal coupling as a species-conserved cognitive mechanism: a human translational imaging study},<br>
author = {Florian Bähner, Charmaine Demanuele, Janina Schweiger, Martin F Gerchen, Vera Zamoscik, Kai Ueltzhöffer, Tim Hahn, Patric Meyer, Herta Flor, Daniel Durstewitz, Heike Tost, Peter Kirsch, Michael M Plichta & Andreas Meyer-Lindenberg},<br>
url = {https://www.nature.com/articles/npp201513},<br>
year  = {2015},<br>
date = {2015-06-01},<br>
journal = {Neuropsychopharmacology},<br>
volume = {40},<br>
number = {7},<br>
pages = {1674-81},<br>
abstract = {Hippocampal–prefrontal cortex (HC–PFC) interactions are implicated in working memory (WM) and altered in psychiatric conditions with cognitive impairment such as schizophrenia. While coupling between both structures is crucial for WM performance in rodents, evidence from human studies is conflicting and translation of findings is complicated by the use of differing paradigms across species. We therefore used functional magnetic resonance imaging together with a spatial WM paradigm adapted from rodent research to examine HC–PFC coupling in humans. A PFC–parietal network was functionally connected to hippocampus (HC) during task stages requiring high levels of executive control but not during a matched control condition. The magnitude of coupling in a network comprising HC, bilateral dorsolateral PFC (DLPFC), and right supramarginal gyrus explained one-fourth of the variability in an independent spatial WM task but was unrelated to visual WM performance. HC–DLPFC coupling may thus represent a systems-level mechanism specific to spatial WM that is conserved across species, suggesting its utility for modeling cognitive dysfunction in translational neuroscience.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('47','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_47" style="display:none;"><div class="tp_abstract_entry">Hippocampal–prefrontal cortex (HC–PFC) interactions are implicated in working memory (WM) and altered in psychiatric conditions with cognitive impairment such as schizophrenia. While coupling between both structures is crucial for WM performance in rodents, evidence from human studies is conflicting and translation of findings is complicated by the use of differing paradigms across species. We therefore used functional magnetic resonance imaging together with a spatial WM paradigm adapted from rodent research to examine HC–PFC coupling in humans. A PFC–parietal network was functionally connected to hippocampus (HC) during task stages requiring high levels of executive control but not during a matched control condition. The magnitude of coupling in a network comprising HC, bilateral dorsolateral PFC (DLPFC), and right supramarginal gyrus explained one-fourth of the variability in an independent spatial WM task but was unrelated to visual WM performance. HC–DLPFC coupling may thus represent a systems-level mechanism specific to spatial WM that is conserved across species, suggesting its utility for modeling cognitive dysfunction in translational neuroscience.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('47','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_47" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.nature.com/articles/npp201513" title="https://www.nature.com/articles/npp201513" target="_blank">https://www.nature.com/articles/npp201513</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('47','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Kucewicz, Michal T;  Kucewicz, Michal T;  Durstewitz, Daniel;  Tricklebank, Mark D;  Jones, Matt;  Laubach, Mark;  Fujisawa, Shigeyoshi;  Pennartz, Cyriel;  Shapiro, Matthew;  Hampson, Robert;  Deadwyler, Samuel</p><p class="tp_pub_title">Decoding the sequential contributions of hippocampal-prefrontal neuronal assemblies to spatial working memory <span class="tp_pub_type unpublished">Unpublished</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_year">2015</span>.</p><p class="tp_pub_tags"><span class="tp_bibtex_link"><a id="tp_bibtex_sh_8" class="tp_show" onclick="teachpress_pub_showhide('8','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_8" style="display:none;"><div class="tp_bibtex_entry">@unpublished{Kucewicz2015,<br>
title = {Decoding the sequential contributions of hippocampal-prefrontal neuronal assemblies to spatial working memory},<br>
author = {Michal T Kucewicz and Michal T Kucewicz and Daniel Durstewitz and Mark D Tricklebank and Matt Jones and Mark Laubach and Shigeyoshi Fujisawa and Cyriel Pennartz and Matthew Shapiro and Robert Hampson and Samuel Deadwyler},<br>
year  = {2015},<br>
date = {2015-01-01},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {unpublished}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('8','tp_bibtex')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Lapish, Christopher C;  Balaguer-ballester, Emili;  Seamans, Jeremy K;  Phillips, Anthony G;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('25','tp_links')" style="cursor:pointer;">Amphetamine Exerts Dose-Dependent Changes in Prefrontal Cortex Attractor Dynamics during Working Memory</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_volume">35 </span><span class="tp_pub_additional_number">(28), </span><span class="tp_pub_additional_pages">pp. 10172–10187, </span><span class="tp_pub_additional_year">2015</span>.</p><p class="tp_pub_tags"><span class="tp_resource_link"><a id="tp_links_sh_25" class="tp_show" onclick="teachpress_pub_showhide('25','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_25" class="tp_show" onclick="teachpress_pub_showhide('25','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_25" style="display:none;"><div class="tp_bibtex_entry">@article{Lapish2015,<br>
title = {Amphetamine Exerts Dose-Dependent Changes in Prefrontal Cortex Attractor Dynamics during Working Memory},<br>
author = {Christopher C Lapish and Emili Balaguer-ballester and Jeremy K Seamans and Anthony G Phillips and Daniel Durstewitz},<br>
doi = {10.1523/JNEUROSCI.2421-14.2015},<br>
year  = {2015},<br>
date = {2015-01-01},<br>
volume = {35},<br>
number = {28},<br>
pages = {10172--10187},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('25','tp_bibtex')">Close</a></p></div><div class="tp_links" id="tp_links_25" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1523/JNEUROSCI.2421-14.2015" title="Follow DOI:10.1523/JNEUROSCI.2421-14.2015" target="_blank">doi:10.1523/JNEUROSCI.2421-14.2015</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('25','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2014">2014</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Joachim Hass, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('50','tp_links')" style="cursor:pointer;">Neurocomputational models of time perception</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal"> Adv Exp Med Biol, </span><span class="tp_pub_additional_number">(829), </span><span class="tp_pub_additional_pages">pp. 49-71, </span><span class="tp_pub_additional_year">2014</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_50" class="tp_show" onclick="teachpress_pub_showhide('50','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_50" class="tp_show" onclick="teachpress_pub_showhide('50','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_50" class="tp_show" onclick="teachpress_pub_showhide('50','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_50" style="display:none;"><div class="tp_bibtex_entry">@article{Hass2014,<br>
title = {Neurocomputational models of time perception},<br>
author = {Joachim Hass, Daniel Durstewitz<br>
},<br>
url = {https://pubmed.ncbi.nlm.nih.gov/25358705/},<br>
doi = {10.1007/978-1-4939-1782-2_4 },<br>
year  = {2014},<br>
date = {2014-10-10},<br>
journal = { Adv Exp Med Biol},<br>
number = {829},<br>
pages = {49-71},<br>
abstract = {Mathematical modeling is a useful tool for understanding the neurodynamical and computational mechanisms of cognitive abilities like time perception, and for linking neurophysiology to psychology. In this chapter, we discuss several biophysical models of time perception and how they can be tested against experimental evidence. After a brief overview on the history of computational timing models, we list a number of central psychological and physiological findings that such a model should be able to account for, with a focus on the scaling of the variability of duration estimates with the length of the interval that needs to be estimated. The functional form of this scaling turns out to be predictive of the underlying computational mechanism for time perception. We then present four basic classes of timing models (ramping activity, sequential activation of neuron populations, state space trajectories and neural oscillators) and discuss two specific examples in more detail. Finally, we review to what extent existing theories of time perception adhere to the experimental constraints. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('50','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_50" style="display:none;"><div class="tp_abstract_entry">Mathematical modeling is a useful tool for understanding the neurodynamical and computational mechanisms of cognitive abilities like time perception, and for linking neurophysiology to psychology. In this chapter, we discuss several biophysical models of time perception and how they can be tested against experimental evidence. After a brief overview on the history of computational timing models, we list a number of central psychological and physiological findings that such a model should be able to account for, with a focus on the scaling of the variability of duration estimates with the length of the interval that needs to be estimated. The functional form of this scaling turns out to be predictive of the underlying computational mechanism for time perception. We then present four basic classes of timing models (ramping activity, sequential activation of neuron populations, state space trajectories and neural oscillators) and discuss two specific examples in more detail. Finally, we review to what extent existing theories of time perception adhere to the experimental constraints. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('50','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_50" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://pubmed.ncbi.nlm.nih.gov/25358705/" title="https://pubmed.ncbi.nlm.nih.gov/25358705/" target="_blank">https://pubmed.ncbi.nlm.nih.gov/25358705/</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1007/978-1-4939-1782-2_4%20" title="Follow DOI:10.1007/978-1-4939-1782-2_4 " target="_blank">doi:10.1007/978-1-4939-1782-2_4 </a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('50','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Loreen Hertäg, Daniel Durstewitz ;  Brunel, Nicolas</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('49','tp_links')" style="cursor:pointer;">Analytical approximations of the firing rate of an adaptive exponential integrate-and-fire neuron in the presence of synaptic noise</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Frontiers Computational Neuroscience, </span><span class="tp_pub_additional_volume">8 </span><span class="tp_pub_additional_number">(116), </span><span class="tp_pub_additional_year">2014</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_49" class="tp_show" onclick="teachpress_pub_showhide('49','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_49" class="tp_show" onclick="teachpress_pub_showhide('49','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_49" class="tp_show" onclick="teachpress_pub_showhide('49','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_49" style="display:none;"><div class="tp_bibtex_entry">@article{Hertäg2014,<br>
title = {Analytical approximations of the firing rate of an adaptive exponential integrate-and-fire neuron in the presence of synaptic noise},<br>
author = {Loreen Hertäg, Daniel Durstewitz and Nicolas Brunel},<br>
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4167001/},<br>
doi = {10.3389/fncom.2014.00116},<br>
year  = {2014},<br>
date = {2014-09-18},<br>
journal = {Frontiers Computational Neuroscience},<br>
volume = {8},<br>
number = {116},<br>
abstract = {Computational models offer a unique tool for understanding the network-dynamical mechanisms which mediate between physiological and biophysical properties, and behavioral function. A traditional challenge in computational neuroscience is, however, that simple neuronal models which can be studied analytically fail to reproduce the diversity of electrophysiological behaviors seen in real neurons, while detailed neuronal models which do reproduce such diversity are intractable analytically and computationally expensive. A number of intermediate models have been proposed whose aim is to capture the diversity of firing behaviors and spike times of real neurons while entailing the simplest possible mathematical description. One such model is the exponential integrate-and-fire neuron with spike rate adaptation (aEIF) which consists of two differential equations for the membrane potential (V) and an adaptation current (w). Despite its simplicity, it can reproduce a wide variety of physiologically observed spiking patterns, can be fit to physiological recordings quantitatively, and, once done so, is able to predict spike times on traces not used for model fitting. Here we compute the steady-state firing rate of aEIF in the presence of Gaussian synaptic noise, using two approaches. The first approach is based on the 2-dimensional Fokker-Planck equation that describes the (V,w)-probability distribution, which is solved using an expansion in the ratio between the time constants of the two variables. The second is based on the firing rate of the EIF model, which is averaged over the distribution of the w variable. These analytically derived closed-form expressions were tested on simulations from a large variety of model cells quantitatively fitted to in vitro electrophysiological recordings from pyramidal cells and interneurons. Theoretical predictions closely agreed with the firing rate of the simulated cells fed with in-vivo-like synaptic noise.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('49','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_49" style="display:none;"><div class="tp_abstract_entry">Computational models offer a unique tool for understanding the network-dynamical mechanisms which mediate between physiological and biophysical properties, and behavioral function. A traditional challenge in computational neuroscience is, however, that simple neuronal models which can be studied analytically fail to reproduce the diversity of electrophysiological behaviors seen in real neurons, while detailed neuronal models which do reproduce such diversity are intractable analytically and computationally expensive. A number of intermediate models have been proposed whose aim is to capture the diversity of firing behaviors and spike times of real neurons while entailing the simplest possible mathematical description. One such model is the exponential integrate-and-fire neuron with spike rate adaptation (aEIF) which consists of two differential equations for the membrane potential (V) and an adaptation current (w). Despite its simplicity, it can reproduce a wide variety of physiologically observed spiking patterns, can be fit to physiological recordings quantitatively, and, once done so, is able to predict spike times on traces not used for model fitting. Here we compute the steady-state firing rate of aEIF in the presence of Gaussian synaptic noise, using two approaches. The first approach is based on the 2-dimensional Fokker-Planck equation that describes the (V,w)-probability distribution, which is solved using an expansion in the ratio between the time constants of the two variables. The second is based on the firing rate of the EIF model, which is averaged over the distribution of the w variable. These analytically derived closed-form expressions were tested on simulations from a large variety of model cells quantitatively fitted to in vitro electrophysiological recordings from pyramidal cells and interneurons. Theoretical predictions closely agreed with the firing rate of the simulated cells fed with in-vivo-like synaptic noise.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('49','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_49" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4167001/" title="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4167001/" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4167001/</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.3389/fncom.2014.00116" title="Follow DOI:10.3389/fncom.2014.00116" target="_blank">doi:10.3389/fncom.2014.00116</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('49','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2013">2013</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Rainer Spanagel  Daniel Durstewitz, Anita Hansson Andreas Heinz Falk Kiefer Georg Köhr Franziska Matthäus Markus Nöthen Hamid Noori Klaus Obermayer Marcella Rietschel Patrick Schloss Henrike Scholz Gunter Schumann Michael Smolka Wolfgang Sommer Valentina Vengeliene Henrik Walter Wolfgang Wurst Uli Zimmermann Addiction GWAS Resource Group; Sven Stringer Yannick Smits Eske Derks M  R            S    M</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('51','tp_links')" style="cursor:pointer;">A systems medicine research approach for studying alcohol addiction</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Addiction Biology, </span><span class="tp_pub_additional_volume">18 </span><span class="tp_pub_additional_number">(6), </span><span class="tp_pub_additional_year">2013</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_51" class="tp_show" onclick="teachpress_pub_showhide('51','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_51" class="tp_show" onclick="teachpress_pub_showhide('51','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_51" class="tp_show" onclick="teachpress_pub_showhide('51','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_51" style="display:none;"><div class="tp_bibtex_entry">@article{Spanagel2013,<br>
title = {A systems medicine research approach for studying alcohol addiction},<br>
author = {<br>
Rainer Spanagel, Daniel Durstewitz, Anita Hansson, Andreas Heinz, Falk Kiefer, Georg Köhr, Franziska Matthäus, Markus M Nöthen, Hamid R Noori, Klaus Obermayer, Marcella Rietschel, Patrick Schloss, Henrike Scholz, Gunter Schumann, Michael Smolka, Wolfgang Sommer, Valentina Vengeliene, Henrik Walter, Wolfgang Wurst, Uli S Zimmermann, Addiction GWAS Resource Group; Sven Stringer, Yannick Smits, Eske M Derks},<br>
url = {https://pubmed.ncbi.nlm.nih.gov/24283978/},<br>
doi = {10.1111/adb.12109},<br>
year  = {2013},<br>
date = {2013-11-01},<br>
journal = {Addiction Biology},<br>
volume = {18},<br>
number = {6},<br>
abstract = {According to the World Health Organization, about 2 billion people drink alcohol. Excessive alcohol consumption can result in alcohol addiction, which is one of the most prevalent neuropsychiatric diseases afflicting our society today. Prevention and intervention of alcohol binging in adolescents and treatment of alcoholism are major unmet challenges affecting our health-care system and society alike. Our newly formed German SysMedAlcoholism consortium is using a new systems medicine approach and intends (1) to define individual neurobehavioral risk profiles in adolescents that are predictive of alcohol use disorders later in life and (2) to identify new pharmacological targets and molecules for the treatment of alcoholism. To achieve these goals, we will use omics-information from epigenomics, genetics transcriptomics, neurodynamics, global neurochemical connectomes and neuroimaging (IMAGEN; Schumann et al. ) to feed mathematical prediction modules provided by two Bernstein Centers for Computational Neurosciences (Berlin and Heidelberg/Mannheim), the results of which will subsequently be functionally validated in independent clinical samples and appropriate animal models. This approach will lead to new early intervention strategies and identify innovative molecules for relapse prevention that will be tested in experimental human studies. This research program will ultimately help in consolidating addiction research clusters in Germany that can effectively conduct large clinical trials, implement early intervention strategies and impact political and healthcare decision makers. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('51','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_51" style="display:none;"><div class="tp_abstract_entry">According to the World Health Organization, about 2 billion people drink alcohol. Excessive alcohol consumption can result in alcohol addiction, which is one of the most prevalent neuropsychiatric diseases afflicting our society today. Prevention and intervention of alcohol binging in adolescents and treatment of alcoholism are major unmet challenges affecting our health-care system and society alike. Our newly formed German SysMedAlcoholism consortium is using a new systems medicine approach and intends (1) to define individual neurobehavioral risk profiles in adolescents that are predictive of alcohol use disorders later in life and (2) to identify new pharmacological targets and molecules for the treatment of alcoholism. To achieve these goals, we will use omics-information from epigenomics, genetics transcriptomics, neurodynamics, global neurochemical connectomes and neuroimaging (IMAGEN; Schumann et al. ) to feed mathematical prediction modules provided by two Bernstein Centers for Computational Neurosciences (Berlin and Heidelberg/Mannheim), the results of which will subsequently be functionally validated in independent clinical samples and appropriate animal models. This approach will lead to new early intervention strategies and identify innovative molecules for relapse prevention that will be tested in experimental human studies. This research program will ultimately help in consolidating addiction research clusters in Germany that can effectively conduct large clinical trials, implement early intervention strategies and impact political and healthcare decision makers. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('51','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_51" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://pubmed.ncbi.nlm.nih.gov/24283978/" title="https://pubmed.ncbi.nlm.nih.gov/24283978/" target="_blank">https://pubmed.ncbi.nlm.nih.gov/24283978/</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1111/adb.12109" title="Follow DOI:10.1111/adb.12109" target="_blank">doi:10.1111/adb.12109</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('51','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Claudio S. Quiroga-Lombard, Joachim Hass ;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('52','tp_links')" style="cursor:pointer;">Method for stationarity-segmentation of spike train data with application to the Pearson cross-correlation</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Journal of Neurophysiology, </span><span class="tp_pub_additional_year">2013</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_52" class="tp_show" onclick="teachpress_pub_showhide('52','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_52" class="tp_show" onclick="teachpress_pub_showhide('52','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_52" class="tp_show" onclick="teachpress_pub_showhide('52','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_52" style="display:none;"><div class="tp_bibtex_entry">@article{Quiroga-Lombard2013,<br>
title = {Method for stationarity-segmentation of spike train data with application to the Pearson cross-correlation},<br>
author = {Claudio S. Quiroga-Lombard, Joachim Hass and Daniel Durstewitz},<br>
url = {https://doi.org/10.1152/jn.00186.2013},<br>
doi = {10.1152/jn.00186.2013},<br>
year  = {2013},<br>
date = {2013-07-15},<br>
journal = {Journal of Neurophysiology},<br>
abstract = {Correlations among neurons are supposed to play an important role in computation and information coding in the nervous system. Empirically, functional interactions between neurons are most commonly assessed by cross-correlation functions. Recent studies have suggested that pairwise correlations may indeed be sufficient to capture most of the information present in neural interactions. Many applications of correlation functions, however, implicitly tend to assume that the underlying processes are stationary. This assumption will usually fail for real neurons recorded in vivo since their activity during behavioral tasks is heavily influenced by stimulus-, movement-, or cognition-related processes as well as by more general processes like slow oscillations or changes in state of alertness. To address the problem of nonstationarity, we introduce a method for assessing stationarity empirically and then “slicing” spike trains into stationary segments according to the statistical definition of weak-sense stationarity. We examine pairwise Pearson cross-correlations (PCCs) under both stationary and nonstationary conditions and identify another source of covariance that can be differentiated from the covariance of the spike times and emerges as a consequence of residual nonstationarities after the slicing process: the covariance of the firing rates defined on each segment. Based on this, a correction of the PCC is introduced that accounts for the effect of segmentation. We probe these methods both on simulated data sets and on in vivo recordings from the prefrontal cortex of behaving rats. Rather than for removing nonstationarities, the present method may also be used for detecting significant events in spike trains.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('52','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_52" style="display:none;"><div class="tp_abstract_entry">Correlations among neurons are supposed to play an important role in computation and information coding in the nervous system. Empirically, functional interactions between neurons are most commonly assessed by cross-correlation functions. Recent studies have suggested that pairwise correlations may indeed be sufficient to capture most of the information present in neural interactions. Many applications of correlation functions, however, implicitly tend to assume that the underlying processes are stationary. This assumption will usually fail for real neurons recorded in vivo since their activity during behavioral tasks is heavily influenced by stimulus-, movement-, or cognition-related processes as well as by more general processes like slow oscillations or changes in state of alertness. To address the problem of nonstationarity, we introduce a method for assessing stationarity empirically and then “slicing” spike trains into stationary segments according to the statistical definition of weak-sense stationarity. We examine pairwise Pearson cross-correlations (PCCs) under both stationary and nonstationary conditions and identify another source of covariance that can be differentiated from the covariance of the spike times and emerges as a consequence of residual nonstationarities after the slicing process: the covariance of the firing rates defined on each segment. Based on this, a correction of the PCC is introduced that accounts for the effect of segmentation. We probe these methods both on simulated data sets and on in vivo recordings from the prefrontal cortex of behaving rats. Rather than for removing nonstationarities, the present method may also be used for detecting significant events in spike trains.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('52','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_52" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1152/jn.00186.2013" title="https://doi.org/10.1152/jn.00186.2013" target="_blank">https://doi.org/10.1152/jn.00186.2013</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1152/jn.00186.2013" title="Follow DOI:10.1152/jn.00186.2013" target="_blank">doi:10.1152/jn.00186.2013</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('52','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Sophie Helene Richter   Benjamin Zeuch, Katja Lankisch Peter Gass Daniel Durstewitz Barbara Vollmayr </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('53','tp_links')" style="cursor:pointer;">Where Have I Been? Where Should I Go? Spatial Working Memory on a Radial Arm Maze in a Rat Model of Depression</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLOS ONE, </span><span class="tp_pub_additional_year">2013</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_53" class="tp_show" onclick="teachpress_pub_showhide('53','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_53" class="tp_show" onclick="teachpress_pub_showhide('53','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_53" class="tp_show" onclick="teachpress_pub_showhide('53','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_53" style="display:none;"><div class="tp_bibtex_entry">@article{Richter2013,<br>
title = {Where Have I Been? Where Should I Go? Spatial Working Memory on a Radial Arm Maze in a Rat Model of Depression},<br>
author = {Sophie Helene Richter , Benjamin Zeuch, Katja Lankisch, Peter Gass, Daniel Durstewitz, Barbara Vollmayr<br>
},<br>
url = { https://doi.org/10.1371/journal.pone.0062458},<br>
doi = {10.1371/journal.pone.0062458},<br>
year  = {2013},<br>
date = {2013-04-13},<br>
journal = {PLOS ONE},<br>
abstract = {Disturbances in cognitive functioning are among the most debilitating problems experienced by patients with major depression. Investigations of these deficits in animals help to extend and refine our understanding of human emotional disorder, while at the same time providing valid tools to study higher executive functions in animals. We employ the “learned helplessness” genetic rat model of depression in studying working memory using an eight arm radial maze procedure with temporal delay. This so-called delayed spatial win-shift task consists of three phases, training, delay and test, requiring rats to hold information on-line across a retention interval and making choices based on this information in the test phase. According to a 2×2 factorial design, working memory performance of thirty-one congenitally helpless (cLH) and non-helpless (cNLH) rats was tested on eighteen trials, additionally imposing two different delay durations, 30 s and 15 min, respectively. While not observing a general cognitive deficit in cLH rats, the delay length greatly influenced maze performance. Notably, performance was most impaired in cLH rats tested with the shorter 30 s delay, suggesting a stress-related disruption of attentional processes in rats that are more sensitive to stress. Our study provides direct animal homologues of clinically important measures in human research, and contributes to the non-invasive assessment of cognitive deficits associated with depression.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('53','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_53" style="display:none;"><div class="tp_abstract_entry">Disturbances in cognitive functioning are among the most debilitating problems experienced by patients with major depression. Investigations of these deficits in animals help to extend and refine our understanding of human emotional disorder, while at the same time providing valid tools to study higher executive functions in animals. We employ the “learned helplessness” genetic rat model of depression in studying working memory using an eight arm radial maze procedure with temporal delay. This so-called delayed spatial win-shift task consists of three phases, training, delay and test, requiring rats to hold information on-line across a retention interval and making choices based on this information in the test phase. According to a 2×2 factorial design, working memory performance of thirty-one congenitally helpless (cLH) and non-helpless (cNLH) rats was tested on eighteen trials, additionally imposing two different delay durations, 30 s and 15 min, respectively. While not observing a general cognitive deficit in cLH rats, the delay length greatly influenced maze performance. Notably, performance was most impaired in cLH rats tested with the shorter 30 s delay, suggesting a stress-related disruption of attentional processes in rats that are more sensitive to stress. Our study provides direct animal homologues of clinically important measures in human research, and contributes to the non-invasive assessment of cognitive deficits associated with depression.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('53','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_53" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://doi.org/10.1371/journal.pone.0062458" title="https://doi.org/10.1371/journal.pone.0062458" target="_blank">https://doi.org/10.1371/journal.pone.0062458</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pone.0062458" title="Follow DOI:10.1371/journal.pone.0062458" target="_blank">doi:10.1371/journal.pone.0062458</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('53','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2012">2012</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> James M Hyman   Liya Ma, Emili Balaguer-Ballester Daniel Durstewitz Jeremy Seamans K</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('54','tp_links')" style="cursor:pointer;">Contextual encoding by ensembles of medial prefrontal cortex neurons</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Proceedings of the National Academy of Sciences, </span><span class="tp_pub_additional_year">2012</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_54" class="tp_show" onclick="teachpress_pub_showhide('54','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_54" class="tp_show" onclick="teachpress_pub_showhide('54','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_54" class="tp_show" onclick="teachpress_pub_showhide('54','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_54" style="display:none;"><div class="tp_bibtex_entry">@article{Hyman2012,<br>
title = {Contextual encoding by ensembles of medial prefrontal cortex neurons},<br>
author = {James M Hyman , Liya Ma, Emili Balaguer-Ballester, Daniel Durstewitz, Jeremy K Seamans<br>
},<br>
url = {https://pubmed.ncbi.nlm.nih.gov/22421138/},<br>
doi = {10.1073/pnas.1114415109 },<br>
year  = {2012},<br>
date = {2012-03-27},<br>
journal = {Proceedings of the National Academy of Sciences},<br>
abstract = {Contextual representations serve to guide many aspects of behavior and influence the way stimuli or actions are encoded and interpreted. The medial prefrontal cortex (mPFC), including the anterior cingulate subregion, has been implicated in contextual encoding, yet the nature of contextual representations formed by the mPFC is unclear. Using multiple single-unit tetrode recordings in rats, we found that different activity patterns emerged in mPFC ensembles when animals moved between different environmental contexts. These differences in activity patterns were significantly larger than those observed for hippocampal ensembles. Whereas ≈11% of mPFC cells consistently preferred one environment over the other across multiple exposures to the same environments, optimal decoding (prediction) of the environmental setting occurred when the activity of up to ≈50% of all mPFC neurons was taken into account. On the other hand, population activity patterns were not identical upon repeated exposures to the very same environment. This was partly because the state of mPFC ensembles seemed to systematically shift with time, such that we could sometimes predict the change in ensemble state upon later reentry into one environment according to linear extrapolation from the time-dependent shifts observed during the first exposure. We also observed that many strongly action-selective mPFC neurons exhibited a significant degree of context-dependent modulation. These results highlight potential differences in contextual encoding schemes by the mPFC and hippocampus and suggest that the mPFC forms rich contextual representations that take into account not only sensory cues but also actions and time. },<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('54','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_54" style="display:none;"><div class="tp_abstract_entry">Contextual representations serve to guide many aspects of behavior and influence the way stimuli or actions are encoded and interpreted. The medial prefrontal cortex (mPFC), including the anterior cingulate subregion, has been implicated in contextual encoding, yet the nature of contextual representations formed by the mPFC is unclear. Using multiple single-unit tetrode recordings in rats, we found that different activity patterns emerged in mPFC ensembles when animals moved between different environmental contexts. These differences in activity patterns were significantly larger than those observed for hippocampal ensembles. Whereas ≈11% of mPFC cells consistently preferred one environment over the other across multiple exposures to the same environments, optimal decoding (prediction) of the environmental setting occurred when the activity of up to ≈50% of all mPFC neurons was taken into account. On the other hand, population activity patterns were not identical upon repeated exposures to the very same environment. This was partly because the state of mPFC ensembles seemed to systematically shift with time, such that we could sometimes predict the change in ensemble state upon later reentry into one environment according to linear extrapolation from the time-dependent shifts observed during the first exposure. We also observed that many strongly action-selective mPFC neurons exhibited a significant degree of context-dependent modulation. These results highlight potential differences in contextual encoding schemes by the mPFC and hippocampus and suggest that the mPFC forms rich contextual representations that take into account not only sensory cues but also actions and time. </div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('54','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_54" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://pubmed.ncbi.nlm.nih.gov/22421138/" title="https://pubmed.ncbi.nlm.nih.gov/22421138/" target="_blank">https://pubmed.ncbi.nlm.nih.gov/22421138/</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1073/pnas.1114415109%20" title="Follow DOI:10.1073/pnas.1114415109 " target="_blank">doi:10.1073/pnas.1114415109 </a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('54','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Hertäg, Loreen;  Hass, Joachim;  Golovko, Tatiana;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('17','tp_links')" style="cursor:pointer;">An Approximation to the Adaptive Exponential Integrate-and-Fire Neuron Model Allows Fast and Predictive Fitting to Physiological Data</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Frontiers in Computational Neuroscience, </span><span class="tp_pub_additional_volume">6 </span><span class="tp_pub_additional_number">(September), </span><span class="tp_pub_additional_pages">pp. 1–22, </span><span class="tp_pub_additional_year">2012</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_17" class="tp_show" onclick="teachpress_pub_showhide('17','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_17" class="tp_show" onclick="teachpress_pub_showhide('17','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_17" class="tp_show" onclick="teachpress_pub_showhide('17','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_17" style="display:none;"><div class="tp_bibtex_entry">@article{Hertag2012,<br>
title = {An Approximation to the Adaptive Exponential Integrate-and-Fire Neuron Model Allows Fast and Predictive Fitting to Physiological Data},<br>
author = {Loreen Hertäg and Joachim Hass and Tatiana Golovko and Daniel Durstewitz},<br>
doi = {10.3389/fncom.2012.00062},<br>
year  = {2012},<br>
date = {2012-01-01},<br>
journal = {Frontiers in Computational Neuroscience},<br>
volume = {6},<br>
number = {September},<br>
pages = {1--22},<br>
abstract = {For large-scale network simulations, it is often desirable to have computationally tractable, yet in a defined sense still physiologically valid neuron models. In particular, these models should be able to reproduce physiological measurements, ideally in a predictive sense, and under different input regimes in which neurons may operate in vivo. Here we present an approach to parameter estimation for a simple spiking neuron model mainly based on standard f-I curves obtained from in vitro recordings. Such recordings are routinely obtained in standard protocols and assess a neuron's response under a wide range of mean input currents. Our fitting procedure makes use of closed-form expressions for the firing rate derived from an approximation to the adaptive exponential integrate-and-fire (AdEx) model. The resulting fitting process is simple and about two orders of magnitude faster compared to methods based on numerical integration of the differential equations. We probe this method on different cell types recorded from rodent prefrontal cortex. After fitting to the f-I current-clamp data, the model cells are tested on completely different sets of recordings obtained by fluctuating ('invivo-like') input currents. For a wide range of different input regimes, cell types, and cortical layers, the model could predict spike times on these test traces quite accurately within the bounds of physiological reliability, although no information from these distinct test sets was used for model fitting. Further analyses delineated some of the empirical factors constraining model fitting and the model's generalization performance. An even simpler adaptive LIF neuron was also examined in this context. Hence, we have developed a 'high-throughput' model fitting procedure which is simple and fast, with good prediction performance, and which relies only on firing rate information and standard physiological data widely and easily available. textcopyright 2012 Hertäg, Hass, Golovko and Durstewitz.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('17','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_17" style="display:none;"><div class="tp_abstract_entry">For large-scale network simulations, it is often desirable to have computationally tractable, yet in a defined sense still physiologically valid neuron models. In particular, these models should be able to reproduce physiological measurements, ideally in a predictive sense, and under different input regimes in which neurons may operate in vivo. Here we present an approach to parameter estimation for a simple spiking neuron model mainly based on standard f-I curves obtained from in vitro recordings. Such recordings are routinely obtained in standard protocols and assess a neuron's response under a wide range of mean input currents. Our fitting procedure makes use of closed-form expressions for the firing rate derived from an approximation to the adaptive exponential integrate-and-fire (AdEx) model. The resulting fitting process is simple and about two orders of magnitude faster compared to methods based on numerical integration of the differential equations. We probe this method on different cell types recorded from rodent prefrontal cortex. After fitting to the f-I current-clamp data, the model cells are tested on completely different sets of recordings obtained by fluctuating ('invivo-like') input currents. For a wide range of different input regimes, cell types, and cortical layers, the model could predict spike times on these test traces quite accurately within the bounds of physiological reliability, although no information from these distinct test sets was used for model fitting. Further analyses delineated some of the empirical factors constraining model fitting and the model's generalization performance. An even simpler adaptive LIF neuron was also examined in this context. Hence, we have developed a 'high-throughput' model fitting procedure which is simple and fast, with good prediction performance, and which relies only on firing rate information and standard physiological data widely and easily available. textcopyright 2012 Hertäg, Hass, Golovko and Durstewitz.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('17','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_17" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.3389/fncom.2012.00062" title="Follow DOI:10.3389/fncom.2012.00062" target="_blank">doi:10.3389/fncom.2012.00062</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('17','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2011">2011</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Joachim Hass, Daniel Durstewitz </p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('55','tp_links')" style="cursor:pointer;">Models of dopaminergic modulation</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Scholarpedia, </span><span class="tp_pub_additional_volume">6 </span><span class="tp_pub_additional_number">(6), </span><span class="tp_pub_additional_year">2011</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_55" class="tp_show" onclick="teachpress_pub_showhide('55','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_55" class="tp_show" onclick="teachpress_pub_showhide('55','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_55" class="tp_show" onclick="teachpress_pub_showhide('55','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_55" style="display:none;"><div class="tp_bibtex_entry">@article{Hass2011,<br>
title = {Models of dopaminergic modulation},<br>
author = {Joachim Hass, Daniel Durstewitz},<br>
url = {http://www.scholarpedia.org/article/Models_of_dopaminergic_modulation},<br>
doi = {doi:10.4249/scholarpedia.4215},<br>
year  = {2011},<br>
date = {2011-08-01},<br>
journal = {Scholarpedia},<br>
volume = {6},<br>
number = {6},<br>
abstract = {In computational neuroscience, models of dopaminergic modulation address the physiological and computational functions of the neuromodulator dopamine (DA) by implementing it into models of biological neurons and networks.<br><br>
DA plays a highly important role in higher order motor control, goal-directed behavior, motivation, reinforcement learning, and a number of cognitive and executive functions such as working memory, planning, attention, behavioral and cognitive flexibility, inhibition of impulsive responses, and time perception (Schultz, 1998, Nieoullon, 2003, Goldman-Rakic, 2008, Dalley and Everitt, 2009). DA's fundamental part in learning, cognitive, and motor control is also reflected in the various serious nervous system diseases associated with impaired DA regulation, such as Parkinson’s disease, Schizophrenia, bipolar disorder, Huntington’s disease, attention-deficit hyperactivity disorder (ADHD), autism, restless legs syndrome (RLS), and addictions (Meyer-Lindenberg, 2010, Egan and Weinberger, 1997, Dalley and Everitt, 2009).<br><br>
From electrophysiological experiments, DA is known to affect a number of neuronal and synaptic properties in various target areas such as the striatum, the hippocampus, and motor and frontal cortical regions, via different types of receptors often combined within the D1- and D2-receptor class (D1R and D2R) (see Dopamine modulation). In single neurons, DA changes neuronal excitability and signal integration by virtue of its effects on a variety of voltage-dependent currents. DA also enhances or suppresses various synaptic currents such as AMPA-, GABA- and NMDA-type currents. With regards to both intrinsic and synaptic currents, the D1 and D2 receptor classes may function largely antagonistically (Trantham-Davidson et al. 2004, West and Grace 2002, Gulledge and Jaffe, 1998): D2 receptors decrease neuronal excitability with relatively short latency (in vitro), while there is a delayed and prolonged increase mediated by D1R. Similarly, D1R enhance NMDA- and GABA-type currents, while D2R decrease them. These antagonistic physiological effects may be rooted in the differential regulation of intracellular proteins like adenylyl cyclase, cAMP and DARPP-32 through D1R and D2R (Greengard, 2001).},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('55','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_55" style="display:none;"><div class="tp_abstract_entry">In computational neuroscience, models of dopaminergic modulation address the physiological and computational functions of the neuromodulator dopamine (DA) by implementing it into models of biological neurons and networks.<br><br>
DA plays a highly important role in higher order motor control, goal-directed behavior, motivation, reinforcement learning, and a number of cognitive and executive functions such as working memory, planning, attention, behavioral and cognitive flexibility, inhibition of impulsive responses, and time perception (Schultz, 1998, Nieoullon, 2003, Goldman-Rakic, 2008, Dalley and Everitt, 2009). DA's fundamental part in learning, cognitive, and motor control is also reflected in the various serious nervous system diseases associated with impaired DA regulation, such as Parkinson’s disease, Schizophrenia, bipolar disorder, Huntington’s disease, attention-deficit hyperactivity disorder (ADHD), autism, restless legs syndrome (RLS), and addictions (Meyer-Lindenberg, 2010, Egan and Weinberger, 1997, Dalley and Everitt, 2009).<br><br>
From electrophysiological experiments, DA is known to affect a number of neuronal and synaptic properties in various target areas such as the striatum, the hippocampus, and motor and frontal cortical regions, via different types of receptors often combined within the D1- and D2-receptor class (D1R and D2R) (see Dopamine modulation). In single neurons, DA changes neuronal excitability and signal integration by virtue of its effects on a variety of voltage-dependent currents. DA also enhances or suppresses various synaptic currents such as AMPA-, GABA- and NMDA-type currents. With regards to both intrinsic and synaptic currents, the D1 and D2 receptor classes may function largely antagonistically (Trantham-Davidson et al. 2004, West and Grace 2002, Gulledge and Jaffe, 1998): D2 receptors decrease neuronal excitability with relatively short latency (in vitro), while there is a delayed and prolonged increase mediated by D1R. Similarly, D1R enhance NMDA- and GABA-type currents, while D2R decrease them. These antagonistic physiological effects may be rooted in the differential regulation of intracellular proteins like adenylyl cyclase, cAMP and DARPP-32 through D1R and D2R (Greengard, 2001).</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('55','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_55" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://www.scholarpedia.org/article/Models_of_dopaminergic_modulation" title="http://www.scholarpedia.org/article/Models_of_dopaminergic_modulation" target="_blank">http://www.scholarpedia.org/article/Models_of_dopaminergic_modulation</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/doi:10.4249/scholarpedia.4215" title="Follow DOI:doi:10.4249/scholarpedia.4215" target="_blank">doi:doi:10.4249/scholarpedia.4215</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('55','tp_links')">Close</a></p></div></td></tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Balaguer-Ballester, Emili;  Lapish, Christopher C;  Seamans, Jeremy K;  Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('18','tp_links')" style="cursor:pointer;">Attracting dynamics of frontal cortex ensembles during memory-guided decision-making</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">PLoS Computational Biology, </span><span class="tp_pub_additional_volume">7 </span><span class="tp_pub_additional_number">(5), </span><span class="tp_pub_additional_year">2011</span>, <span class="tp_pub_additional_issn">ISSN: 1553734X</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_18" class="tp_show" onclick="teachpress_pub_showhide('18','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_18" class="tp_show" onclick="teachpress_pub_showhide('18','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_18" class="tp_show" onclick="teachpress_pub_showhide('18','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_18" style="display:none;"><div class="tp_bibtex_entry">@article{Balaguer-Ballester2011,<br>
title = {Attracting dynamics of frontal cortex ensembles during memory-guided decision-making},<br>
author = {Emili Balaguer-Ballester and Christopher C Lapish and Jeremy K Seamans and Daniel Durstewitz},<br>
doi = {10.1371/journal.pcbi.1002057},<br>
issn = {1553734X},<br>
year  = {2011},<br>
date = {2011-01-01},<br>
journal = {PLoS Computational Biology},<br>
volume = {7},<br>
number = {5},<br>
abstract = {A common theoretical view is that attractor-like properties of neuronal dynamics underlie cognitive processing. However, although often proposed theoretically, direct experimental support for the convergence of neural activity to stable population patterns as a signature of attracting states has been sparse so far, especially in higher cortical areas. Combining state space reconstruction theorems and statistical learning techniques, we were able to resolve details of anterior cingulate cortex (ACC) multiple single-unit activity (MSUA) ensemble dynamics during a higher cognitive task which were not accessible previously. The approach worked by constructing high-dimensional state spaces from delays of the original single-unit firing rate variables and the interactions among them, which were then statistically analyzed using kernel methods. We observed cognitive-epoch-specific neural ensemble states in ACC which were stable across many trials (in the sense of being predictive) and depended on behavioral performance. More interestingly, attracting properties of these cognitively defined ensemble states became apparent in high-dimensional expansions of the MSUA spaces due to a proper unfolding of the neural activity flow, with properties common across different animals. These results therefore suggest that ACC networks may process different subcomponents of higher cognitive tasks by transiting among different attracting states.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('18','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_18" style="display:none;"><div class="tp_abstract_entry">A common theoretical view is that attractor-like properties of neuronal dynamics underlie cognitive processing. However, although often proposed theoretically, direct experimental support for the convergence of neural activity to stable population patterns as a signature of attracting states has been sparse so far, especially in higher cortical areas. Combining state space reconstruction theorems and statistical learning techniques, we were able to resolve details of anterior cingulate cortex (ACC) multiple single-unit activity (MSUA) ensemble dynamics during a higher cognitive task which were not accessible previously. The approach worked by constructing high-dimensional state spaces from delays of the original single-unit firing rate variables and the interactions among them, which were then statistically analyzed using kernel methods. We observed cognitive-epoch-specific neural ensemble states in ACC which were stable across many trials (in the sense of being predictive) and depended on behavioral performance. More interestingly, attracting properties of these cognitively defined ensemble states became apparent in high-dimensional expansions of the MSUA spaces due to a proper unfolding of the neural activity flow, with properties common across different animals. These results therefore suggest that ACC networks may process different subcomponents of higher cognitive tasks by transiting among different attracting states.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('18','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_18" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1371/journal.pcbi.1002057" title="Follow DOI:10.1371/journal.pcbi.1002057" target="_blank">doi:10.1371/journal.pcbi.1002057</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('18','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2010">2010</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel;  Vittoz, Nicole M;  Floresco, Stan B;  Seamans, Jeremy K</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('24','tp_links')" style="cursor:pointer;">Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Neuron, </span><span class="tp_pub_additional_volume">66 </span><span class="tp_pub_additional_number">(3), </span><span class="tp_pub_additional_pages">pp. 438–448, </span><span class="tp_pub_additional_year">2010</span>, <span class="tp_pub_additional_issn">ISSN: 08966273</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_24" class="tp_show" onclick="teachpress_pub_showhide('24','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_24" class="tp_show" onclick="teachpress_pub_showhide('24','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_24" class="tp_show" onclick="teachpress_pub_showhide('24','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_24" style="display:none;"><div class="tp_bibtex_entry">@article{Durstewitz2010,<br>
title = {Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning},<br>
author = {Daniel Durstewitz and Nicole M Vittoz and Stan B Floresco and Jeremy K Seamans},<br>
url = {http://dx.doi.org/10.1016/j.neuron.2010.03.029},<br>
doi = {10.1016/j.neuron.2010.03.029},<br>
issn = {08966273},<br>
year  = {2010},<br>
date = {2010-01-01},<br>
journal = {Neuron},<br>
volume = {66},<br>
number = {3},<br>
pages = {438--448},<br>
publisher = {Elsevier Ltd},<br>
abstract = {One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight. ?? 2010 Elsevier Inc.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('24','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_24" style="display:none;"><div class="tp_abstract_entry">One of the most intriguing aspects of adaptive behavior involves the inference of regularities and rules in ever-changing environments. Rules are often deduced through evidence-based learning which relies on the prefrontal cortex (PFC). This is a highly dynamic process, evolving trial by trial and therefore may not be adequately captured by averaging single-unit responses over numerous repetitions. Here, we employed advanced statistical techniques to visualize the trajectories of ensembles of simultaneously recorded medial PFC neurons on a trial-by-trial basis as rats deduced a novel rule in a set-shifting task. Neural populations formed clearly distinct and lasting representations of familiar and novel rules by entering unique network states. During rule acquisition, the recorded ensembles often exhibited abrupt transitions, rather than evolving continuously, in tight temporal relation to behavioral performance shifts. These results support the idea that rule learning is an evidence-based decision process, perhaps accompanied by moments of sudden insight. ?? 2010 Elsevier Inc.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('24','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_24" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="http://dx.doi.org/10.1016/j.neuron.2010.03.029" title="http://dx.doi.org/10.1016/j.neuron.2010.03.029" target="_blank">http://dx.doi.org/10.1016/j.neuron.2010.03.029</a></li><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1016/j.neuron.2010.03.029" title="Follow DOI:10.1016/j.neuron.2010.03.029" target="_blank">doi:10.1016/j.neuron.2010.03.029</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('24','tp_links')">Close</a></p></div></td></tr><tr><td>
                        <h3 class="tp_h3" id="tp_h3_2009">2009</h3>
                    </td>
                </tr><tr class="tp_publication"><td class="tp_pub_info"><p class="tp_pub_author"> Durstewitz, Daniel</p><p class="tp_pub_title"><a class="tp_title_link" onclick="teachpress_pub_showhide('22','tp_links')" style="cursor:pointer;">Implications of synaptic biophysics for recurrent network dynamics and active memory</a> <span class="tp_pub_type article">Journal Article</span> </p><p class="tp_pub_additional"><span class="tp_pub_additional_journal">Neural Networks, </span><span class="tp_pub_additional_volume">22 </span><span class="tp_pub_additional_number">(8), </span><span class="tp_pub_additional_pages">pp. 1189–1200, </span><span class="tp_pub_additional_year">2009</span>, <span class="tp_pub_additional_issn">ISSN: 08936080</span>.</p><p class="tp_pub_tags"><span class="tp_abstract_link"><a id="tp_abstract_sh_22" class="tp_show" onclick="teachpress_pub_showhide('22','tp_abstract')" title="Show abstract" style="cursor:pointer;">Abstract</a></span> | <span class="tp_resource_link"><a id="tp_links_sh_22" class="tp_show" onclick="teachpress_pub_showhide('22','tp_links')" title="Show links and resources" style="cursor:pointer;">Links</a></span> | <span class="tp_bibtex_link"><a id="tp_bibtex_sh_22" class="tp_show" onclick="teachpress_pub_showhide('22','tp_bibtex')" title="Show BibTeX entry" style="cursor:pointer;">BibTeX</a></span></p><div class="tp_bibtex" id="tp_bibtex_22" style="display:none;"><div class="tp_bibtex_entry">@article{Durstewitz2009,<br>
title = {Implications of synaptic biophysics for recurrent network dynamics and active memory},<br>
author = {Daniel Durstewitz},<br>
doi = {10.1016/j.neunet.2009.07.016},<br>
issn = {08936080},<br>
year  = {2009},<br>
date = {2009-10-01},<br>
journal = {Neural Networks},<br>
volume = {22},<br>
number = {8},<br>
pages = {1189--1200},<br>
abstract = {In cortical networks, synaptic excitation is mediated by AMPA- and NMDA-type receptors. NMDA differ from AMPA synaptic potentials with regard to peak current, time course, and a strong voltage-dependent nonlinearity. Here we illustrate based on empirical and computational findings that these specific biophysical properties may have profound implications for the dynamics of cortical networks, and via dynamics on cognitive functions like active memory. The discussion will be led along a minimal set of neural equations introduced to capture the essential dynamics of the various phenomena described. NMDA currents could establish cortical bistability and may provide the relatively constant synaptic drive needed to robustly maintain enhanced levels of activity during working memory epochs, freeing fast AMPA currents for other computational purposes. Perhaps more importantly, variations in NMDA synaptic input-due to their biophysical particularities-control the dynamical regime within which single neurons and networks reside. By provoking bursting, chaotic irregularity, and coherent oscillations their major effect may be on the temporal pattern of spiking activity, rather than on average firing rate. During active memory, neurons may thus be pushed into a spiking regime that harbors complex temporal structure, potentially optimal for the encoding and processing of temporal sequence information. These observations provide a qualitatively different view on the role of synaptic excitation in neocortical dynamics than entailed by many more abstract models. In this sense, this article is a plead for taking the specific biophysics of real neurons and synapses seriously when trying to account for the neurobiology of cognition. textcopyright 2009 Elsevier Ltd. All rights reserved.},<br>
keywords = {},<br>
pubstate = {published},<br>
tppubtype = {article}<br>
}<br></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('22','tp_bibtex')">Close</a></p></div><div class="tp_abstract" id="tp_abstract_22" style="display:none;"><div class="tp_abstract_entry">In cortical networks, synaptic excitation is mediated by AMPA- and NMDA-type receptors. NMDA differ from AMPA synaptic potentials with regard to peak current, time course, and a strong voltage-dependent nonlinearity. Here we illustrate based on empirical and computational findings that these specific biophysical properties may have profound implications for the dynamics of cortical networks, and via dynamics on cognitive functions like active memory. The discussion will be led along a minimal set of neural equations introduced to capture the essential dynamics of the various phenomena described. NMDA currents could establish cortical bistability and may provide the relatively constant synaptic drive needed to robustly maintain enhanced levels of activity during working memory epochs, freeing fast AMPA currents for other computational purposes. Perhaps more importantly, variations in NMDA synaptic input-due to their biophysical particularities-control the dynamical regime within which single neurons and networks reside. By provoking bursting, chaotic irregularity, and coherent oscillations their major effect may be on the temporal pattern of spiking activity, rather than on average firing rate. During active memory, neurons may thus be pushed into a spiking regime that harbors complex temporal structure, potentially optimal for the encoding and processing of temporal sequence information. These observations provide a qualitatively different view on the role of synaptic excitation in neocortical dynamics than entailed by many more abstract models. In this sense, this article is a plead for taking the specific biophysics of real neurons and synapses seriously when trying to account for the neurobiology of cognition. textcopyright 2009 Elsevier Ltd. All rights reserved.</div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('22','tp_abstract')">Close</a></p></div><div class="tp_links" id="tp_links_22" style="display:none;"><div class="tp_links_entry"><ul class="tp_pub_list"><li><a class="tp_pub_list" style="background-image:url(http://OFFLINEZIP.wpsho/wp-content/plugins/teachpress/images/mimetypes/xtext-html.png.pagespeed.ic.fiNbvcHt-l.png)" href="https://dx.doi.org/10.1016/j.neunet.2009.07.016" title="Follow DOI:10.1016/j.neunet.2009.07.016" target="_blank">doi:10.1016/j.neunet.2009.07.016</a></li></ul></div><p class="tp_close_menu"><a class="tp_close" onclick="teachpress_pub_showhide('22','tp_links')">Close</a></p></div></td></tr></table><div class="tablenav"><div class="tablenav-pages"><span class="displaying-num">69 entries</span> <a class="first-page disabled">«</a> <a class="prev-page disabled">‹</a>  1 of 2 <a href="../publications/index.html" title="next page" class="page-numbers">›</a> <a href="../publications/index.html" title="last page" class="page-numbers">»</a> </div></div>
	</div>
</article></main></div>
</div>


		</div>

		<footer id="colophon" class="site-footer" role="contentinfo"><div class="wrap">
				
<div class="site-info">
		<a href="https://wordpress.org/" class="imprint">
		Proudly powered by WordPress	</a>
</div>
			</div>
		</footer></div>
</div>
<style id="tp_template_2016-css" media="all">td.tp_pub_info{border-bottom:1px solid silver;vertical-align:top;padding:8px}.tp_pub_author,#content p.tp_pub_author{font-size:small;margin-bottom:1px;margin-top:1px}.tp_pub_title,#content p.tp_pub_title{font-size:small;font-weight:bold;margin-top:1px;margin-bottom:1px}.tp_pub_additional,#content p.tp_pub_additional{font-size:small;margin-top:1px;margin-bottom:1px}.tp_pub_tags,#content p.tp_pub_tags{font-size:small;margin-top:1px;margin-bottom:1px;color:#aaa}.tp_pub_tags a{color:#aaa;text-decoration:underline;box-shadow:none}.tp_pub_tags a:hover{color:#aaa;text-decoration:none}.tp_pub_type{background-color:#008bd2;color:#fff;display:inline-block;padding:3px 4px;margin-left:5px;font-size:10px;font-weight:bold;line-height:1;border-radius:2px;box-shadow:inset 0 -1px 0 rgba(0,0,0,.12)}.tp_pub_label_status{background-color:#ffa500;color:#fff;display:inline-block;padding:3px 4px;margin-left:5px;font-size:10px;font-weight:bold;line-height:1;border-radius:2px;box-shadow:inset 0 -1px 0 rgba(0,0,0,.12)}</style><script type="text/javascript" src="../wp-includes/js/underscore.min.js" id="underscore-js"></script><script type="text/javascript" src="../wp-includes/js/backbone.min.js,qver=1.4.0.pagespeed.jm.3v66iHt-4Y.js" id="backbone-js"></script><script type="text/javascript" id="wp-api-request-js-extra">//<![CDATA[
var wpApiSettings={"root":"http:\/\/OFFLINEZIP.wpshowp-json\/","nonce":"2616c88d1a","versionString":"wp\/v2\/"};
//]]></script><script src="../wp-includes/js/api-request.min.js,qver==5.5.5+wp-api.min.js,qver==5.5.5.pagespeed.jc.oRuioP8Frj.js"></script><script>eval(mod_pagespeed_Ob9i$xFH5v);</script><script>eval(mod_pagespeed_WoONBsTzAN);</script><script type="text/javascript" id="twentyseventeen-skip-link-focus-fix-js-extra">//<![CDATA[
var twentyseventeenScreenReaderText={"quote":"<svg class=\"icon icon-quote-right\" aria-hidden=\"true\" role=\"img\"> <use href=\"#icon-quote-right\" xlink:href=\"#icon-quote-right\"><\/use> <\/svg>","expand":"Expand child menu","collapse":"Collapse child menu","icon":"<svg class=\"icon icon-angle-down\" aria-hidden=\"true\" role=\"img\"> <use href=\"#icon-angle-down\" xlink:href=\"#icon-angle-down\"><\/use> <span class=\"svg-fallback icon-angle-down\"><\/span><\/svg>"};
//]]></script><script src="../wp-content/themes/twentyseventeen/assets/js/skip-link-focus-fix.js,qver==1.0+navigation.js,qver==1.0+global.js,qver==1.0+jquery.scrollTo.js,qver==2.1.2.pagespeed.jc.N8UcrPnzX2.js"></script><script>eval(mod_pagespeed_ERKm2E4T_i);</script><script>eval(mod_pagespeed_WnmX$Eia5g);</script><script>eval(mod_pagespeed_OczzLSUZbI);</script><script>eval(mod_pagespeed_9YE48b0kQs);</script><svg style="position: absolute; width: 0; height: 0; overflow: hidden;" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><symbol id="icon-behance" viewbox="0 0 37 32"><path class="path1" d="M33 6.054h-9.125v2.214h9.125v-2.214zM28.5 13.661q-1.607 0-2.607 0.938t-1.107 2.545h7.286q-0.321-3.482-3.571-3.482zM28.786 24.107q1.125 0 2.179-0.571t1.357-1.554h3.946q-1.786 5.482-7.625 5.482-3.821 0-6.080-2.357t-2.259-6.196q0-3.714 2.33-6.17t6.009-2.455q2.464 0 4.295 1.214t2.732 3.196 0.902 4.429q0 0.304-0.036 0.839h-11.75q0 1.982 1.027 3.063t2.973 1.080zM4.946 23.214h5.286q3.661 0 3.661-2.982 0-3.214-3.554-3.214h-5.393v6.196zM4.946 13.625h5.018q1.393 0 2.205-0.652t0.813-2.027q0-2.571-3.393-2.571h-4.643v5.25zM0 4.536h10.607q1.554 0 2.768 0.25t2.259 0.848 1.607 1.723 0.563 2.75q0 3.232-3.071 4.696 2.036 0.571 3.071 2.054t1.036 3.643q0 1.339-0.438 2.438t-1.179 1.848-1.759 1.268-2.161 0.75-2.393 0.232h-10.911v-22.5z"></path></symbol><symbol id="icon-deviantart" viewbox="0 0 18 32"><path class="path1" d="M18.286 5.411l-5.411 10.393 0.429 0.554h4.982v7.411h-9.054l-0.786 0.536-2.536 4.875-0.536 0.536h-5.375v-5.411l5.411-10.411-0.429-0.536h-4.982v-7.411h9.054l0.786-0.536 2.536-4.875 0.536-0.536h5.375v5.411z"></path></symbol><symbol id="icon-medium" viewbox="0 0 32 32"><path class="path1" d="M10.661 7.518v20.946q0 0.446-0.223 0.759t-0.652 0.313q-0.304 0-0.589-0.143l-8.304-4.161q-0.375-0.179-0.634-0.598t-0.259-0.83v-20.357q0-0.357 0.179-0.607t0.518-0.25q0.25 0 0.786 0.268l9.125 4.571q0.054 0.054 0.054 0.089zM11.804 9.321l9.536 15.464-9.536-4.75v-10.714zM32 9.643v18.821q0 0.446-0.25 0.723t-0.679 0.277-0.839-0.232l-7.875-3.929zM31.946 7.5q0 0.054-4.58 7.491t-5.366 8.705l-6.964-11.321 5.786-9.411q0.304-0.5 0.929-0.5 0.25 0 0.464 0.107l9.661 4.821q0.071 0.036 0.071 0.107z"></path></symbol><symbol id="icon-slideshare" viewbox="0 0 32 32"><path class="path1" d="M15.589 13.214q0 1.482-1.134 2.545t-2.723 1.063-2.723-1.063-1.134-2.545q0-1.5 1.134-2.554t2.723-1.054 2.723 1.054 1.134 2.554zM24.554 13.214q0 1.482-1.125 2.545t-2.732 1.063q-1.589 0-2.723-1.063t-1.134-2.545q0-1.5 1.134-2.554t2.723-1.054q1.607 0 2.732 1.054t1.125 2.554zM28.571 16.429v-11.911q0-1.554-0.571-2.205t-1.982-0.652h-19.857q-1.482 0-2.009 0.607t-0.527 2.25v12.018q0.768 0.411 1.58 0.714t1.446 0.5 1.446 0.33 1.268 0.196 1.25 0.071 1.045 0.009 1.009-0.036 0.795-0.036q1.214-0.018 1.696 0.482 0.107 0.107 0.179 0.161 0.464 0.446 1.089 0.911 0.125-1.625 2.107-1.554 0.089 0 0.652 0.027t0.768 0.036 0.813 0.018 0.946-0.018 0.973-0.080 1.089-0.152 1.107-0.241 1.196-0.348 1.205-0.482 1.286-0.616zM31.482 16.339q-2.161 2.661-6.643 4.5 1.5 5.089-0.411 8.304-1.179 2.018-3.268 2.643-1.857 0.571-3.25-0.268-1.536-0.911-1.464-2.929l-0.018-5.821v-0.018q-0.143-0.036-0.438-0.107t-0.42-0.089l-0.018 6.036q0.071 2.036-1.482 2.929-1.411 0.839-3.268 0.268-2.089-0.643-3.25-2.679-1.875-3.214-0.393-8.268-4.482-1.839-6.643-4.5-0.446-0.661-0.071-1.125t1.071 0.018q0.054 0.036 0.196 0.125t0.196 0.143v-12.393q0-1.286 0.839-2.196t2.036-0.911h22.446q1.196 0 2.036 0.911t0.839 2.196v12.393l0.375-0.268q0.696-0.482 1.071-0.018t-0.071 1.125z"></path></symbol><symbol id="icon-snapchat-ghost" viewbox="0 0 30 32"><path class="path1" d="M15.143 2.286q2.393-0.018 4.295 1.223t2.92 3.438q0.482 1.036 0.482 3.196 0 0.839-0.161 3.411 0.25 0.125 0.5 0.125 0.321 0 0.911-0.241t0.911-0.241q0.518 0 1 0.321t0.482 0.821q0 0.571-0.563 0.964t-1.232 0.563-1.232 0.518-0.563 0.848q0 0.268 0.214 0.768 0.661 1.464 1.83 2.679t2.58 1.804q0.5 0.214 1.429 0.411 0.5 0.107 0.5 0.625 0 1.25-3.911 1.839-0.125 0.196-0.196 0.696t-0.25 0.83-0.589 0.33q-0.357 0-1.107-0.116t-1.143-0.116q-0.661 0-1.107 0.089-0.571 0.089-1.125 0.402t-1.036 0.679-1.036 0.723-1.357 0.598-1.768 0.241q-0.929 0-1.723-0.241t-1.339-0.598-1.027-0.723-1.036-0.679-1.107-0.402q-0.464-0.089-1.125-0.089-0.429 0-1.17 0.134t-1.045 0.134q-0.446 0-0.625-0.33t-0.25-0.848-0.196-0.714q-3.911-0.589-3.911-1.839 0-0.518 0.5-0.625 0.929-0.196 1.429-0.411 1.393-0.571 2.58-1.804t1.83-2.679q0.214-0.5 0.214-0.768 0-0.5-0.563-0.848t-1.241-0.527-1.241-0.563-0.563-0.938q0-0.482 0.464-0.813t0.982-0.33q0.268 0 0.857 0.232t0.946 0.232q0.321 0 0.571-0.125-0.161-2.536-0.161-3.393 0-2.179 0.482-3.214 1.143-2.446 3.071-3.536t4.714-1.125z"></path></symbol><symbol id="icon-yelp" viewbox="0 0 27 32"><path class="path1" d="M13.804 23.554v2.268q-0.018 5.214-0.107 5.446-0.214 0.571-0.911 0.714-0.964 0.161-3.241-0.679t-2.902-1.589q-0.232-0.268-0.304-0.643-0.018-0.214 0.071-0.464 0.071-0.179 0.607-0.839t3.232-3.857q0.018 0 1.071-1.25 0.268-0.339 0.705-0.438t0.884 0.063q0.429 0.179 0.67 0.518t0.223 0.75zM11.143 19.071q-0.054 0.982-0.929 1.25l-2.143 0.696q-4.911 1.571-5.214 1.571-0.625-0.036-0.964-0.643-0.214-0.446-0.304-1.339-0.143-1.357 0.018-2.973t0.536-2.223 1-0.571q0.232 0 3.607 1.375 1.25 0.518 2.054 0.839l1.5 0.607q0.411 0.161 0.634 0.545t0.205 0.866zM25.893 24.375q-0.125 0.964-1.634 2.875t-2.42 2.268q-0.661 0.25-1.125-0.125-0.25-0.179-3.286-5.125l-0.839-1.375q-0.25-0.375-0.205-0.821t0.348-0.821q0.625-0.768 1.482-0.464 0.018 0.018 2.125 0.714 3.625 1.179 4.321 1.42t0.839 0.366q0.5 0.393 0.393 1.089zM13.893 13.089q0.089 1.821-0.964 2.179-1.036 0.304-2.036-1.268l-6.75-10.679q-0.143-0.625 0.339-1.107 0.732-0.768 3.705-1.598t4.009-0.563q0.714 0.179 0.875 0.804 0.054 0.321 0.393 5.455t0.429 6.777zM25.714 15.018q0.054 0.696-0.464 1.054-0.268 0.179-5.875 1.536-1.196 0.268-1.625 0.411l0.018-0.036q-0.411 0.107-0.821-0.071t-0.661-0.571q-0.536-0.839 0-1.554 0.018-0.018 1.339-1.821 2.232-3.054 2.679-3.643t0.607-0.696q0.5-0.339 1.161-0.036 0.857 0.411 2.196 2.384t1.446 2.991v0.054z"></path></symbol><symbol id="icon-vine" viewbox="0 0 27 32"><path class="path1" d="M26.732 14.768v3.536q-1.804 0.411-3.536 0.411-1.161 2.429-2.955 4.839t-3.241 3.848-2.286 1.902q-1.429 0.804-2.893-0.054-0.5-0.304-1.080-0.777t-1.518-1.491-1.83-2.295-1.92-3.286-1.884-4.357-1.634-5.616-1.259-6.964h5.054q0.464 3.893 1.25 7.116t1.866 5.661 2.17 4.205 2.5 3.482q3.018-3.018 5.125-7.25-2.536-1.286-3.982-3.929t-1.446-5.946q0-3.429 1.857-5.616t5.071-2.188q3.179 0 4.875 1.884t1.696 5.313q0 2.839-1.036 5.107-0.125 0.018-0.348 0.054t-0.821 0.036-1.125-0.107-1.107-0.455-0.902-0.92q0.554-1.839 0.554-3.286 0-1.554-0.518-2.357t-1.411-0.804q-0.946 0-1.518 0.884t-0.571 2.509q0 3.321 1.875 5.241t4.768 1.92q1.107 0 2.161-0.25z"></path></symbol><symbol id="icon-vk" viewbox="0 0 35 32"><path class="path1" d="M34.232 9.286q0.411 1.143-2.679 5.25-0.429 0.571-1.161 1.518-1.393 1.786-1.607 2.339-0.304 0.732 0.25 1.446 0.304 0.375 1.446 1.464h0.018l0.071 0.071q2.518 2.339 3.411 3.946 0.054 0.089 0.116 0.223t0.125 0.473-0.009 0.607-0.446 0.491-1.054 0.223l-4.571 0.071q-0.429 0.089-1-0.089t-0.929-0.393l-0.357-0.214q-0.536-0.375-1.25-1.143t-1.223-1.384-1.089-1.036-1.009-0.277q-0.054 0.018-0.143 0.063t-0.304 0.259-0.384 0.527-0.304 0.929-0.116 1.384q0 0.268-0.063 0.491t-0.134 0.33l-0.071 0.089q-0.321 0.339-0.946 0.393h-2.054q-1.268 0.071-2.607-0.295t-2.348-0.946-1.839-1.179-1.259-1.027l-0.446-0.429q-0.179-0.179-0.491-0.536t-1.277-1.625-1.893-2.696-2.188-3.768-2.33-4.857q-0.107-0.286-0.107-0.482t0.054-0.286l0.071-0.107q0.268-0.339 1.018-0.339l4.893-0.036q0.214 0.036 0.411 0.116t0.286 0.152l0.089 0.054q0.286 0.196 0.429 0.571 0.357 0.893 0.821 1.848t0.732 1.455l0.286 0.518q0.518 1.071 1 1.857t0.866 1.223 0.741 0.688 0.607 0.25 0.482-0.089q0.036-0.018 0.089-0.089t0.214-0.393 0.241-0.839 0.17-1.446 0-2.232q-0.036-0.714-0.161-1.304t-0.25-0.821l-0.107-0.214q-0.446-0.607-1.518-0.768-0.232-0.036 0.089-0.429 0.304-0.339 0.679-0.536 0.946-0.464 4.268-0.429 1.464 0.018 2.411 0.232 0.357 0.089 0.598 0.241t0.366 0.429 0.188 0.571 0.063 0.813-0.018 0.982-0.045 1.259-0.027 1.473q0 0.196-0.018 0.75t-0.009 0.857 0.063 0.723 0.205 0.696 0.402 0.438q0.143 0.036 0.304 0.071t0.464-0.196 0.679-0.616 0.929-1.196 1.214-1.92q1.071-1.857 1.911-4.018 0.071-0.179 0.179-0.313t0.196-0.188l0.071-0.054 0.089-0.045t0.232-0.054 0.357-0.009l5.143-0.036q0.696-0.089 1.143 0.045t0.554 0.295z"></path></symbol><symbol id="icon-search" viewbox="0 0 30 32"><path class="path1" d="M20.571 14.857q0-3.304-2.348-5.652t-5.652-2.348-5.652 2.348-2.348 5.652 2.348 5.652 5.652 2.348 5.652-2.348 2.348-5.652zM29.714 29.714q0 0.929-0.679 1.607t-1.607 0.679q-0.964 0-1.607-0.679l-6.125-6.107q-3.196 2.214-7.125 2.214-2.554 0-4.884-0.991t-4.018-2.679-2.679-4.018-0.991-4.884 0.991-4.884 2.679-4.018 4.018-2.679 4.884-0.991 4.884 0.991 4.018 2.679 2.679 4.018 0.991 4.884q0 3.929-2.214 7.125l6.125 6.125q0.661 0.661 0.661 1.607z"></path></symbol><symbol id="icon-envelope-o" viewbox="0 0 32 32"><path class="path1" d="M29.714 26.857v-13.714q-0.571 0.643-1.232 1.179-4.786 3.679-7.607 6.036-0.911 0.768-1.482 1.196t-1.545 0.866-1.83 0.438h-0.036q-0.857 0-1.83-0.438t-1.545-0.866-1.482-1.196q-2.821-2.357-7.607-6.036-0.661-0.536-1.232-1.179v13.714q0 0.232 0.17 0.402t0.402 0.17h26.286q0.232 0 0.402-0.17t0.17-0.402zM29.714 8.089v-0.438t-0.009-0.232-0.054-0.223-0.098-0.161-0.161-0.134-0.25-0.045h-26.286q-0.232 0-0.402 0.17t-0.17 0.402q0 3 2.625 5.071 3.446 2.714 7.161 5.661 0.107 0.089 0.625 0.527t0.821 0.67 0.795 0.563 0.902 0.491 0.768 0.161h0.036q0.357 0 0.768-0.161t0.902-0.491 0.795-0.563 0.821-0.67 0.625-0.527q3.714-2.946 7.161-5.661 0.964-0.768 1.795-2.063t0.83-2.348zM32 7.429v19.429q0 1.179-0.839 2.018t-2.018 0.839h-26.286q-1.179 0-2.018-0.839t-0.839-2.018v-19.429q0-1.179 0.839-2.018t2.018-0.839h26.286q1.179 0 2.018 0.839t0.839 2.018z"></path></symbol><symbol id="icon-close" viewbox="0 0 25 32"><path class="path1" d="M23.179 23.607q0 0.714-0.5 1.214l-2.429 2.429q-0.5 0.5-1.214 0.5t-1.214-0.5l-5.25-5.25-5.25 5.25q-0.5 0.5-1.214 0.5t-1.214-0.5l-2.429-2.429q-0.5-0.5-0.5-1.214t0.5-1.214l5.25-5.25-5.25-5.25q-0.5-0.5-0.5-1.214t0.5-1.214l2.429-2.429q0.5-0.5 1.214-0.5t1.214 0.5l5.25 5.25 5.25-5.25q0.5-0.5 1.214-0.5t1.214 0.5l2.429 2.429q0.5 0.5 0.5 1.214t-0.5 1.214l-5.25 5.25 5.25 5.25q0.5 0.5 0.5 1.214z"></path></symbol><symbol id="icon-angle-down" viewbox="0 0 21 32"><path class="path1" d="M19.196 13.143q0 0.232-0.179 0.411l-8.321 8.321q-0.179 0.179-0.411 0.179t-0.411-0.179l-8.321-8.321q-0.179-0.179-0.179-0.411t0.179-0.411l0.893-0.893q0.179-0.179 0.411-0.179t0.411 0.179l7.018 7.018 7.018-7.018q0.179-0.179 0.411-0.179t0.411 0.179l0.893 0.893q0.179 0.179 0.179 0.411z"></path></symbol><symbol id="icon-folder-open" viewbox="0 0 34 32"><path class="path1" d="M33.554 17q0 0.554-0.554 1.179l-6 7.071q-0.768 0.911-2.152 1.545t-2.563 0.634h-19.429q-0.607 0-1.080-0.232t-0.473-0.768q0-0.554 0.554-1.179l6-7.071q0.768-0.911 2.152-1.545t2.563-0.634h19.429q0.607 0 1.080 0.232t0.473 0.768zM27.429 10.857v2.857h-14.857q-1.679 0-3.518 0.848t-2.929 2.134l-6.107 7.179q0-0.071-0.009-0.223t-0.009-0.223v-17.143q0-1.643 1.179-2.821t2.821-1.179h5.714q1.643 0 2.821 1.179t1.179 2.821v0.571h9.714q1.643 0 2.821 1.179t1.179 2.821z"></path></symbol><symbol id="icon-twitter" viewbox="0 0 30 32"><path class="path1" d="M28.929 7.286q-1.196 1.75-2.893 2.982 0.018 0.25 0.018 0.75 0 2.321-0.679 4.634t-2.063 4.437-3.295 3.759-4.607 2.607-5.768 0.973q-4.839 0-8.857-2.589 0.625 0.071 1.393 0.071 4.018 0 7.161-2.464-1.875-0.036-3.357-1.152t-2.036-2.848q0.589 0.089 1.089 0.089 0.768 0 1.518-0.196-2-0.411-3.313-1.991t-1.313-3.67v-0.071q1.214 0.679 2.607 0.732-1.179-0.786-1.875-2.054t-0.696-2.75q0-1.571 0.786-2.911 2.161 2.661 5.259 4.259t6.634 1.777q-0.143-0.679-0.143-1.321 0-2.393 1.688-4.080t4.080-1.688q2.5 0 4.214 1.821 1.946-0.375 3.661-1.393-0.661 2.054-2.536 3.179 1.661-0.179 3.321-0.893z"></path></symbol><symbol id="icon-facebook" viewbox="0 0 19 32"><path class="path1" d="M17.125 0.214v4.714h-2.804q-1.536 0-2.071 0.643t-0.536 1.929v3.375h5.232l-0.696 5.286h-4.536v13.554h-5.464v-13.554h-4.554v-5.286h4.554v-3.893q0-3.321 1.857-5.152t4.946-1.83q2.625 0 4.071 0.214z"></path></symbol><symbol id="icon-github" viewbox="0 0 27 32"><path class="path1" d="M13.714 2.286q3.732 0 6.884 1.839t4.991 4.991 1.839 6.884q0 4.482-2.616 8.063t-6.759 4.955q-0.482 0.089-0.714-0.125t-0.232-0.536q0-0.054 0.009-1.366t0.009-2.402q0-1.732-0.929-2.536 1.018-0.107 1.83-0.321t1.679-0.696 1.446-1.188 0.946-1.875 0.366-2.688q0-2.125-1.411-3.679 0.661-1.625-0.143-3.643-0.5-0.161-1.446 0.196t-1.643 0.786l-0.679 0.429q-1.661-0.464-3.429-0.464t-3.429 0.464q-0.286-0.196-0.759-0.482t-1.491-0.688-1.518-0.241q-0.804 2.018-0.143 3.643-1.411 1.554-1.411 3.679 0 1.518 0.366 2.679t0.938 1.875 1.438 1.196 1.679 0.696 1.83 0.321q-0.696 0.643-0.875 1.839-0.375 0.179-0.804 0.268t-1.018 0.089-1.17-0.384-0.991-1.116q-0.339-0.571-0.866-0.929t-0.884-0.429l-0.357-0.054q-0.375 0-0.518 0.080t-0.089 0.205 0.161 0.25 0.232 0.214l0.125 0.089q0.393 0.179 0.777 0.679t0.563 0.911l0.179 0.411q0.232 0.679 0.786 1.098t1.196 0.536 1.241 0.125 0.991-0.063l0.411-0.071q0 0.679 0.009 1.58t0.009 0.973q0 0.321-0.232 0.536t-0.714 0.125q-4.143-1.375-6.759-4.955t-2.616-8.063q0-3.732 1.839-6.884t4.991-4.991 6.884-1.839zM5.196 21.982q0.054-0.125-0.125-0.214-0.179-0.054-0.232 0.036-0.054 0.125 0.125 0.214 0.161 0.107 0.232-0.036zM5.75 22.589q0.125-0.089-0.036-0.286-0.179-0.161-0.286-0.054-0.125 0.089 0.036 0.286 0.179 0.179 0.286 0.054zM6.286 23.393q0.161-0.125 0-0.339-0.143-0.232-0.304-0.107-0.161 0.089 0 0.321t0.304 0.125zM7.036 24.143q0.143-0.143-0.071-0.339-0.214-0.214-0.357-0.054-0.161 0.143 0.071 0.339 0.214 0.214 0.357 0.054zM8.054 24.589q0.054-0.196-0.232-0.286-0.268-0.071-0.339 0.125t0.232 0.268q0.268 0.107 0.339-0.107zM9.179 24.679q0-0.232-0.304-0.196-0.286 0-0.286 0.196 0 0.232 0.304 0.196 0.286 0 0.286-0.196zM10.214 24.5q-0.036-0.196-0.321-0.161-0.286 0.054-0.25 0.268t0.321 0.143 0.25-0.25z"></path></symbol><symbol id="icon-bars" viewbox="0 0 27 32"><path class="path1" d="M27.429 24v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804zM27.429 14.857v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804zM27.429 5.714v2.286q0 0.464-0.339 0.804t-0.804 0.339h-25.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h25.143q0.464 0 0.804 0.339t0.339 0.804z"></path></symbol><symbol id="icon-google-plus" viewbox="0 0 41 32"><path class="path1" d="M25.661 16.304q0 3.714-1.554 6.616t-4.429 4.536-6.589 1.634q-2.661 0-5.089-1.036t-4.179-2.786-2.786-4.179-1.036-5.089 1.036-5.089 2.786-4.179 4.179-2.786 5.089-1.036q5.107 0 8.768 3.429l-3.554 3.411q-2.089-2.018-5.214-2.018-2.196 0-4.063 1.107t-2.955 3.009-1.089 4.152 1.089 4.152 2.955 3.009 4.063 1.107q1.482 0 2.723-0.411t2.045-1.027 1.402-1.402 0.875-1.482 0.384-1.321h-7.429v-4.5h12.357q0.214 1.125 0.214 2.179zM41.143 14.125v3.75h-3.732v3.732h-3.75v-3.732h-3.732v-3.75h3.732v-3.732h3.75v3.732h3.732z"></path></symbol><symbol id="icon-linkedin" viewbox="0 0 27 32"><path class="path1" d="M6.232 11.161v17.696h-5.893v-17.696h5.893zM6.607 5.696q0.018 1.304-0.902 2.179t-2.42 0.875h-0.036q-1.464 0-2.357-0.875t-0.893-2.179q0-1.321 0.92-2.188t2.402-0.866 2.375 0.866 0.911 2.188zM27.429 18.714v10.143h-5.875v-9.464q0-1.875-0.723-2.938t-2.259-1.063q-1.125 0-1.884 0.616t-1.134 1.527q-0.196 0.536-0.196 1.446v9.875h-5.875q0.036-7.125 0.036-11.554t-0.018-5.286l-0.018-0.857h5.875v2.571h-0.036q0.357-0.571 0.732-1t1.009-0.929 1.554-0.777 2.045-0.277q3.054 0 4.911 2.027t1.857 5.938z"></path></symbol><symbol id="icon-quote-right" viewbox="0 0 30 32"><path class="path1" d="M13.714 5.714v12.571q0 1.857-0.723 3.545t-1.955 2.92-2.92 1.955-3.545 0.723h-1.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h1.143q1.893 0 3.232-1.339t1.339-3.232v-0.571q0-0.714-0.5-1.214t-1.214-0.5h-4q-1.429 0-2.429-1t-1-2.429v-6.857q0-1.429 1-2.429t2.429-1h6.857q1.429 0 2.429 1t1 2.429zM29.714 5.714v12.571q0 1.857-0.723 3.545t-1.955 2.92-2.92 1.955-3.545 0.723h-1.143q-0.464 0-0.804-0.339t-0.339-0.804v-2.286q0-0.464 0.339-0.804t0.804-0.339h1.143q1.893 0 3.232-1.339t1.339-3.232v-0.571q0-0.714-0.5-1.214t-1.214-0.5h-4q-1.429 0-2.429-1t-1-2.429v-6.857q0-1.429 1-2.429t2.429-1h6.857q1.429 0 2.429 1t1 2.429z"></path></symbol><symbol id="icon-mail-reply" viewbox="0 0 32 32"><path class="path1" d="M32 20q0 2.964-2.268 8.054-0.054 0.125-0.188 0.429t-0.241 0.536-0.232 0.393q-0.214 0.304-0.5 0.304-0.268 0-0.42-0.179t-0.152-0.446q0-0.161 0.045-0.473t0.045-0.42q0.089-1.214 0.089-2.196 0-1.804-0.313-3.232t-0.866-2.473-1.429-1.804-1.884-1.241-2.375-0.759-2.75-0.384-3.134-0.107h-4v4.571q0 0.464-0.339 0.804t-0.804 0.339-0.804-0.339l-9.143-9.143q-0.339-0.339-0.339-0.804t0.339-0.804l9.143-9.143q0.339-0.339 0.804-0.339t0.804 0.339 0.339 0.804v4.571h4q12.732 0 15.625 7.196 0.946 2.393 0.946 5.946z"></path></symbol><symbol id="icon-youtube" viewbox="0 0 27 32"><path class="path1" d="M17.339 22.214v3.768q0 1.196-0.696 1.196-0.411 0-0.804-0.393v-5.375q0.393-0.393 0.804-0.393 0.696 0 0.696 1.196zM23.375 22.232v0.821h-1.607v-0.821q0-1.214 0.804-1.214t0.804 1.214zM6.125 18.339h1.911v-1.679h-5.571v1.679h1.875v10.161h1.786v-10.161zM11.268 28.5h1.589v-8.821h-1.589v6.75q-0.536 0.75-1.018 0.75-0.321 0-0.375-0.375-0.018-0.054-0.018-0.625v-6.5h-1.589v6.982q0 0.875 0.143 1.304 0.214 0.661 1.036 0.661 0.857 0 1.821-1.089v0.964zM18.929 25.857v-3.518q0-1.304-0.161-1.768-0.304-1-1.268-1-0.893 0-1.661 0.964v-3.875h-1.589v11.839h1.589v-0.857q0.804 0.982 1.661 0.982 0.964 0 1.268-0.982 0.161-0.482 0.161-1.786zM24.964 25.679v-0.232h-1.625q0 0.911-0.036 1.089-0.125 0.643-0.714 0.643-0.821 0-0.821-1.232v-1.554h3.196v-1.839q0-1.411-0.482-2.071-0.696-0.911-1.893-0.911-1.214 0-1.911 0.911-0.5 0.661-0.5 2.071v3.089q0 1.411 0.518 2.071 0.696 0.911 1.929 0.911 1.286 0 1.929-0.946 0.321-0.482 0.375-0.964 0.036-0.161 0.036-1.036zM14.107 9.375v-3.75q0-1.232-0.768-1.232t-0.768 1.232v3.75q0 1.25 0.768 1.25t0.768-1.25zM26.946 22.786q0 4.179-0.464 6.25-0.25 1.054-1.036 1.768t-1.821 0.821q-3.286 0.375-9.911 0.375t-9.911-0.375q-1.036-0.107-1.83-0.821t-1.027-1.768q-0.464-2-0.464-6.25 0-4.179 0.464-6.25 0.25-1.054 1.036-1.768t1.839-0.839q3.268-0.357 9.893-0.357t9.911 0.357q1.036 0.125 1.83 0.839t1.027 1.768q0.464 2 0.464 6.25zM9.125 0h1.821l-2.161 7.125v4.839h-1.786v-4.839q-0.25-1.321-1.089-3.786-0.661-1.839-1.161-3.339h1.893l1.268 4.696zM15.732 5.946v3.125q0 1.446-0.5 2.107-0.661 0.911-1.893 0.911-1.196 0-1.875-0.911-0.5-0.679-0.5-2.107v-3.125q0-1.429 0.5-2.089 0.679-0.911 1.875-0.911 1.232 0 1.893 0.911 0.5 0.661 0.5 2.089zM21.714 3.054v8.911h-1.625v-0.982q-0.946 1.107-1.839 1.107-0.821 0-1.054-0.661-0.143-0.429-0.143-1.339v-7.036h1.625v6.554q0 0.589 0.018 0.625 0.054 0.393 0.375 0.393 0.482 0 1.018-0.768v-6.804h1.625z"></path></symbol><symbol id="icon-dropbox" viewbox="0 0 32 32"><path class="path1" d="M7.179 12.625l8.821 5.446-6.107 5.089-8.75-5.696zM24.786 22.536v1.929l-8.75 5.232v0.018l-0.018-0.018-0.018 0.018v-0.018l-8.732-5.232v-1.929l2.625 1.714 6.107-5.071v-0.036l0.018 0.018 0.018-0.018v0.036l6.125 5.071zM9.893 2.107l6.107 5.089-8.821 5.429-6.036-4.821zM24.821 12.625l6.036 4.839-8.732 5.696-6.125-5.089zM22.125 2.107l8.732 5.696-6.036 4.821-8.821-5.429z"></path></symbol><symbol id="icon-instagram" viewbox="0 0 27 32"><path class="path1" d="M18.286 16q0-1.893-1.339-3.232t-3.232-1.339-3.232 1.339-1.339 3.232 1.339 3.232 3.232 1.339 3.232-1.339 1.339-3.232zM20.75 16q0 2.929-2.054 4.982t-4.982 2.054-4.982-2.054-2.054-4.982 2.054-4.982 4.982-2.054 4.982 2.054 2.054 4.982zM22.679 8.679q0 0.679-0.482 1.161t-1.161 0.482-1.161-0.482-0.482-1.161 0.482-1.161 1.161-0.482 1.161 0.482 0.482 1.161zM13.714 4.75q-0.125 0-1.366-0.009t-1.884 0-1.723 0.054-1.839 0.179-1.277 0.33q-0.893 0.357-1.571 1.036t-1.036 1.571q-0.196 0.518-0.33 1.277t-0.179 1.839-0.054 1.723 0 1.884 0.009 1.366-0.009 1.366 0 1.884 0.054 1.723 0.179 1.839 0.33 1.277q0.357 0.893 1.036 1.571t1.571 1.036q0.518 0.196 1.277 0.33t1.839 0.179 1.723 0.054 1.884 0 1.366-0.009 1.366 0.009 1.884 0 1.723-0.054 1.839-0.179 1.277-0.33q0.893-0.357 1.571-1.036t1.036-1.571q0.196-0.518 0.33-1.277t0.179-1.839 0.054-1.723 0-1.884-0.009-1.366 0.009-1.366 0-1.884-0.054-1.723-0.179-1.839-0.33-1.277q-0.357-0.893-1.036-1.571t-1.571-1.036q-0.518-0.196-1.277-0.33t-1.839-0.179-1.723-0.054-1.884 0-1.366 0.009zM27.429 16q0 4.089-0.089 5.661-0.179 3.714-2.214 5.75t-5.75 2.214q-1.571 0.089-5.661 0.089t-5.661-0.089q-3.714-0.179-5.75-2.214t-2.214-5.75q-0.089-1.571-0.089-5.661t0.089-5.661q0.179-3.714 2.214-5.75t5.75-2.214q1.571-0.089 5.661-0.089t5.661 0.089q3.714 0.179 5.75 2.214t2.214 5.75q0.089 1.571 0.089 5.661z"></path></symbol><symbol id="icon-flickr" viewbox="0 0 27 32"><path class="path1" d="M22.286 2.286q2.125 0 3.634 1.509t1.509 3.634v17.143q0 2.125-1.509 3.634t-3.634 1.509h-17.143q-2.125 0-3.634-1.509t-1.509-3.634v-17.143q0-2.125 1.509-3.634t3.634-1.509h17.143zM12.464 16q0-1.571-1.107-2.679t-2.679-1.107-2.679 1.107-1.107 2.679 1.107 2.679 2.679 1.107 2.679-1.107 1.107-2.679zM22.536 16q0-1.571-1.107-2.679t-2.679-1.107-2.679 1.107-1.107 2.679 1.107 2.679 2.679 1.107 2.679-1.107 1.107-2.679z"></path></symbol><symbol id="icon-tumblr" viewbox="0 0 19 32"><path class="path1" d="M16.857 23.732l1.429 4.232q-0.411 0.625-1.982 1.179t-3.161 0.571q-1.857 0.036-3.402-0.464t-2.545-1.321-1.696-1.893-0.991-2.143-0.295-2.107v-9.714h-3v-3.839q1.286-0.464 2.304-1.241t1.625-1.607 1.036-1.821 0.607-1.768 0.268-1.58q0.018-0.089 0.080-0.152t0.134-0.063h4.357v7.571h5.946v4.5h-5.964v9.25q0 0.536 0.116 1t0.402 0.938 0.884 0.741 1.455 0.25q1.393-0.036 2.393-0.518z"></path></symbol><symbol id="icon-dockerhub" viewbox="0 0 24 28"><path class="path1" d="M1.597 10.257h2.911v2.83H1.597v-2.83zm3.573 0h2.91v2.83H5.17v-2.83zm0-3.627h2.91v2.829H5.17V6.63zm3.57 3.627h2.912v2.83H8.74v-2.83zm0-3.627h2.912v2.829H8.74V6.63zm3.573 3.627h2.911v2.83h-2.911v-2.83zm0-3.627h2.911v2.829h-2.911V6.63zm3.572 3.627h2.911v2.83h-2.911v-2.83zM12.313 3h2.911v2.83h-2.911V3zm-6.65 14.173c-.449 0-.812.354-.812.788 0 .435.364.788.812.788.447 0 .811-.353.811-.788 0-.434-.363-.788-.811-.788"></path><path class="path2" d="M28.172 11.721c-.978-.549-2.278-.624-3.388-.306-.136-1.146-.91-2.149-1.83-2.869l-.366-.286-.307.345c-.618.692-.8 1.845-.718 2.73.063.651.273 1.312.685 1.834-.313.183-.668.328-.985.434-.646.212-1.347.33-2.028.33H.083l-.042.429c-.137 1.432.065 2.866.674 4.173l.262.519.03.048c1.8 2.973 4.963 4.225 8.41 4.225 6.672 0 12.174-2.896 14.702-9.015 1.689.085 3.417-.4 4.243-1.968l.211-.4-.401-.223zM5.664 19.458c-.85 0-1.542-.671-1.542-1.497 0-.825.691-1.498 1.541-1.498.849 0 1.54.672 1.54 1.497s-.69 1.498-1.539 1.498z"></path></symbol><symbol id="icon-dribbble" viewbox="0 0 27 32"><path class="path1" d="M18.286 26.786q-0.75-4.304-2.5-8.893h-0.036l-0.036 0.018q-0.286 0.107-0.768 0.295t-1.804 0.875-2.446 1.464-2.339 2.045-1.839 2.643l-0.268-0.196q3.286 2.679 7.464 2.679 2.357 0 4.571-0.929zM14.982 15.946q-0.375-0.875-0.946-1.982-5.554 1.661-12.018 1.661-0.018 0.125-0.018 0.375 0 2.214 0.786 4.223t2.214 3.598q0.893-1.589 2.205-2.973t2.545-2.223 2.33-1.446 1.777-0.857l0.661-0.232q0.071-0.018 0.232-0.063t0.232-0.080zM13.071 12.161q-2.143-3.804-4.357-6.75-2.464 1.161-4.179 3.321t-2.286 4.857q5.393 0 10.821-1.429zM25.286 17.857q-3.75-1.071-7.304-0.518 1.554 4.268 2.286 8.375 1.982-1.339 3.304-3.384t1.714-4.473zM10.911 4.625q-0.018 0-0.036 0.018 0.018-0.018 0.036-0.018zM21.446 7.214q-3.304-2.929-7.732-2.929-1.357 0-2.768 0.339 2.339 3.036 4.393 6.821 1.232-0.464 2.321-1.080t1.723-1.098 1.17-1.018 0.67-0.723zM25.429 15.875q-0.054-4.143-2.661-7.321l-0.018 0.018q-0.161 0.214-0.339 0.438t-0.777 0.795-1.268 1.080-1.786 1.161-2.348 1.152q0.446 0.946 0.786 1.696 0.036 0.107 0.116 0.313t0.134 0.295q0.643-0.089 1.33-0.125t1.313-0.036 1.232 0.027 1.143 0.071 1.009 0.098 0.857 0.116 0.652 0.107 0.446 0.080zM27.429 16q0 3.732-1.839 6.884t-4.991 4.991-6.884 1.839-6.884-1.839-4.991-4.991-1.839-6.884 1.839-6.884 4.991-4.991 6.884-1.839 6.884 1.839 4.991 4.991 1.839 6.884z"></path></symbol><symbol id="icon-skype" viewbox="0 0 27 32"><path class="path1" d="M20.946 18.982q0-0.893-0.348-1.634t-0.866-1.223-1.304-0.875-1.473-0.607-1.563-0.411l-1.857-0.429q-0.536-0.125-0.786-0.188t-0.625-0.205-0.536-0.286-0.295-0.375-0.134-0.536q0-1.375 2.571-1.375 0.768 0 1.375 0.214t0.964 0.509 0.679 0.598 0.714 0.518 0.857 0.214q0.839 0 1.348-0.571t0.509-1.375q0-0.982-1-1.777t-2.536-1.205-3.25-0.411q-1.214 0-2.357 0.277t-2.134 0.839-1.589 1.554-0.598 2.295q0 1.089 0.339 1.902t1 1.348 1.429 0.866 1.839 0.58l2.607 0.643q1.607 0.393 2 0.643 0.571 0.357 0.571 1.071 0 0.696-0.714 1.152t-1.875 0.455q-0.911 0-1.634-0.286t-1.161-0.688-0.813-0.804-0.821-0.688-0.964-0.286q-0.893 0-1.348 0.536t-0.455 1.339q0 1.643 2.179 2.813t5.196 1.17q1.304 0 2.5-0.33t2.188-0.955 1.58-1.67 0.589-2.348zM27.429 22.857q0 2.839-2.009 4.848t-4.848 2.009q-2.321 0-4.179-1.429-1.375 0.286-2.679 0.286-2.554 0-4.884-0.991t-4.018-2.679-2.679-4.018-0.991-4.884q0-1.304 0.286-2.679-1.429-1.857-1.429-4.179 0-2.839 2.009-4.848t4.848-2.009q2.321 0 4.179 1.429 1.375-0.286 2.679-0.286 2.554 0 4.884 0.991t4.018 2.679 2.679 4.018 0.991 4.884q0 1.304-0.286 2.679 1.429 1.857 1.429 4.179z"></path></symbol><symbol id="icon-foursquare" viewbox="0 0 23 32"><path class="path1" d="M17.857 7.75l0.661-3.464q0.089-0.411-0.161-0.714t-0.625-0.304h-12.714q-0.411 0-0.688 0.304t-0.277 0.661v19.661q0 0.125 0.107 0.018l5.196-6.286q0.411-0.464 0.679-0.598t0.857-0.134h4.268q0.393 0 0.661-0.259t0.321-0.527q0.429-2.321 0.661-3.411 0.071-0.375-0.205-0.714t-0.652-0.339h-5.25q-0.518 0-0.857-0.339t-0.339-0.857v-0.75q0-0.518 0.339-0.848t0.857-0.33h6.179q0.321 0 0.625-0.241t0.357-0.527zM21.911 3.786q-0.268 1.304-0.955 4.759t-1.241 6.25-0.625 3.098q-0.107 0.393-0.161 0.58t-0.25 0.58-0.438 0.589-0.688 0.375-1.036 0.179h-4.839q-0.232 0-0.393 0.179-0.143 0.161-7.607 8.821-0.393 0.446-1.045 0.509t-0.866-0.098q-0.982-0.393-0.982-1.75v-25.179q0-0.982 0.679-1.83t2.143-0.848h15.857q1.696 0 2.268 0.946t0.179 2.839zM21.911 3.786l-2.821 14.107q0.071-0.304 0.625-3.098t1.241-6.25 0.955-4.759z"></path></symbol><symbol id="icon-wordpress" viewbox="0 0 32 32"><path class="path1" d="M2.268 16q0-2.911 1.196-5.589l6.554 17.946q-3.5-1.696-5.625-5.018t-2.125-7.339zM25.268 15.304q0 0.339-0.045 0.688t-0.179 0.884-0.205 0.786-0.313 1.054-0.313 1.036l-1.357 4.571-4.964-14.75q0.821-0.054 1.571-0.143 0.339-0.036 0.464-0.33t-0.045-0.554-0.509-0.241l-3.661 0.179q-1.339-0.018-3.607-0.179-0.214-0.018-0.366 0.089t-0.205 0.268-0.027 0.33 0.161 0.295 0.348 0.143l1.429 0.143 2.143 5.857-3 9-5-14.857q0.821-0.054 1.571-0.143 0.339-0.036 0.464-0.33t-0.045-0.554-0.509-0.241l-3.661 0.179q-0.125 0-0.411-0.009t-0.464-0.009q1.875-2.857 4.902-4.527t6.563-1.67q2.625 0 5.009 0.946t4.259 2.661h-0.179q-0.982 0-1.643 0.723t-0.661 1.705q0 0.214 0.036 0.429t0.071 0.384 0.143 0.411 0.161 0.375 0.214 0.402 0.223 0.375 0.259 0.429 0.25 0.411q1.125 1.911 1.125 3.786zM16.232 17.196l4.232 11.554q0.018 0.107 0.089 0.196-2.25 0.786-4.554 0.786-2 0-3.875-0.571zM28.036 9.411q1.696 3.107 1.696 6.589 0 3.732-1.857 6.884t-4.982 4.973l4.196-12.107q1.054-3.018 1.054-4.929 0-0.75-0.107-1.411zM16 0q3.25 0 6.214 1.268t5.107 3.411 3.411 5.107 1.268 6.214-1.268 6.214-3.411 5.107-5.107 3.411-6.214 1.268-6.214-1.268-5.107-3.411-3.411-5.107-1.268-6.214 1.268-6.214 3.411-5.107 5.107-3.411 6.214-1.268zM16 31.268q3.089 0 5.92-1.214t4.875-3.259 3.259-4.875 1.214-5.92-1.214-5.92-3.259-4.875-4.875-3.259-5.92-1.214-5.92 1.214-4.875 3.259-3.259 4.875-1.214 5.92 1.214 5.92 3.259 4.875 4.875 3.259 5.92 1.214z"></path></symbol><symbol id="icon-stumbleupon" viewbox="0 0 34 32"><path class="path1" d="M18.964 12.714v-2.107q0-0.75-0.536-1.286t-1.286-0.536-1.286 0.536-0.536 1.286v10.929q0 3.125-2.25 5.339t-5.411 2.214q-3.179 0-5.42-2.241t-2.241-5.42v-4.75h5.857v4.679q0 0.768 0.536 1.295t1.286 0.527 1.286-0.527 0.536-1.295v-11.071q0-3.054 2.259-5.214t5.384-2.161q3.143 0 5.393 2.179t2.25 5.25v2.429l-3.482 1.036zM28.429 16.679h5.857v4.75q0 3.179-2.241 5.42t-5.42 2.241q-3.161 0-5.411-2.223t-2.25-5.366v-4.786l2.339 1.089 3.482-1.036v4.821q0 0.75 0.536 1.277t1.286 0.527 1.286-0.527 0.536-1.277v-4.911z"></path></symbol><symbol id="icon-digg" viewbox="0 0 37 32"><path class="path1" d="M5.857 5.036h3.643v17.554h-9.5v-12.446h5.857v-5.107zM5.857 19.661v-6.589h-2.196v6.589h2.196zM10.964 10.143v12.446h3.661v-12.446h-3.661zM10.964 5.036v3.643h3.661v-3.643h-3.661zM16.089 10.143h9.518v16.821h-9.518v-2.911h5.857v-1.464h-5.857v-12.446zM21.946 19.661v-6.589h-2.196v6.589h2.196zM27.071 10.143h9.5v16.821h-9.5v-2.911h5.839v-1.464h-5.839v-12.446zM32.911 19.661v-6.589h-2.196v6.589h2.196z"></path></symbol><symbol id="icon-spotify" viewbox="0 0 27 32"><path class="path1" d="M20.125 21.607q0-0.571-0.536-0.911-3.446-2.054-7.982-2.054-2.375 0-5.125 0.607-0.75 0.161-0.75 0.929 0 0.357 0.241 0.616t0.634 0.259q0.089 0 0.661-0.143 2.357-0.482 4.339-0.482 4.036 0 7.089 1.839 0.339 0.196 0.589 0.196 0.339 0 0.589-0.241t0.25-0.616zM21.839 17.768q0-0.714-0.625-1.089-4.232-2.518-9.786-2.518-2.732 0-5.411 0.75-0.857 0.232-0.857 1.143 0 0.446 0.313 0.759t0.759 0.313q0.125 0 0.661-0.143 2.179-0.589 4.482-0.589 4.982 0 8.714 2.214 0.429 0.232 0.679 0.232 0.446 0 0.759-0.313t0.313-0.759zM23.768 13.339q0-0.839-0.714-1.25-2.25-1.304-5.232-1.973t-6.125-0.67q-3.643 0-6.5 0.839-0.411 0.125-0.688 0.455t-0.277 0.866q0 0.554 0.366 0.929t0.92 0.375q0.196 0 0.714-0.143 2.375-0.661 5.482-0.661 2.839 0 5.527 0.607t4.527 1.696q0.375 0.214 0.714 0.214 0.518 0 0.902-0.366t0.384-0.92zM27.429 16q0 3.732-1.839 6.884t-4.991 4.991-6.884 1.839-6.884-1.839-4.991-4.991-1.839-6.884 1.839-6.884 4.991-4.991 6.884-1.839 6.884 1.839 4.991 4.991 1.839 6.884z"></path></symbol><symbol id="icon-soundcloud" viewbox="0 0 41 32"><path class="path1" d="M14 24.5l0.286-4.304-0.286-9.339q-0.018-0.179-0.134-0.304t-0.295-0.125q-0.161 0-0.286 0.125t-0.125 0.304l-0.25 9.339 0.25 4.304q0.018 0.179 0.134 0.295t0.277 0.116q0.393 0 0.429-0.411zM19.286 23.982l0.196-3.768-0.214-10.464q0-0.286-0.232-0.429-0.143-0.089-0.286-0.089t-0.286 0.089q-0.232 0.143-0.232 0.429l-0.018 0.107-0.179 10.339q0 0.018 0.196 4.214v0.018q0 0.179 0.107 0.304 0.161 0.196 0.411 0.196 0.196 0 0.357-0.161 0.161-0.125 0.161-0.357zM0.625 17.911l0.357 2.286-0.357 2.25q-0.036 0.161-0.161 0.161t-0.161-0.161l-0.304-2.25 0.304-2.286q0.036-0.161 0.161-0.161t0.161 0.161zM2.161 16.5l0.464 3.696-0.464 3.625q-0.036 0.161-0.179 0.161-0.161 0-0.161-0.179l-0.411-3.607 0.411-3.696q0-0.161 0.161-0.161 0.143 0 0.179 0.161zM3.804 15.821l0.446 4.375-0.446 4.232q0 0.196-0.196 0.196-0.179 0-0.214-0.196l-0.375-4.232 0.375-4.375q0.036-0.214 0.214-0.214 0.196 0 0.196 0.214zM5.482 15.696l0.411 4.5-0.411 4.357q-0.036 0.232-0.25 0.232-0.232 0-0.232-0.232l-0.375-4.357 0.375-4.5q0-0.232 0.232-0.232 0.214 0 0.25 0.232zM7.161 16.018l0.375 4.179-0.375 4.393q-0.036 0.286-0.286 0.286-0.107 0-0.188-0.080t-0.080-0.205l-0.357-4.393 0.357-4.179q0-0.107 0.080-0.188t0.188-0.080q0.25 0 0.286 0.268zM8.839 13.411l0.375 6.786-0.375 4.393q0 0.125-0.089 0.223t-0.214 0.098q-0.286 0-0.321-0.321l-0.321-4.393 0.321-6.786q0.036-0.321 0.321-0.321 0.125 0 0.214 0.098t0.089 0.223zM10.518 11.875l0.339 8.357-0.339 4.357q0 0.143-0.098 0.241t-0.241 0.098q-0.321 0-0.357-0.339l-0.286-4.357 0.286-8.357q0.036-0.339 0.357-0.339 0.143 0 0.241 0.098t0.098 0.241zM12.268 11.161l0.321 9.036-0.321 4.321q-0.036 0.375-0.393 0.375-0.339 0-0.375-0.375l-0.286-4.321 0.286-9.036q0-0.161 0.116-0.277t0.259-0.116q0.161 0 0.268 0.116t0.125 0.277zM19.268 24.411v0 0zM15.732 11.089l0.268 9.107-0.268 4.268q0 0.179-0.134 0.313t-0.313 0.134-0.304-0.125-0.143-0.321l-0.25-4.268 0.25-9.107q0-0.196 0.134-0.321t0.313-0.125 0.313 0.125 0.134 0.321zM17.5 11.429l0.25 8.786-0.25 4.214q0 0.196-0.143 0.339t-0.339 0.143-0.339-0.143-0.161-0.339l-0.214-4.214 0.214-8.786q0.018-0.214 0.161-0.357t0.339-0.143 0.33 0.143 0.152 0.357zM21.286 20.214l-0.25 4.125q0 0.232-0.161 0.393t-0.393 0.161-0.393-0.161-0.179-0.393l-0.107-2.036-0.107-2.089 0.214-11.357v-0.054q0.036-0.268 0.214-0.429 0.161-0.125 0.357-0.125 0.143 0 0.268 0.089 0.25 0.143 0.286 0.464zM41.143 19.875q0 2.089-1.482 3.563t-3.571 1.473h-14.036q-0.232-0.036-0.393-0.196t-0.161-0.393v-16.054q0-0.411 0.5-0.589 1.518-0.607 3.232-0.607 3.482 0 6.036 2.348t2.857 5.777q0.946-0.393 1.964-0.393 2.089 0 3.571 1.482t1.482 3.589z"></path></symbol><symbol id="icon-codepen" viewbox="0 0 32 32"><path class="path1" d="M3.857 20.875l10.768 7.179v-6.411l-5.964-3.982zM2.75 18.304l3.446-2.304-3.446-2.304v4.607zM17.375 28.054l10.768-7.179-4.804-3.214-5.964 3.982v6.411zM16 19.25l4.857-3.25-4.857-3.25-4.857 3.25zM8.661 14.339l5.964-3.982v-6.411l-10.768 7.179zM25.804 16l3.446 2.304v-4.607zM23.339 14.339l4.804-3.214-10.768-7.179v6.411zM32 11.125v9.75q0 0.732-0.607 1.143l-14.625 9.75q-0.375 0.232-0.768 0.232t-0.768-0.232l-14.625-9.75q-0.607-0.411-0.607-1.143v-9.75q0-0.732 0.607-1.143l14.625-9.75q0.375-0.232 0.768-0.232t0.768 0.232l14.625 9.75q0.607 0.411 0.607 1.143z"></path></symbol><symbol id="icon-twitch" viewbox="0 0 32 32"><path class="path1" d="M16 7.75v7.75h-2.589v-7.75h2.589zM23.107 7.75v7.75h-2.589v-7.75h2.589zM23.107 21.321l4.518-4.536v-14.196h-21.321v18.732h5.821v3.875l3.875-3.875h7.107zM30.214 0v18.089l-7.75 7.75h-5.821l-3.875 3.875h-3.875v-3.875h-7.107v-20.679l1.946-5.161h26.482z"></path></symbol><symbol id="icon-meanpath" viewbox="0 0 27 32"><path class="path1" d="M23.411 15.036v2.036q0 0.429-0.241 0.679t-0.67 0.25h-3.607q-0.429 0-0.679-0.25t-0.25-0.679v-2.036q0-0.429 0.25-0.679t0.679-0.25h3.607q0.429 0 0.67 0.25t0.241 0.679zM14.661 19.143v-4.464q0-0.946-0.58-1.527t-1.527-0.58h-2.375q-1.214 0-1.714 0.929-0.5-0.929-1.714-0.929h-2.321q-0.946 0-1.527 0.58t-0.58 1.527v4.464q0 0.393 0.375 0.393h0.982q0.393 0 0.393-0.393v-4.107q0-0.429 0.241-0.679t0.688-0.25h1.679q0.429 0 0.679 0.25t0.25 0.679v4.107q0 0.393 0.375 0.393h0.964q0.393 0 0.393-0.393v-4.107q0-0.429 0.25-0.679t0.679-0.25h1.732q0.429 0 0.67 0.25t0.241 0.679v4.107q0 0.393 0.393 0.393h0.982q0.375 0 0.375-0.393zM25.179 17.429v-2.75q0-0.946-0.589-1.527t-1.536-0.58h-4.714q-0.946 0-1.536 0.58t-0.589 1.527v7.321q0 0.375 0.393 0.375h0.982q0.375 0 0.375-0.375v-3.214q0.554 0.75 1.679 0.75h3.411q0.946 0 1.536-0.58t0.589-1.527zM27.429 6.429v19.143q0 1.714-1.214 2.929t-2.929 1.214h-19.143q-1.714 0-2.929-1.214t-1.214-2.929v-19.143q0-1.714 1.214-2.929t2.929-1.214h19.143q1.714 0 2.929 1.214t1.214 2.929z"></path></symbol><symbol id="icon-pinterest-p" viewbox="0 0 23 32"><path class="path1" d="M0 10.661q0-1.929 0.67-3.634t1.848-2.973 2.714-2.196 3.304-1.393 3.607-0.464q2.821 0 5.25 1.188t3.946 3.455 1.518 5.125q0 1.714-0.339 3.357t-1.071 3.161-1.786 2.67-2.589 1.839-3.375 0.688q-1.214 0-2.411-0.571t-1.714-1.571q-0.179 0.696-0.5 2.009t-0.42 1.696-0.366 1.268-0.464 1.268-0.571 1.116-0.821 1.384-1.107 1.545l-0.25 0.089-0.161-0.179q-0.268-2.804-0.268-3.357 0-1.643 0.384-3.688t1.188-5.134 0.929-3.625q-0.571-1.161-0.571-3.018 0-1.482 0.929-2.786t2.357-1.304q1.089 0 1.696 0.723t0.607 1.83q0 1.179-0.786 3.411t-0.786 3.339q0 1.125 0.804 1.866t1.946 0.741q0.982 0 1.821-0.446t1.402-1.214 1-1.696 0.679-1.973 0.357-1.982 0.116-1.777q0-3.089-1.955-4.813t-5.098-1.723q-3.571 0-5.964 2.313t-2.393 5.866q0 0.786 0.223 1.518t0.482 1.161 0.482 0.813 0.223 0.545q0 0.5-0.268 1.304t-0.661 0.804q-0.036 0-0.304-0.054-0.911-0.268-1.616-1t-1.089-1.688-0.58-1.929-0.196-1.902z"></path></symbol><symbol id="icon-periscope" viewbox="0 0 24 28"><path class="path1" d="M12.285,1C6.696,1,2.277,5.643,2.277,11.243c0,5.851,7.77,14.578,10.007,14.578c1.959,0,9.729-8.728,9.729-14.578 C22.015,5.643,17.596,1,12.285,1z M12.317,16.551c-3.473,0-6.152-2.611-6.152-5.664c0-1.292,0.39-2.472,1.065-3.438 c0.206,1.084,1.18,1.906,2.352,1.906c1.322,0,2.393-1.043,2.393-2.333c0-0.832-0.447-1.561-1.119-1.975 c0.467-0.105,0.955-0.161,1.46-0.161c3.133,0,5.81,2.611,5.81,5.998C18.126,13.94,15.449,16.551,12.317,16.551z"></path></symbol><symbol id="icon-get-pocket" viewbox="0 0 31 32"><path class="path1" d="M27.946 2.286q1.161 0 1.964 0.813t0.804 1.973v9.268q0 3.143-1.214 6t-3.259 4.911-4.893 3.259-5.973 1.205q-3.143 0-5.991-1.205t-4.902-3.259-3.268-4.911-1.214-6v-9.268q0-1.143 0.821-1.964t1.964-0.821h25.161zM15.375 21.286q0.839 0 1.464-0.589l7.214-6.929q0.661-0.625 0.661-1.518 0-0.875-0.616-1.491t-1.491-0.616q-0.839 0-1.464 0.589l-5.768 5.536-5.768-5.536q-0.625-0.589-1.446-0.589-0.875 0-1.491 0.616t-0.616 1.491q0 0.911 0.643 1.518l7.232 6.929q0.589 0.589 1.446 0.589z"></path></symbol><symbol id="icon-vimeo" viewbox="0 0 32 32"><path class="path1" d="M30.518 9.25q-0.179 4.214-5.929 11.625-5.946 7.696-10.036 7.696-2.536 0-4.286-4.696-0.786-2.857-2.357-8.607-1.286-4.679-2.804-4.679-0.321 0-2.268 1.357l-1.375-1.75q0.429-0.375 1.929-1.723t2.321-2.063q2.786-2.464 4.304-2.607 1.696-0.161 2.732 0.991t1.446 3.634q0.786 5.125 1.179 6.661 0.982 4.446 2.143 4.446 0.911 0 2.75-2.875 1.804-2.875 1.946-4.393 0.232-2.482-1.946-2.482-1.018 0-2.161 0.464 2.143-7.018 8.196-6.821 4.482 0.143 4.214 5.821z"></path></symbol><symbol id="icon-reddit-alien" viewbox="0 0 32 32"><path class="path1" d="M32 15.107q0 1.036-0.527 1.884t-1.42 1.295q0.214 0.821 0.214 1.714 0 2.768-1.902 5.125t-5.188 3.723-7.143 1.366-7.134-1.366-5.179-3.723-1.902-5.125q0-0.839 0.196-1.679-0.911-0.446-1.464-1.313t-0.554-1.902q0-1.464 1.036-2.509t2.518-1.045q1.518 0 2.589 1.125 3.893-2.714 9.196-2.893l2.071-9.304q0.054-0.232 0.268-0.375t0.464-0.089l6.589 1.446q0.321-0.661 0.964-1.063t1.411-0.402q1.107 0 1.893 0.777t0.786 1.884-0.786 1.893-1.893 0.786-1.884-0.777-0.777-1.884l-5.964-1.321-1.857 8.429q5.357 0.161 9.268 2.857 1.036-1.089 2.554-1.089 1.482 0 2.518 1.045t1.036 2.509zM7.464 18.661q0 1.107 0.777 1.893t1.884 0.786 1.893-0.786 0.786-1.893-0.786-1.884-1.893-0.777q-1.089 0-1.875 0.786t-0.786 1.875zM21.929 25q0.196-0.196 0.196-0.464t-0.196-0.464q-0.179-0.179-0.446-0.179t-0.464 0.179q-0.732 0.75-2.161 1.107t-2.857 0.357-2.857-0.357-2.161-1.107q-0.196-0.179-0.464-0.179t-0.446 0.179q-0.196 0.179-0.196 0.455t0.196 0.473q0.768 0.768 2.116 1.214t2.188 0.527 1.625 0.080 1.625-0.080 2.188-0.527 2.116-1.214zM21.875 21.339q1.107 0 1.884-0.786t0.777-1.893q0-1.089-0.786-1.875t-1.875-0.786q-1.107 0-1.893 0.777t-0.786 1.884 0.786 1.893 1.893 0.786z"></path></symbol><symbol id="icon-hashtag" viewbox="0 0 32 32"><path class="path1" d="M17.696 18.286l1.143-4.571h-4.536l-1.143 4.571h4.536zM31.411 9.286l-1 4q-0.125 0.429-0.554 0.429h-5.839l-1.143 4.571h5.554q0.268 0 0.446 0.214 0.179 0.25 0.107 0.5l-1 4q-0.089 0.429-0.554 0.429h-5.839l-1.446 5.857q-0.125 0.429-0.554 0.429h-4q-0.286 0-0.464-0.214-0.161-0.214-0.107-0.5l1.393-5.571h-4.536l-1.446 5.857q-0.125 0.429-0.554 0.429h-4.018q-0.268 0-0.446-0.214-0.161-0.214-0.107-0.5l1.393-5.571h-5.554q-0.268 0-0.446-0.214-0.161-0.214-0.107-0.5l1-4q0.125-0.429 0.554-0.429h5.839l1.143-4.571h-5.554q-0.268 0-0.446-0.214-0.179-0.25-0.107-0.5l1-4q0.089-0.429 0.554-0.429h5.839l1.446-5.857q0.125-0.429 0.571-0.429h4q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5l-1.393 5.571h4.536l1.446-5.857q0.125-0.429 0.571-0.429h4q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5l-1.393 5.571h5.554q0.268 0 0.446 0.214 0.161 0.214 0.107 0.5z"></path></symbol><symbol id="icon-chain" viewbox="0 0 30 32"><path class="path1" d="M26 21.714q0-0.714-0.5-1.214l-3.714-3.714q-0.5-0.5-1.214-0.5-0.75 0-1.286 0.571 0.054 0.054 0.339 0.33t0.384 0.384 0.268 0.339 0.232 0.455 0.063 0.491q0 0.714-0.5 1.214t-1.214 0.5q-0.268 0-0.491-0.063t-0.455-0.232-0.339-0.268-0.384-0.384-0.33-0.339q-0.589 0.554-0.589 1.304 0 0.714 0.5 1.214l3.679 3.696q0.482 0.482 1.214 0.482 0.714 0 1.214-0.464l2.625-2.607q0.5-0.5 0.5-1.196zM13.446 9.125q0-0.714-0.5-1.214l-3.679-3.696q-0.5-0.5-1.214-0.5-0.696 0-1.214 0.482l-2.625 2.607q-0.5 0.5-0.5 1.196 0 0.714 0.5 1.214l3.714 3.714q0.482 0.482 1.214 0.482 0.75 0 1.286-0.554-0.054-0.054-0.339-0.33t-0.384-0.384-0.268-0.339-0.232-0.455-0.063-0.491q0-0.714 0.5-1.214t1.214-0.5q0.268 0 0.491 0.063t0.455 0.232 0.339 0.268 0.384 0.384 0.33 0.339q0.589-0.554 0.589-1.304zM29.429 21.714q0 2.143-1.518 3.625l-2.625 2.607q-1.482 1.482-3.625 1.482-2.161 0-3.643-1.518l-3.679-3.696q-1.482-1.482-1.482-3.625 0-2.196 1.571-3.732l-1.571-1.571q-1.536 1.571-3.714 1.571-2.143 0-3.643-1.5l-3.714-3.714q-1.5-1.5-1.5-3.643t1.518-3.625l2.625-2.607q1.482-1.482 3.625-1.482 2.161 0 3.643 1.518l3.679 3.696q1.482 1.482 1.482 3.625 0 2.196-1.571 3.732l1.571 1.571q1.536-1.571 3.714-1.571 2.143 0 3.643 1.5l3.714 3.714q1.5 1.5 1.5 3.643z"></path></symbol><symbol id="icon-thumb-tack" viewbox="0 0 21 32"><path class="path1" d="M8.571 15.429v-8q0-0.25-0.161-0.411t-0.411-0.161-0.411 0.161-0.161 0.411v8q0 0.25 0.161 0.411t0.411 0.161 0.411-0.161 0.161-0.411zM20.571 21.714q0 0.464-0.339 0.804t-0.804 0.339h-7.661l-0.911 8.625q-0.036 0.214-0.188 0.366t-0.366 0.152h-0.018q-0.482 0-0.571-0.482l-1.357-8.661h-7.214q-0.464 0-0.804-0.339t-0.339-0.804q0-2.196 1.402-3.955t3.17-1.759v-9.143q-0.929 0-1.607-0.679t-0.679-1.607 0.679-1.607 1.607-0.679h11.429q0.929 0 1.607 0.679t0.679 1.607-0.679 1.607-1.607 0.679v9.143q1.768 0 3.17 1.759t1.402 3.955z"></path></symbol><symbol id="icon-arrow-left" viewbox="0 0 43 32"><path class="path1" d="M42.311 14.044c-0.178-0.178-0.533-0.356-0.711-0.356h-33.778l10.311-10.489c0.178-0.178 0.356-0.533 0.356-0.711 0-0.356-0.178-0.533-0.356-0.711l-1.6-1.422c-0.356-0.178-0.533-0.356-0.889-0.356s-0.533 0.178-0.711 0.356l-14.578 14.933c-0.178 0.178-0.356 0.533-0.356 0.711s0.178 0.533 0.356 0.711l14.756 14.933c0 0.178 0.356 0.356 0.533 0.356s0.533-0.178 0.711-0.356l1.6-1.6c0.178-0.178 0.356-0.533 0.356-0.711s-0.178-0.533-0.356-0.711l-10.311-10.489h33.778c0.178 0 0.533-0.178 0.711-0.356 0.356-0.178 0.533-0.356 0.533-0.711v-2.133c0-0.356-0.178-0.711-0.356-0.889z"></path></symbol><symbol id="icon-arrow-right" viewbox="0 0 43 32"><path class="path1" d="M0.356 17.956c0.178 0.178 0.533 0.356 0.711 0.356h33.778l-10.311 10.489c-0.178 0.178-0.356 0.533-0.356 0.711 0 0.356 0.178 0.533 0.356 0.711l1.6 1.6c0.178 0.178 0.533 0.356 0.711 0.356s0.533-0.178 0.711-0.356l14.756-14.933c0.178-0.356 0.356-0.711 0.356-0.889s-0.178-0.533-0.356-0.711l-14.756-14.933c0-0.178-0.356-0.356-0.533-0.356s-0.533 0.178-0.711 0.356l-1.6 1.6c-0.178 0.178-0.356 0.533-0.356 0.711s0.178 0.533 0.356 0.711l10.311 10.489h-33.778c-0.178 0-0.533 0.178-0.711 0.356-0.356 0.178-0.533 0.356-0.533 0.711v2.311c0 0.178 0.178 0.533 0.356 0.711z"></path></symbol><symbol id="icon-play" viewbox="0 0 22 28"><path d="M21.625 14.484l-20.75 11.531c-0.484 0.266-0.875 0.031-0.875-0.516v-23c0-0.547 0.391-0.781 0.875-0.516l20.75 11.531c0.484 0.266 0.484 0.703 0 0.969z"></path></symbol><symbol id="icon-pause" viewbox="0 0 24 28"><path d="M24 3v22c0 0.547-0.453 1-1 1h-8c-0.547 0-1-0.453-1-1v-22c0-0.547 0.453-1 1-1h8c0.547 0 1 0.453 1 1zM10 3v22c0 0.547-0.453 1-1 1h-8c-0.547 0-1-0.453-1-1v-22c0-0.547 0.453-1 1-1h8c0.547 0 1 0.453 1 1z"></path></symbol></defs></svg></body></html>
